{"meta":{"title":"biglovewheat","subtitle":"","description":"","author":"biglovewheat","url":"https://biglovewheat.gihub.io","root":"/"},"pages":[{"title":"分类","date":"2022-07-25T08:47:31.000Z","updated":"2022-07-26T03:10:57.675Z","comments":true,"path":"categories/index.html","permalink":"https://biglovewheat.gihub.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-07-25T08:39:39.000Z","updated":"2022-07-26T03:08:43.741Z","comments":true,"path":"tags/index.html","permalink":"https://biglovewheat.gihub.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Kafka-集群安装","slug":"Kafka-集群安装","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/08/21/Kafka-集群安装/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/Kafka-%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","excerpt":"","text":"Kafka-集群安装官方文档部署主机123172.31.34.25 aws-sit-app-01 172.31.43.98 aws-sit-app-03172.31.43.45 aws-sit-app-04 zookeeper配置12345678910111213141516171819202122232425262728293031323334353637##重命名配置文件mv conf/zoo_sample.cfg conf/conzoo.cfg#编辑vim conf/zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeper/zkdataclientPort=2181server.1=172.31.34.25:2888:3888server.2=172.31.43.98:2888:3888server.3=172.31.43.45:2888:3888#上面这段server.A=B:C:D中#A代表的就是每个节点中myid文件中的编号#B代表的是节点的服务地址#C代表这个服务器 Follower 与集群中的 Leader 服务器交换信息的端口#D代表是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用#来执行选举时服务器相互通信的端口#创建myid文件，每个节点id是唯一mkdir -p /data/zookeeper/zkdata;echo 1&gt;/data/zookeeper/zkdata/myidmkdir -p /data/zookeeper/zkdata;echo 2&gt;/data/zookeeper/zkdata/myidmkdir -p /data/zookeeper/zkdata;echo 3&gt;/data/zookeeper/zkdata/myid## 启动脚本#!/bin/shexport JAVA_HOME=/data/soft/jdk1.8.0_301export PATH=$JAVA_HOME/bin:$PATHROOT_PATH=/data/zookeeper$ROOT_PATH/bin/zkServer.sh start## 检查./bin/zkServer.sh status kafka配置1234567891011121314151617181920212223242526272829303132333435## 修改配置文件vi confile/server.properties#broker.id不重复broker.id=0num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/data/kafka/kafka-logsnum.partitions=1num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=60log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=172.31.34.25:2181,172.31.43.98:2181,172.31.43.45:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0# 自动创建topicauto.create.topics.enable=true## 启动脚本#!/bin/bashexport JAVA_HOME=/data/soft/jdk1.8.0_301export PATH=$JAVA_HOME/bin:$PATHROOT_PATH=/data/kafka$ROOT_PATH/bin/kafka-server-start.sh -daemon $ROOT_PATH/config/server.properties 调试12345678910111213141516## 创建topicbin/kafka-topics.sh --create --topic quickstart-events1 --bootstrap-server 172.31.34.25:9092,172.31.43.98:9092,172.31.43.45:9092bin/kafka-topics.sh --describe --topic quickstart-events1 --bootstrap-server 172.31.34.25:9092,172.31.43.98:9092,172.31.43.45:9092## 往topic写入信息$ bin/kafka-console-producer.sh --topic quickstart-events1 --bootstrap-server 172.31.34.25:9092,172.31.43.98:9092,172.31.43.45:909212## 读取信息$ bin/kafka-console-consumer.sh --topic quickstart-events1 --from-beginning --bootstrap-server 172.31.34.25:9092,172.31.43.98:9092,172.31.43.45:909212bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092","categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/tags/middleware/"},{"name":"mq","slug":"mq","permalink":"https://biglovewheat.gihub.io/tags/mq/"}]},{"title":"AWS-子网划分","slug":"aws-子网划分","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2023/08/21/aws-子网划分/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/aws-%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86/","excerpt":"","text":"AWS-子网划分参考网址在线网络计算器 https://www.sojson.com/convert/subnetmask.html 列子网络列表网络 172.31.0.0 ，掩码255.255.240.0或20 可用网络16，每个网络可用主机4096","categories":[{"name":"云原生","slug":"云原生","permalink":"https://biglovewheat.gihub.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"aws","slug":"aws","permalink":"https://biglovewheat.gihub.io/tags/aws/"}]},{"title":"Gitlab-常用命令","slug":"git-常用命令","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/08/21/git-常用命令/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/git-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"Gitlab-常用命令1234567891011121314151617181920212223242526272829303132## 下载git clone [url]## 显示配置git config --list## 设置用户信息git config [--global] user.name &quot;[name]&quot;git config [--global] user.email &quot;[email address]&quot;## 增加文件git add [file1] [file2] ...git add [dir]git add .## 代码提交git commit -m [message]## 列出分支git branchgit branch -rgit branch -a## 切换分支git checkout [branch-name]## 合并分支git merge [branch]## 查看变更的文件git status","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"https://biglovewheat.gihub.io/tags/gitlab/"}]},{"title":"gitlab-角色","slug":"git-角色","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/08/21/git-角色/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/git-%E8%A7%92%E8%89%B2/","excerpt":"","text":"gitlab-角色用户在项目中的角色12345Guest：访客。可以创建issue、发表评论，不能读写版本库。（就是看不了代码…）Reporter：Git项目测试人员。可以克隆代码，不能提交。QA、PM可以赋予这个权限。Developer：项目开发人员。可以克隆代码、开发、提交、push。RD可以赋予这个权限。Maintainer：Git项目管理员。可以创建项目、添加tag、保护分支、添加项目成员、编辑项目。核心RD负责人可以赋予这个权限。Owner：Git系统管理员即Administrator。拥有至高无上的权限。开发组leader可以赋予这个权限。 项目的访问权限123Private：只有组成员才能看到Internal：只要登录的用户就能看到Public：所有人都能看到","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"git","slug":"git","permalink":"https://biglovewheat.gihub.io/tags/git/"}]},{"title":"Oracle-常用查询","slug":"oracle-常用查询","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/08/21/oracle-常用查询/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/oracle-%E5%B8%B8%E7%94%A8%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"Oracle-常用查询","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://biglovewheat.gihub.io/tags/oracle/"}]},{"title":"Oracle-常见ora错误","slug":"oracle-常见ora错误","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/08/21/oracle-常见ora错误/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/oracle-%E5%B8%B8%E8%A7%81ora%E9%94%99%E8%AF%AF/","excerpt":"","text":"Oracle-常见ora错误ORA_ORA-00257 空间不足错误12345678--查看使用情况select * from V$FLASH_RECOVERY_AREA_USAGE;--查看存储目录show parameter recover;--增大空间alter system set DB_RECOVERY_FILE_DEST_SIZE=20g;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://biglovewheat.gihub.io/tags/oracle/"}]},{"title":"Oracle-获取表结构","slug":"oracle-获取表结构","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/08/21/oracle-获取表结构/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/oracle-%E8%8E%B7%E5%8F%96%E8%A1%A8%E7%BB%93%E6%9E%84/","excerpt":"","text":"Oracle-获取表结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#!/bin/bashgetTabSql()&#123;sqlplus -S / as sysdba &gt;&gt;./$logfile &lt;&lt;!set heading off;set echo off;set pages 999;set long 90000;set linesize 1000;column DDLS format a1000;EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;PRETTY&#x27;, TRUE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;SQLTERMINATOR&#x27;, TRUE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;CONSTRAINTS&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;REF_CONSTRAINTS&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;CONSTRAINTS_AS_ALTER&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;STORAGE&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;TABLESPACE&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;SEGMENT_ATTRIBUTES&#x27;, FALSE);EXECUTE DBMS_METADATA.SET_TRANSFORM_PARAM(DBMS_METADATA.SESSION_TRANSFORM,&#x27;STORAGE&#x27;,false); spool getsql.$1.tmp;select dbms_metadata.get_ddl(&#x27;TABLE&#x27;,&#x27;$1&#x27;,&#x27;$2&#x27;) as ddls FROM DUAL;spool offexit!&#125;getIdxSql()&#123;sqlplus -S / as sysdba &gt;&gt;./$logfile &lt;&lt;!set heading off;set echo off;set pages 999;set long 90000;set linesize 1000;column DDLS format a1000;EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;PRETTY&#x27;, TRUE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;SQLTERMINATOR&#x27;, TRUE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;CONSTRAINTS&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;REF_CONSTRAINTS&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;CONSTRAINTS_AS_ALTER&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;STORAGE&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;TABLESPACE&#x27;, FALSE);EXEC DBMS_METADATA.set_transform_param(DBMS_METADATA.session_transform, &#x27;SEGMENT_ATTRIBUTES&#x27;, FALSE);spool getsql.$1.tmp;select dbms_metadata.get_ddl(&#x27;INDEX&#x27;,&#x27;$1&#x27;,&#x27;$2&#x27;) as ddls FROM DUAL;spool offexit!&#125;getIdxName()&#123; sqlplus -S / as sysdba &gt;&gt;./$logfile &lt;&lt;! set echo off set termout off set trimspool on set feedback off set verify off set pagesize 0 spool getsql.$1.idxname.tmp select index_name from dba_indexes where table_name=&#x27;$1&#x27; and owner=&#x27;$2&#x27;; spool off exit!&#125;rm -rf getsql.*.tmprm -rf getsql.loglogfile=getsql.log for rec in `cat getsql.lst` do OWNER=`echo $rec|awk -F\\. &#x27;&#123;print $1&#125;&#x27;` TABNAME=`echo $rec|awk -F\\. &#x27;&#123;print $2&#125;&#x27;` typeset -u $OWNER typeset -u $TABNAME getTabSql $TABNAME $OWNER getIdxName $TABNAME $OWNER for rec in `cat getsql.$TABNAME.idxname.tmp` do IDXNAME=`echo $rec|awk &#x27;&#123;print $1&#125;&#x27;` getIdxSql $IDXNAME $OWNER cat getsql.$IDXNAME.tmp &gt;&gt; getsql.$TABNAME.tmp done sed &#x27;s/[ \\t]*$//&#x27; getsql.$TABNAME.tmp|sed -e &#x27;/^$/d&#x27;&gt;$TABNAME.sql donerm -rf getsql.*.tmp","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://biglovewheat.gihub.io/tags/oracle/"}]},{"title":"Postgresql-基本操作","slug":"postgresql-基本操作","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/08/21/postgresql-基本操作/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/postgresql-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"","text":"Postgresql-基本操作12345##查看所有数据库\\lselect datname from pg_database;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://biglovewheat.gihub.io/tags/postgresql/"}]},{"title":"Shell-将文件平均分成n份","slug":"shell-将文件平均分成n份","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/08/21/shell-将文件平均分成n份/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/shell-%E5%B0%86%E6%96%87%E4%BB%B6%E5%B9%B3%E5%9D%87%E5%88%86%E6%88%90n%E4%BB%BD/","excerpt":"","text":"将文件平均分成n份12345678910111213141516171819202122232425262728#!/bin/shFILENAME=policyno.unlPARALLEL=10TOTALROW=`wc -l $FILENAME | awk &#x27;&#123;print $1&#125;&#x27;`DIVROW=$(( $TOTALROW / $PARALLEL ))LEFTROW=$(( $TOTALROW % $PARALLEL ))for ((i=1;i&lt;=$PARALLEL;i++))doif [ $i -le $LEFTROW ]thenPIECEROW=$(( $DIVROW + 1 ))elsePIECEROW=$DIVROWficase $i in1)head -n $PIECEROW $FILENAME &gt; $FILENAME.$iGETROW=$PIECEROW;;$PARALLEL)tail -n $PIECEROW $FILENAME &gt; $FILENAME.$i;;*)GETROW=$(( $GETROW + $PIECEROW ))head -n $GETROW $FILENAME |tail -n $PIECEROW &gt;$FILENAME.$i;;esacdone","categories":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"}]},{"title":"阿里云-数据库选型","slug":"阿里云-数据库选型","date":"2023-08-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/08/21/阿里云-数据库选型/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/21/%E9%98%BF%E9%87%8C%E4%BA%91-%E6%95%B0%E6%8D%AE%E5%BA%93%E9%80%89%E5%9E%8B/","excerpt":"","text":"阿里云-数据库选型","categories":[{"name":"云原生","slug":"云原生","permalink":"https://biglovewheat.gihub.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"https://biglovewheat.gihub.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"ELK-ON-K8S安装","slug":"elk-on-k8s安装","date":"2023-08-16T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/08/17/elk-on-k8s安装/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/17/elk-on-k8s%E5%AE%89%E8%A3%85/","excerpt":"","text":"ELK-ON-K8S安装helm安装12345678910111213141516171819202122232425262728293031323334353637383940## helm-eshelm repo add bitnami https://charts.bitnami.com/bitnamihelm upgrade --install elasticsearch bitnami/elasticsearch -n base \\--set global.storageClass=nfs-zhikong \\--set global.kibanaEnabled=true \\--set image.tag=7.15.2-debian-10-r10 \\--set security.elasticPassword=Hxkj2021 \\--set master.replicas=1 \\--set master.autoscaling.enabled=false \\--set master.autoscaling.minReplicas=2 \\--set master.autoscaling.maxReplicas=11 \\--set master.heapSize=256m \\--set coordinating.replicas=1 \\--set coordinating.autoscaling.enabled=false \\--set coordinating.autoscaling.minReplicas=2 \\--set coordinating.autoscaling.maxReplicas=11 \\--set coordinating.heapSize=256m \\--set data.replicas=1 \\--set data.autoscaling.enabled=false \\--set data.autoscaling.minReplicas=2 \\--set data.autoscaling.maxReplicas=11 \\--set data.heapSize=1G \\--set ingest.replicas=1 \\--set curator.enabled=false \\--set metrics.enabled=false## helm-logstashhelm repo add bitnami https://charts.bitnami.com/bitnamihelm upgrade --install logstash bitnami/logstash -n base \\--set image.tag=7.15.2-debian-10-r12 \\--set replicaCount=1 \\--set service.type=ClusterIP \\--set persistence.enabled=false \\--set persistence.storageClass=nfs-zhikong \\--set persistence.size=2Gi## helm-filebeathelm repo add elastic https://helm.elastic.cohelm upgrade --install filebeat elastic/filebeat -n base \\--set daemonset.enabled=true configmap配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546## es-configmappid.file: /opt/bitnami/kibana/tmp/kibana.pidserver.host: &quot;::&quot;server.port: 5601elasticsearch.hosts: [http://elasticsearch-coordinating-only:9200]server.rewriteBasePath: false## filebeat-configmapfilebeat.inputs:- type: log paths: - /var/log/*server/*server/*.logoutput.logstash: hosts: [logstash:8080]## logstash-configmapinput &#123; # udp &#123; # port =&gt; 1514 # type =&gt; syslog # &#125; # tcp &#123; # port =&gt; 1514 # type =&gt; syslog # &#125; beats &#123; port =&gt; 8080 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;elasticsearch-master:9200&quot;] # manage_template =&gt; false index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;&quot; &#125; # gelf &#123; # host =&gt; &quot;$&#123;GRAYLOG_HOST&#125;&quot; # port =&gt; $&#123;GRAYLOG_PORT&#125; # &#125; # stdout &#123;&#125;&#125;","categories":[{"name":"日志","slug":"日志","permalink":"https://biglovewheat.gihub.io/categories/%E6%97%A5%E5%BF%97/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://biglovewheat.gihub.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"emqx-安装","slug":"emqx-安装","date":"2023-08-16T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/08/17/emqx-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/17/emqx-%E5%AE%89%E8%A3%85/","excerpt":"","text":"emqx-安装概述EMQX 是一款开源 (opens new window)的大规模分布式 MQTT 消息服务器，功能丰富，专为物联网和实时通信应用而设计。EMQX 5.0 单集群支持 MQTT 并发连接数高达 1 亿条，单服务器的传输与处理吞吐量可达每秒百万级 MQTT 消息，并保证延迟在亚毫秒级。 环境centos7.9 emqx4.13 官方文档https://www.emqx.io/docs/zh/v4.3/ 安装12345678910## 下载仓库curl -s https://assets.emqx.com/scripts/install-emqx-rpm.sh | sudo bash## 安装指定版本yum list emqx --showduplicatesyum install -y emqx.x86_64-4.3.15## 开启启动和启动systemctl enable emqxsystemctl restart emqx 控制台和默认端口123http://10.77.114.178:18083/ admin/publicmqtt:1883mqtts:8883 ssl证书生成脚本12345678910111213141516171819202122232425262728293031323334353637383940#!/bin/shcat &lt;&lt; EOF &gt; openssl.cnf[req]default_bits = 2048distinguished_name = req_distinguished_namereq_extensions = req_extx509_extensions = v3_reqprompt = no[req_distinguished_name]countryName = CNstateOrProvinceName = ZhejianglocalityName = HangzhouorganizationName = EMQXcommonName = CA[req_ext]subjectAltName = @alt_names[v3_req]subjectAltName = @alt_names[alt_names]DNS.1 = *.abc.cnIP.2 = 120.224.237.21DNS.2 = 120.224.237.21IP.3 = 10.77.114.158DNS.3 = 10.77.114.158IP.4 = 10.77.114.178DNS.4 = 10.77.114.178EOFopenssl genrsa -out ca.key 2048openssl req -x509 -new -nodes -key ca.key -sha256 -days 3650 -out ca.pemopenssl genrsa -out emqx.key 2048openssl req -new -key ./emqx.key -config openssl.cnf -out emqx.csropenssl x509 -req -in ./emqx.csr -CA ca.pem -CAkey ca.key -CAcreateserial -out emqx.pem -days 3650 -sha256 -extensions v3_req -extfile openssl.cnfopenssl genrsa -out client.key 2048openssl req -new -key client.key -out client.csr -subj &quot;/C=CN/ST=Zhejiang/L=Hangzhou/O=EMQX/CN=client&quot;openssl x509 -req -days 3650 -in client.csr -CA ca.pem -CAkey ca.key -CAcreateserial -out client.pemmv ca.pem cacert.pemmv emqx.pem cert.pemmv emqx.key key.pem 证书配置1234567891011## 将生成的证书替换掉/etc/emqx下的同名证书listener.ssl.external.keyfile = /etc/emqx/certs/key.pemlistener.ssl.external.certfile = /etc/emqx/certs/cert.pem## 重启emqxsystemctl restart emqx## 客户端配置3个证书即可链接cacert.pemclient.pemclient.key","categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/tags/middleware/"}]},{"title":"Shell-输出多行","slug":"shell-cat输出多行","date":"2023-08-16T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/08/17/shell-cat输出多行/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/17/shell-cat%E8%BE%93%E5%87%BA%E5%A4%9A%E8%A1%8C/","excerpt":"","text":"Shell-输出多行并发执行12345678910cat &lt;&lt; EOF &gt; test.sh#!/bin/bash#you Shell script writes here.EOFcat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.confnet.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1net.bridge.bridge-nf-call-ip6tables = 1EOF","categories":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"}]},{"title":"Prometheus-安装配置","slug":"prometheus-安装配置","date":"2023-08-13T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/08/14/prometheus-安装配置/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/14/prometheus-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Prometheus-安装配置supervisor安装1yum install -y supervisor 各组件ini123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115cat &lt;&lt; EOF &gt; alertmanager.ini[program:alertmanager]command=/data/moni/alertmanager/alertmanager --web.listen-address=&quot;:9093&quot;directory=/data/moni/alertmanager ; directory to cwd to before exec (def no cwd)umask=022 ; umask for process (default None)priority=999 ; the relative start priority (default 999)autostart=true ; start at supervisord start (default: true)autorestart=true ; retstart at unexpected quit (default: true)startsecs=1 ; number of secs prog must stay running (def. 1)startretries=3 ; max # of serial start failures (default 3)exitcodes=0,2 ; &#x27;expected&#x27; exit codes for process (default 0,2)stopsignal=QUIT ; signal used to kill process (default TERM)stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10)user=root ; setuid to this UNIX account to run the programredirect_stderr=true ; redirect proc stderr to stdout (default false)stdout_logfile=/var/log/alertmanager/alertmanager.log ; stdout log path, NONE for none; default AUTOstdout_logfile_maxbytes=50MB ; max # logfile bytes b4 rotation (default 50MB)stdout_logfile_backups=10 ; # of stdout logfile backups (default 10)stdout_capture_maxbytes=1MB ; number of bytes in &#x27;capturemode&#x27; (default 0)stdout_events_enabled=false ; emit events on stdout writes (default false)environment=A=1,B=2 ; process environment additions (def no adds)EOFcat &lt;&lt; EOF &gt; consul.ini[program:consul]command=/data/moni/consul agent -dev -data-dir=/data/moni/consul-data -node=aws-base-01 -bind=10.77.114.153 -config-dir=/etc/consul.d -enable-script-checks=true -datacenter=hykj -ui -rejoin -client=0.0.0.0directory=/data/moni ; directory to cwd to before exec (def no cwd)umask=022 ; umask for process (default None)priority=999 ; the relative start priority (default 999)autostart=true ; start at supervisord start (default: true)autorestart=true ; retstart at unexpected quit (default: true)startsecs=1 ; number of secs prog must stay running (def. 1)startretries=3 ; max # of serial start failures (default 3)exitcodes=0,2 ; &#x27;expected&#x27; exit codes for process (default 0,2)stopsignal=QUIT ; signal used to kill process (default TERM)stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10)user=root ; setuid to this UNIX account to run the programredirect_stderr=true ; redirect proc stderr to stdout (default false)stdout_logfile=/var/log/consul/consul.log ; stdout log path, NONE for none; default AUTOstdout_logfile_maxbytes=50MB ; max # logfile bytes b4 rotation (default 50MB)stdout_logfile_backups=10 ; # of stdout logfile backups (default 10)stdout_capture_maxbytes=1MB ; number of bytes in &#x27;capturemode&#x27; (default 0)stdout_events_enabled=false ; emit events on stdout writes (default false)environment=A=1,B=2 ; process environment additions (def no adds)#serverurl=AUTO ; override serverurl computation (childutils)EOFcat &lt;&lt; EOF &gt; dingtalk.ini[program:dingtalk]command=/data/moni/dingtalk/dingtalk --config.file=config.yml --web.listen-address=&quot;:8860&quot;directory=/data/moni/dingtalk ; directory to cwd to before exec (def no cwd)umask=022 ; umask for process (default None)priority=999 ; the relative start priority (default 999)autostart=false ; start at supervisord start (default: true)autorestart=true ; retstart at unexpected quit (default: true)startsecs=1 ; number of secs prog must stay running (def. 1)startretries=3 ; max # of serial start failures (default 3)exitcodes=0,2 ; &#x27;expected&#x27; exit codes for process (default 0,2)stopsignal=QUIT ; signal used to kill process (default TERM)stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10)user=root ; setuid to this UNIX account to run the programredirect_stderr=true ; redirect proc stderr to stdout (default false)stdout_logfile=/var/log/dingtalk/dingtalk.log ; stdout log path, NONE for none; default AUTOstdout_logfile_maxbytes=50MB ; max # logfile bytes b4 rotation (default 50MB)stdout_logfile_backups=10 ; # of stdout logfile backups (default 10)stdout_capture_maxbytes=1MB ; number of bytes in &#x27;capturemode&#x27; (default 0)stdout_events_enabled=false ; emit events on stdout writes (default false)environment=A=1,B=2 ; process environment additions (def no adds)EOFcat &lt;&lt; EOF &gt; grafana.ini[program:grafana] command=/data/moni/grafana/bin/grafana-server -config /data/moni/grafana/conf/grafana.ini ; directory=/data/moni/grafana ; directory to cwd to before exec (def no cwd)umask=022 ; umask for process (default None)priority=999 ; the relative start priority (default 999)autostart=true ; start at supervisord start (default: true)autorestart=true ; retstart at unexpected quit (default: true)startsecs=1 ; number of secs prog must stay running (def. 1)startretries=3 ; max # of serial start failures (default 3)exitcodes=0,2 ; &#x27;expected&#x27; exit codes for process (default 0,2)stopsignal=QUIT ; signal used to kill process (default TERM)stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10)user=root ; setuid to this UNIX account to run the programredirect_stderr=true ; redirect proc stderr to stdout (default false)stdout_logfile=/var/log/grafana/grafana.log ; stdout log path, NONE for none; default AUTOstdout_logfile_maxbytes=50MB ; max # logfile bytes b4 rotation (default 50MB)stdout_logfile_backups=10 ; # of stdout logfile backups (default 10)stdout_capture_maxbytes=1MB ; number of bytes in &#x27;capturemode&#x27; (default 0)stdout_events_enabled=false ; emit events on stdout writes (default false)environment=A=1,B=2 ; process environment additions (def no adds)EOFcat &lt;&lt; EOF &gt; prometheus.ini[program:prometheus]command=/data/moni/prometheus/prometheus --storage.tsdb.retention.time=30d --storage.tsdb.path=&quot;/data/moni/prometheus/data&quot;directory=/data/moni/prometheus ; directory to cwd to before exec (def no cwd)umask=022 ; umask for process (default None)priority=999 ; the relative start priority (default 999)autostart=true ; start at supervisord start (default: true)autorestart=true ; retstart at unexpected quit (default: true)startsecs=1 ; number of secs prog must stay running (def. 1)startretries=3 ; max # of serial start failures (default 3)exitcodes=0,2 ; &#x27;expected&#x27; exit codes for process (default 0,2)stopsignal=QUIT ; signal used to kill process (default TERM)stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10)user=root ; setuid to this UNIX account to run the programredirect_stderr=true ; redirect proc stderr to stdout (default false)stdout_logfile=/var/log/prometheus/prometheus.log ; stdout log path, NONE for none; default AUTOstdout_logfile_maxbytes=50MB ; max # logfile bytes b4 rotation (default 50MB)stdout_logfile_backups=10 ; # of stdout logfile backups (default 10)stdout_capture_maxbytes=1MB ; number of bytes in &#x27;capturemode&#x27; (default 0)stdout_events_enabled=false ; emit events on stdout writes (default false)environment=A=1,B=2 ; process environment additions (def no adds)EOF supervisor启动12345678910mkdir -p /var/log/&#123;alertmanager,consul,prometheus,dingtalk,grafana&#125;mkdir -p /etc/consul.dcp *.ini /etc/supervisord.d/cp supervisord.conf /etcsystemctl enable supervisordsystemctl restart supervisordsleep 2supervisorctl status prometheus配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182global: scrape_interval: 15s evaluation_interval: 15s alerting: alertmanagers: - static_configs: - targets: - &quot;localhost:9093&quot;rule_files: - &quot;/data/moni/prometheus/rules/*&quot;scrape_configs: - job_name: &quot;prometheus&quot; static_configs: - targets: [&quot;localhost:9090&quot;] - job_name: &quot;alertmanager&quot; static_configs: - targets: [&quot;localhost:9093&quot;] - job_name: &quot;doris_job&quot; static_configs: - targets: [&#x27;hy-bigdata-01:18030&#x27;, &#x27;hy-bigdata-02:18030&#x27;, &#x27;hy-bigdata-03:18030&#x27;] labels: group: fe - targets: [&#x27;hy-bigdata-01:18040&#x27;, &#x27;hy-bigdata-02:18040&#x27;, &#x27;hy-bigdata-03:18040&#x27;] labels: group: be# - job_name: &quot;pushgateway&quot;# honor_labels: true# static_configs:# - targets: [&#x27;10.9.127.245:9091&#x27;]# labels:# instance: pushgateway # - job_name: &quot;java_jvm&quot;# static_configs:# - targets: [&#x27;10.9.127.245:8848&#x27;]# - job_name: &quot;java-jmx-monitor&quot;# static_configs:# - targets: [&#x27;10.249.2.51:3010&#x27;]## - job_name: &quot;davinci_monitor&quot;# metrics_path: /prometheus # static_configs: # - targets: [&#x27;10.249.2.50:14399&#x27;] - job_name: &#x27;consul_sd_node_exporter&#x27; metrics_path: /metrics honor_labels: false consul_sd_configs: - server: &#x27;localhost:8500&#x27; scheme: http services: [&#x27;node_exporter&#x27;] relabel_configs: #根据实际监控所需添加label，并在注册时注册 - source_labels: [&#x27;__meta_consul_bzl&#x27;] # datacenter，会显示注册到的consul的datacenter target_label: &#x27;bgy&#x27; - source_labels: [&#x27;__meta_consul_service_address&#x27;] target_label: &#x27;host&#x27; - source_labels: [&#x27;__meta_consul_service_metadata_hostname&#x27;] target_label: &#x27;hostname&#x27; - source_labels: [&#x27;__meta_consul_service_metadata_business&#x27;] target_label: &#x27;business&#x27; - job_name: &#x27;sa_process_exporter&#x27; scrape_interval: 10s honor_labels: false consul_sd_configs: - server: &#x27;localhost:8500&#x27; scheme: http services: [&#x27;process_exporter&#x27;] relabel_configs: - source_labels: [&#x27;__meta_consul_service_address&#x27;] target_label: &#x27;host&#x27; - source_labels: [&#x27;__meta_consul_service_metadata_hostname&#x27;] target_label: &#x27;hostname&#x27; 告警配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174groups:- name: defaultStatsAlert rules: - alert: cpuUsageAlert expr: (100 - (avg by (instance,hostname,hosttype,responsibility)(irate(node_cpu_seconds_total&#123;job=&quot;consul_sd_node_exporter&quot;,mode=&quot;idle&quot;&#125;[3m])) * 100)) &gt; 95 for: 10m labels: team: node organization: ops # labels:# severity: page annotations: summary: &quot;&#123;&#123; $labels.host &#125;&#125; CPU usgae high&quot; description: &quot;&#123;&#123; $labels.host &#125;&#125; CPU usage above 95% (current value: &#123;&#123; $value &#125;&#125;)&quot; - alert: cpuIOwaitAlert expr: (avg by (hostname,instance,hosttype,responsibility)(irate(node_cpu_seconds_total&#123;business=~&#x27;bzl|aws|hy&#x27;,job=&quot;consul_sd_node_exporter&quot;,mode=&quot;iowait&quot;&#125;[3m])) * 100) &gt; 45 for: 10m labels: team: node organization: ops annotations: summary: &quot;&#123;&#123; $labels.instance &#125;&#125; CPU iowait high&quot; description: &quot;&#123;&#123; $labels.host &#125;&#125; CPU iowait above 45% (current value: &#123;&#123; $value &#125;&#125;)&quot; - alert: sysLoadAlert expr: sum by(hostname, instance,business,hosttype,responsibility) (node_load5&#123;job=&quot;consul_sd_node_exporter&quot;&#125;) / count by(hostname, instance,business,hosttype,responsibility) (count by(cpu, hostname, instance,business,hosttype,responsibility) (node_cpu_seconds_total&#123;job=&quot;consul_sd_node_exporter&quot;&#125;)) &gt; 3.85 for: 10m labels: team: node organization: ops annotations: # summary: &quot;&#123;&#123; $labels.instance &#125;&#125; CPU usgae high&quot; #description: &quot;&#123;&#123; $labels.host &#125;&#125; CPU load1m is greater than cpu core number for 1min(current value: &#123;&#123; $value &#125;&#125;)&quot; description: &quot;&#123;&#123; $labels.host &#125;&#125; CPU load5m is greater than cpu core number(current value: cpu 核数的&#123;&#123; $value &#125;&#125;倍 )&quot; - alert: sys-time-Alert expr: time() - node_time_seconds&#123;job=&quot;consul_sd_node_exporter&quot;&#125; &gt; 125 for: 10m labels: team: node organization: ops annotations: description: &quot;&#123;&#123; $labels.host &#125;&#125; system time is inconsistent (current value: &#123;&#123; $value &#125;&#125;s)&quot; - alert: sys-time-Alert1 expr: time() - node_time_seconds&#123;job=&quot;consul_sd_node_exporter&quot;&#125; &lt; -125 for: 10m labels: team: node organization: ops annotations: description: &quot;&#123;&#123; $labels.host &#125;&#125; system time is inconsistent (current value: &#123;&#123; $value &#125;&#125;s)&quot; - alert: memUsageAlert #expr: ((node_memory_MemTotal_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125; - (node_memory_MemAvailable_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125;))/node_memory_MemTotal_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125;) * 100 &gt; 90 expr: ((node_memory_MemTotal_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125; - (node_memory_MemFree_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125;+node_memory_Buffers_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125;+node_memory_Cached_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125;+node_memory_SReclaimable_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125;))/node_memory_MemTotal_bytes&#123;job=&quot;consul_sd_node_exporter&quot;&#125;) * 100 &gt; 95 for: 15m labels: team: mem organization: ops# labels:# severity: page annotations: summary: &quot;&#123;&#123; $labels.host &#125;&#125; MEM usgae high&quot; description: &quot;&#123;&#123; $labels.host &#125;&#125; MEM usage above 95% (current value: &#123;&#123; $value &#125;&#125;)&quot; - alert: NodeDown expr: up&#123;job=&quot;consul_sd_node_exporter&quot;&#125; == 0 for: 5m labels: team: down organization: ops# labels: 可以使用这个label在altermanager中配置match分组# team: node annotations: description: &#x27;&#123;&#123; $labels.host&#125;&#125; has been down for 5m&#x27; - alert: disk_utilization_rate expr: 100 - ((node_filesystem_avail_bytes&#123;business=~&#x27;bzl|aws|hy&#x27;,fstype!~&quot;rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs|fuse.lxcfs|iso9660&quot;,mountpoint!~&quot;/boot&quot;,job=&quot;consul_sd_node_exporter&quot;&#125; * 100) / node_filesystem_size_bytes &#123;business=~&#x27;bzl|aws|hy&#x27;,fstype!~&quot;rootfs|selinuxfs|autofs|rpc_pipefs|tmpfs|fuse.lxcfs|iso9660&quot;,mountpoint!~&quot;/boot&quot;,job=&quot;consul_sd_node_exporter&quot;&#125;) &gt; 80 for: 10m labels: team: disk organization: ops annotations: description: &#x27;&#123;&#123;$labels.host&#125;&#125; &#123;&#123;$labels.mountpoint&#125;&#125; excess 90% --&gt; &#123;&#123;$value&#125;&#125;&#x27; - alert: network_receive_bytes expr: irate(node_network_receive_bytes_total&#123;business=~&#x27;bzl|aws|hy&#x27;,device!~&#x27;tap.*|veth.*|br.*|docker.*|virbr*|lo*|eth*|eno*&#x27;,job=&quot;consul_sd_node_exporter&quot;&#125;[15m])*8/1024/1024 &gt; 1000 for: 5m labels: team: node organization: ops annotations: description: &#x27;&#123;&#123;$labels.host&#125;&#125; network receive bytes reach to &#123;&#123;$value&#125;&#125; MB/s&#x27; - alert: network_transmit_bytes expr: irate(node_network_transmit_bytes_total&#123;business=~&#x27;bzl|aws|hy&#x27;,device!~&#x27;tap.*|veth.*|br.*|docker.*|virbr*|lo*|eth*|eno*&#x27;,job=&quot;consul_sd_node_exporter&quot;&#125;[15m])*8/1024/1024 &gt; 1000 for: 5m labels: team: node organization: ops annotations: description: &#x27;&#123;&#123;$labels.host&#125;&#125; network transmit bytes reach to &#123;&#123;$value&#125;&#125; MB/s&#x27; - alert: frame-alert expr: node_network_receive_frame_total&#123;device!~&quot;tap.*|veth.*|br.*|docker.*|virbr*|lo*&quot;&#125; - min_over_time(node_network_receive_frame_total&#123;device!~&quot;tap.*|veth.*|br.*|docker.*|virbr*|lo*&quot;&#125;[1h]) &gt;= 5 for: 10s labels: team: node organization: ops annotations: description: &#x27;&#123;&#123;$labels.host&#125;&#125; network frame growth &#123;&#123;$value&#125;&#125;&#x27; - alert: time_zone-alert expr: time_zone&#123;tz!=&quot;CST&quot;&#125; == 0 for: 10s labels: team: node organization: ops annotations: description: &#x27;&#123;&#123;$labels.host&#125;&#125; time zone is not CST&#x27;# - alert: doris_node-alert# expr: sum(up&#123;job=~&quot;doris_job|davinci_monitor&quot;&#125;) by (group,job,instance) &lt; 1# for: 10s# labels:# team: node# organization: bigdata# annotations:# description: &#x27;&#123;&#123;$labels.job&#125;&#125; &#123;&#123;$labels.group&#125;&#125; 的节点&#123;&#123;$labels.instance&#125;&#125; 发生异常!!!!&#x27;groups: - name: rocketmq-delay rules: - alert: rocketmq-delay warning1 expr: rocketmq_group_diff&#123;topic=&quot;machine_work_log&quot;,group=&quot;machine_work_log_roketmq2doris&quot;&#125; &gt;2000 for: 20s labels: group: bigdata severity: bigdata annotations: description: Topic：&#123;&#123;$labels.topic&#125;&#125; , Group：&#123;&#123;$labels.group&#125;&#125; 出现积压，积压量为：&#123;&#123;$value&#125;&#125; - alert: rocketmq-delay warning2 expr: rocketmq_group_diff&#123;topic=&quot;pro_canal_producer&quot;,group=&quot;pro_canal_producer_roketmq2doris&quot;&#125; &gt;10 for: 20s labels: group: bigdata severity: bigdata annotations: description: Topic：&#123;&#123;$labels.topic&#125;&#125; , Group：&#123;&#123;$labels.group&#125;&#125; 出现积压，积压量为：&#123;&#123;$value&#125;&#125;groups: - name: doris_instance_down rules: - alert: Doris Backends Down expr: up &#123;group=&quot;be&quot;, job=&quot;doris_job&quot;&#125; == 0 for: 20s labels: user: doris severity: bigdata annotations: summary: &quot;doris Instance &#123;&#123; $labels.instance &#125;&#125; down&quot; description: &quot;doris &#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; has been down for more than 20s.&quot; - alert: Doris Frontends Down expr: up &#123;group=&quot;fe&quot;, job=&quot;doris_job&quot;&#125; == 0 for: 20s labels: user: doris severity: bigdata annotations: summary: &quot;doris Instance &#123;&#123; $labels.instance &#125;&#125; down&quot; description: &quot;doris &#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; has been down for more than 20s.&quot; alertmanage配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152global: resolve_timeout: 5m #处理超时时间，默认为5min smtp_smarthost: &#x27;smtp.139.com:465&#x27; # 邮箱smtp服务器代理 smtp_from: &#x27;xxxxxx@139.com&#x27; # 发送邮箱名称 smtp_auth_username: &#x27;xxxxx@139.com&#x27; # 邮箱名称 smtp_auth_password: &#x27;xxxxxxxxx&#x27; # 邮箱密码或授权码 smtp_require_tls: false# 定义模板信心templates: - &#x27;/opt/alertmanager/templates/*&#x27;# 定义路由树信息route: receiver: &#x27;ops&#x27; # 发送警报的接收者的名称，以下receivers name的名称 group_by: [&#x27;alertname&#x27;] # 报警分组依据 group_wait: 1s # 最初即第一次等待多久时间发送一组警报的通知 group_interval: 10s # 在发送新警报前的等待时间 repeat_interval: 1h # 发送重复警报的周期 对于email配置中，此项不可以设置过低，否则将会由于邮件发送太多频繁，被smtp服务器拒绝 routes: - receiver: &#x27;bigdata&#x27; group_wait: 10s match_re: severity: bigdata # 定义警报接收者信息receivers: - name: &#x27;ops&#x27; # 警报# email_configs: # 邮箱配置# - to: &#x27;chenyuhua37@countrygarden.com.cn,luminfeng01@countrygarden.com.cn,liangwenjun04@countrygarden.com.cn,maiqixian@countrygarden.com.cn,15121486557@163.com&#x27; # 接收警报的email配置# send_resolved: true# headers:# subject: &quot;AWS-Prometheus报警邮件&quot;# from : &quot;Prometheus监控告警&quot;# to: &quot;You,Please pay attention!!!&quot; webhook_configs: - url: &#x27;http://localhost:8860/dingtalk/webhook1/send&#x27; send_resolved: true - name: &#x27;bigdata&#x27; webhook_configs:# - url: &#x27;http://localhost:18060/dingtalk/webhook_bigdata/send&#x27; - url: &#x27;http://localhost:8860/dingtalk/webhook1/send&#x27; send_resolved: true# 一个inhibition规则是在与另一组匹配器匹配的警报存在的条件下，使匹配一组匹配器的警报失效的规则。两个警报必须具有一组相同的标签。 inhibit_rules: - source_match: severity: &#x27;critical&#x27; target_match: severity: &#x27;warning&#x27; equal: [&#x27;alertname&#x27;, &#x27;dev&#x27;, &#x27;instance&#x27;] 钉钉配置123456789101112131415templates: - dingding.tmpltargets: webhook1: url: https://oapi.dingtalk.com/robot/send?access_token=8cd8f7502c148fa63a7ad9e424731f83022841eab80c81d476e8000f36d5143a # secret for signature secret: SEC000000000000000000000 webhook2: url: https://oapi.dingtalk.com/robot/send?access_token=8cd8f7502c148fa63a7ad9e424731f83022841eab80c81d476e8000f36d5143a webhook_legacy: url: https://oapi.dingtalk.com/robot/send?access_token=8cd8f7502c148fa63a7ad9e424731f83022841eab80c81d476e8000f36d5143a bigdta_webhook: url: https://oapi.dingtalk.com/robot/send?access_token=8cd8f7502c148fa63a7ad9e424731f83022841eab80c81d476e8000f36d5143a","categories":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"https://biglovewheat.gihub.io/tags/prometheus/"}]},{"title":"Linux-Centos7-升级内核","slug":"linux-centos7-升级内核","date":"2023-08-06T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/08/07/linux-centos7-升级内核/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/07/linux-centos7-%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8/","excerpt":"","text":"Linux-Centos7-升级内核12345678910111213141516171819## 查看当前内核uname -r## 安装epel仓库yum install https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm -y## 安装最新长期支持内核yum --enablerepo=elrepo-kernel install kernel-lt-devel kernel-lt -y## 设置默认启动内核awk -F\\&#x27; &#x27;$1==&quot;menuentry &quot; &#123;print i++ &quot; &quot;$2&#125;&#x27; /etc/grub2.cfggrub2-set-default 0grub2-mkconfig -o /boot/grub2/grub.cfg## 重启操作系统reboot## 再次查看内核uname -r","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Linux-sed替换","slug":"linux-sed替换","date":"2023-08-06T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/08/07/linux-sed替换/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/07/linux-sed%E6%9B%BF%E6%8D%A2/","excerpt":"","text":"Linux-sed替换使用竖线方式替换包含特殊字符的文本12sed -i &#x27;s|161.189.150.102:9876|mq.farmbgy.net:9876|g&#x27; *sed -i &#x27;s|172.31.40.27:9876|mq.farmbgy.net:9876|g&#x27; *","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Keepalived-出现双ip问题","slug":"lvs-keepalived-出现双ip问题","date":"2023-08-06T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/08/07/lvs-keepalived-出现双ip问题/","link":"","permalink":"https://biglovewheat.gihub.io/2023/08/07/lvs-keepalived-%E5%87%BA%E7%8E%B0%E5%8F%8Cip%E9%97%AE%E9%A2%98/","excerpt":"","text":"Keepalived-出现双ip问题问题可能是上联交换机禁用了arp的广播限制，造成keepalive无法通过广播通信，两台服务器抢占vip，出现同时都有vip的情况 解决过程123456789## 主机，发现向224.0.0.18发送消息tcpdump -i eth0 vrrp -n## 备机，也在向224.0.0.18发送消息，正常情况下，备节点如果收到主节点的心跳消息时，优先级高于自己，就不会主动对外发送消息tcpdump -i eth0 vrrp -n## 原因：上联交换机禁用了arp的广播限制，造成keepalive无法通过广播通信，两台服务器抢占vip，出现同时都有vip的情况## 解决办法：多播改为单播，重启keepalived 主机配置12345678910111213141516171819202122232425! Configuration File for keepalivedglobal_defs &#123; router_id NGINX &#125;vrrp_instance VI_1 &#123; state MASTER interface eth0 virtual_router_id 17#多播 mcast_src_ip 10.77.114.150 unicast_src_ip 10.77.114.150 unicast_peer &#123; 10.77.114.151 #指向对方主机IP 如果有多个keepalived,再下面加其它节点的IP &#125; priority 150 advert_int 1 authentication &#123; auth_type PASS auth_pass hykj &#125; virtual_ipaddress &#123; 10.77.114.130 &#125;&#125; 备机配置12345678910111213141516171819202122232425! Configuration File for keepalivedglobal_defs &#123; router_id NGINX &#125;vrrp_instance VI_1 &#123; state BACKUP interface eth0 virtual_router_id 17#多播 mcast_src_ip 10.77.114.151 unicast_src_ip 10.77.114.151 unicast_peer &#123; 10.77.114.150 &#125; priority 99 advert_int 1 authentication &#123; auth_type PASS auth_pass hykj &#125; virtual_ipaddress &#123; 10.77.114.130 &#125;&#125; keepalived 安装1yum install -y keepalived","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"GitLab-修改IP","slug":"gitlab-修改IP","date":"2023-06-27T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/06/28/gitlab-修改IP/","link":"","permalink":"https://biglovewheat.gihub.io/2023/06/28/gitlab-%E4%BF%AE%E6%94%B9IP/","excerpt":"","text":"GitLab-修改IP机器IP变了，需要重新修改IP 操作步骤1234567891011## 停止gitlabgitlab-ctl stopvi /etc/gitlab/gitlab.rb## 修改为正确的IP、域名、或端口 ##external_url &#x27;http://10.77.114.100:8690&#x27;nginx[&#x27;listen_port&#x27;] = 8690## 重新配置并启动gitlabgitlab-ctl reconfiguregitlab-ctl start","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"git","slug":"git","permalink":"https://biglovewheat.gihub.io/tags/git/"}]},{"title":"GitLab-初始化root密码","slug":"gitlab-初始化root密码","date":"2023-06-27T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/06/28/gitlab-初始化root密码/","link":"","permalink":"https://biglovewheat.gihub.io/2023/06/28/gitlab-%E5%88%9D%E5%A7%8B%E5%8C%96root%E5%AF%86%E7%A0%81/","excerpt":"","text":"GitLab-初始化root密码忘记gitlab root密码，但能登录gitlab主机，可以通过此方法更改root密码 适用版本13.* &#x2F; 14.* 操作步骤12345678910111213cd /opt/gitlab/bingitlab-rails consoleu=User.where(id:1).first=&gt; #&lt;User id:1 @root&gt;u.password=&#x27;12345678&#x27;=&gt; &quot;12345678&quot;u.password_confirmation=&#x27;12345678&#x27;=&gt; &quot;12345678&quot;u.save!exit## 修改完后重启动即可","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"git","slug":"git","permalink":"https://biglovewheat.gihub.io/tags/git/"}]},{"title":"centos7-安装python3.10","slug":"centos7-安装python3.10","date":"2023-06-12T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2023/06/13/centos7-安装python3.10/","link":"","permalink":"https://biglovewheat.gihub.io/2023/06/13/centos7-%E5%AE%89%E8%A3%85python3.10/","excerpt":"","text":"centos7-安装python3.10遇到问题1WARNING: pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. 问题分析12由于python3.10之后版本不在支持libressl使用ssl，需要使用openssl安装来解决编译安装python时候遇到的ssl模块导入失败的问题，这里需要用的openssl1.1.1版本或者更高版本 安装步骤1234567891011121314151617181920## 安装opensslwget https://www.openssl.org/source/openssl-1.1.1t.tar.gz --no-check-certificate./config --prefix=/usr/local/openssl-1.1.1tmake &amp;&amp; make install## 安装pythonwget https://registry.npmmirror.com/-/binary/python/3.10.11/Python-3.10.11.tgz./configure --prefix=/usr/local/python3 --with-openssl=/usr/local/openssl-1.1.1tmake &amp;&amp; make installln -sf /usr/local/python3/bin/python3 /usr/bin/python3ln -sf /usr/local/python3/bin/pip3 /usr/bin/pip3## 升级pippython3 -m pip install --upgrade pip## 验证python3 -VPython 3.10.11pip3 -Vpip 23.1.2 from /usr/local/python3/lib/python3.10/site-packages/pip (python 3.10)","categories":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"}]},{"title":"confluence-手动备份恢复","slug":"confluence-手动备份恢复","date":"2023-06-12T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2023/06/13/confluence-手动备份恢复/","link":"","permalink":"https://biglovewheat.gihub.io/2023/06/13/confluence-%E6%89%8B%E5%8A%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/","excerpt":"","text":"confluence-手动备份恢复说明confluence常规备份恢复的方法是通过控制台，站点管理，每日备份管理，由系统自动完成，只需备份备份目录下文件即可。 在某种情况下（比如没有管理员账号，或自动备份失败），可使用拷贝整个confluence文件夹，备份数据库的方式进行备份恢复，下面的例子采用此方法。 环境和版本12confluence 7.6.1mysql 8 数据库恢复123456789101112131415161718192021## rpm安装mysql8，安装完成后先不要启动## /etc/my.cnf加入如下参数symbolic-links=0log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pidmax_allowed_packet = 34Mtransaction-isolation=READ-COMMITTEDinnodb_default_row_format=DYNAMICinnodb_log_file_size=2Gcharacter_set_server=utf8mb4default-storage-engine=INNODB### 这里先检查备份出来的sql文件，表名是大写还是小写，如果是小写，需要加lower_case_table_names=1### 此参数mysql中，只能在初始化中修改，详细可搜索此参数含义和用法lower_case_table_names=1## 启动mysql## 创建数据库### 这里需注意的是，原本数据库的字符集是utf8md4还是uff8，在备份出来的sql文件中，可以找到建表语句确认CREATE SCHEMA confluence DEFAULT CHARACTER SET utf8 COLLATE utf8_bin ;## 将备份sql导入，正常情况应该有160个表### 如数量不对或者报错，可以打开备份出来的sql文件，单独处理 文件恢复12345## 默认安装confluence，默认程序位置/opt，默认用户数据/var## 解压并替换程序目录/opt下## 解压并替换用户数据目录/var下## 创建agent目录，把agent.jar放到目录下（pojie文件）## 修改配置文件里的数据库链接信息 confluence.cfg.xml 后续1## 启动confluence，如不能启动，查看日志输出 破解admin密码123456789select u.id, u.user_name, u.active from cwd_user ujoin cwd_membership m on u.id=m.child_user_id join cwd_group g on m.parent_id=g.id join cwd_directory d on d.id=g.directory_idwhere g.group_name = &#x27;confluence-administrators&#x27; and d.directory_name=&#x27;Confluence Internal Directory&#x27;;update cwd_user set credential =&#x27;x61Ey612Kl2gpFL56FT9weDnpSo4AV8j8+qx2AuTHdRyY036xxzTTrw10Wq3+4qQyB+XURPWx1ONxp3Y3pB37A==&#x27;where id=上一条sql查出来的ID;--update后admin密码是admin 完","categories":[{"name":"备份恢复","slug":"备份恢复","permalink":"https://biglovewheat.gihub.io/categories/%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/"}],"tags":[{"name":"备份恢复","slug":"备份恢复","permalink":"https://biglovewheat.gihub.io/tags/%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/"}]},{"title":"mysql-mysqldump-报错","slug":"mysql-mysqldump-报错","date":"2023-06-12T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/06/13/mysql-mysqldump-报错/","link":"","permalink":"https://biglovewheat.gihub.io/2023/06/13/mysql-mysqldump-%E6%8A%A5%E9%94%99/","excerpt":"","text":"Mysql-mysqldump-报错版本12mysql 5.7.31+mysql 8.0.21+ 报错1mysqldump: Error: &#x27;Access denied; you need (at least one of) the PROCESS privilege(s) for this operation&#x27; when trying to dump tablespaces 错误分析12345678The last PROCESS privilege is new as of MySQL 5.7.31 and MySQL 8.0.21 and may be the root source of your problem. You can solve the mysqldump process privilege error in two ways:1.Updating the privileges for your database user. 赋权2.Runing mysqldump with the --no-tablespaces option.加上--no-tablespaces选项 解决办法123GRANT PROCESS ON *.* TO user@localhost;## ormysqldump -u abc db1 -p -C --no-tablespaces |gzip &gt; db1.sql.gz","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"SonarQube-代码检测工具安装","slug":"sonarqube-代码检测工具安装","date":"2023-05-29T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/05/30/sonarqube-代码检测工具安装/","link":"","permalink":"https://biglovewheat.gihub.io/2023/05/30/sonarqube-%E4%BB%A3%E7%A0%81%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85/","excerpt":"","text":"SonarQube-代码检测工具安装简介SonarQube是一个代码质量和安全分析工具，支持java、python、go、c等30+种语言。SonarQube is a self-managed, automatic code review tool that systematically helps you deliver clean code. As a core element of our Sonar solution, SonarQube integrates into your existing workflow and detects issues in your code to help you perform continuous code inspections of your projects. The tool analyses 30+ different programming languages and integrates into your CI pipeline and DevOps platform to ensure that your code meets high-quality standards. 安装配置下载链接：https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-9.9.1.69595.zip安装文档：https://docs.sonarqube.org/latest/try-out-sonarqube/ 需要java17支持，先安装java17 123456789101112## 下载安装包wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-9.9.1.69595.zip## 解压unzip sonarqube-9.9.1.69595.zip## 修改默认web端口vim conf/sonar.propertiessonar.web.port=39000## 默认使用h2本地数据库，可以配置采用外部数据库，支持mysql、pg、oracle 启动和登录123#!/bin/shsu - sonarqube -c &quot;java -version;/data/sonarqube-9.9.1.69595/bin/linux-x86-64/sonar.sh console&quot; 启动后登录，默认密码admin&#x2F;admin 新建gitlab-porject 选择分析的方式目前支持jenkins&#x2F;gitlab-ci等，这里采用最简单的本地分析 本地运行分析1234567## 在代码下载到本地，并运行此命令即可（这里用的mvn的java项目）mvn clean verify sonar:sonar \\ -Dsonar.projectKey=jenkins_test0627_AYhHS6JcYC282dGxCGTK \\ -Dsonar.host.url=http://hxkj07:39000 \\ -Dsonar.login=sqp_230323b5e2ba00a211b48cf5d857ba45287ef667 返回页面查看结果页面可以看到项目的疑似bug，安全漏洞等，点击可以定位到具体代码 后续配置使用外部数据库（略） 配置持续集成工具jenkins或gitlab-ci（略）","categories":[{"name":"测试","slug":"测试","permalink":"https://biglovewheat.gihub.io/categories/%E6%B5%8B%E8%AF%95/"}],"tags":[{"name":"测试","slug":"测试","permalink":"https://biglovewheat.gihub.io/tags/%E6%B5%8B%E8%AF%95/"}]},{"title":"Vscode-Python-Venv设置","slug":"vscode-python-venv设置","date":"2023-05-29T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/05/30/vscode-python-venv设置/","link":"","permalink":"https://biglovewheat.gihub.io/2023/05/30/vscode-python-venv%E8%AE%BE%E7%BD%AE/","excerpt":"","text":"vscode-python-venv设置 windows10&#x2F;vscode&#x2F;python 安装python下载python安装包，右击以管理员运行，记得选添加到path pip install virtualenv 安装vscode安装vscode 安装python插件 Ctrl+Shift+P 输入 python interpreter 选择python.exe Ctrl+Shift+P 输入 python create environment 选择venv 创建并激活虚拟环境12python -m venv myproject\\envmyproject\\Scripts\\activate done","categories":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"}]},{"title":"Doris-Datax数据备份与恢复","slug":"doris-datax数据备份和恢复","date":"2023-05-03T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2023/05/04/doris-datax数据备份和恢复/","link":"","permalink":"https://biglovewheat.gihub.io/2023/05/04/doris-datax%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D/","excerpt":"","text":"Doris-Datax数据备份与恢复datax下载https://github.com/alibaba/DataX 下载最新版本，本测试使用202303版本 https://datax-opensource.oss-cn-hangzhou.aliyuncs.com/202303/datax.tar.gz datax使用方法1python2 datax.py aaa.json Doris测试数据创建1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253--创建数据库create database test1;--创建测试表,以data_partition作为分区字段，并启用动态分区CREATE TABLE if not exists test1.test_work_log (message_deviceId varchar(64) NULL ,message_taskId varchar(32) NULL ,date_partition int(11) NULL COMMENT &quot;时间分区&quot;,message_txt string NULL ) ENGINE=OLAPUNIQUE KEY(message_deviceId,message_taskId, date_partition)PARTITION BY RANGE(date_partition)(PARTITION p_other VALUES LESS THAN (&quot;1&quot;),PARTITION p_history_20220714 VALUES LESS THAN (&quot;20220714&quot;),PARTITION p20230501 VALUES [(&quot;20230501&quot;), (&quot;20230502&quot;)),PARTITION p20230502 VALUES [(&quot;20230502&quot;), (&quot;20230503&quot;)),PARTITION p20230503 VALUES [(&quot;20230503&quot;), (&quot;20230504&quot;)),PARTITION p20230504 VALUES [(&quot;20230504&quot;), (&quot;20230505&quot;)),PARTITION p20230505 VALUES [(&quot;20230505&quot;), (&quot;20230506&quot;)),PARTITION p20230506 VALUES [(&quot;20230506&quot;), (&quot;20230507&quot;)))DISTRIBUTED BY HASH( message_deviceId,message_taskId) BUCKETS 16PROPERTIES (&quot;replication_num&quot; = &quot;1&quot;,&quot;dynamic_partition.enable&quot; = &quot;true&quot;,&quot;dynamic_partition.time_unit&quot; = &quot;DAY&quot;,&quot;dynamic_partition.time_zone&quot; = &quot;Asia/Shanghai&quot;,&quot;dynamic_partition.start&quot; = &quot;-2147483648&quot;,&quot;dynamic_partition.end&quot; = &quot;3&quot;,&quot;dynamic_partition.prefix&quot; = &quot;p&quot;,&quot;dynamic_partition.replication_allocation&quot; = &quot;tag.location.default: 3&quot;,&quot;dynamic_partition.buckets&quot; = &quot;16&quot;,&quot;dynamic_partition.create_history_partition&quot; = &quot;true&quot;,&quot;dynamic_partition.history_partition_num&quot; = &quot;36&quot;,&quot;dynamic_partition.hot_partition_num&quot; = &quot;0&quot;,&quot;dynamic_partition.reserved_history_periods&quot; = &quot;NULL&quot;,&quot;in_memory&quot; = &quot;false&quot;,&quot;storage_format&quot; = &quot;V2&quot;);--插入测试数据insert into test1.test_work_log VALUES (&#x27;1&#x27;,&#x27;2&#x27;,-1,&#x27;aaa&#x27;);insert into test1.test_work_log VALUES (&#x27;2&#x27;,&#x27;1&#x27;,20230504,&#x27;aaa&#x27;);insert into test1.test_work_log VALUES (&#x27;3&#x27;,&#x27;1&#x27;,20230505,&#x27;bbb&#x27;);--查看所有数据select * from test1.test_work_log;--查看分区情况show partitions from test1.test_work_log;--查看某分区数据select * from test1.test_work_log PARTITION p20230504; 报错1234567891011121314152023-05-04 14:27:08.179 [main] ERROR Engine - 经DataX智能分析,该任务最可能的错误原因是:com.alibaba.datax.common.exception.DataXException: Code:[Common-00], Describe:[您提供的配置文件存在错误信息，请检查您的作业配置 .] - 配置信息错误. 您提供的配置信息不是合法的JSON格式: syntax error, string . 请按照标准json格式提供配置信息. at com.alibaba.datax.common.exception.DataXException.asDataXException(DataXException.java:26) at com.alibaba.datax.common.util.Configuration.&lt;init&gt;(Configuration.java:1066) at com.alibaba.datax.common.util.Configuration.from(Configuration.java:79) at com.alibaba.datax.core.util.ConfigParser.parseJobConfig(ConfigParser.java:75) at com.alibaba.datax.core.util.ConfigParser.parse(ConfigParser.java:26) at com.alibaba.datax.core.Engine.entry(Engine.java:137) at com.alibaba.datax.core.Engine.main(Engine.java:204)## 解决办法find /home/mqxdata/datax/plugin/reader -type f -name &quot;._*er&quot; |xargs rm -f find /home/mqxdata/datax/plugin/writer -type f -name &quot;._*er&quot; |xargs rm -f doris导出到csv1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;job&quot;: &#123; &quot;content&quot;: [&#123; &quot;reader&quot;: &#123; &quot;name&quot;: &quot;mysqlreader&quot;, &quot;parameter&quot;: &#123; &quot;username&quot;: &quot;root&quot;, &quot;password&quot;: &quot;root&quot;, &quot;connection&quot;: [ &#123; &quot;querySql&quot;: [ &quot;SELECT * from test1.test_work_log where date_partition=20230504;&quot; ], &quot;jdbcUrl&quot;: [ &quot;jdbc:mysql://hxkj07:19030/test1&quot; ] &#125; ] &#125; &#125;, &quot;writer&quot;: &#123; &quot;name&quot;: &quot;txtfilewriter&quot;, &quot;parameter&quot;: &#123; &quot;path&quot;: &quot;./&quot;, &quot;fileName&quot;: &quot;test_work_log.csv.gz&quot;, &quot;writeMode&quot;: &quot;append&quot;, &quot;dateFormat&quot;: &quot;yyyy-MM-dd&quot;, &quot;fileFormat&quot;: &quot;csv&quot;, &#125; &#125; &#125;], &quot;setting&quot;: &#123; &quot;speed&quot;: &#123; &quot;channel&quot;: &quot;1&quot; &#125; &#125; &#125;&#125; 导出效果123cat test_work_log.csv.gz__ca303326_6445_4443_9e17_6c973ca5efa4 2,1,20230504,aaa csv导入到doris123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&#123; &quot;job&quot;: &#123; &quot;content&quot;: [&#123; &quot;reader&quot;: &#123; &quot;name&quot;: &quot;txtfilereader&quot;, &quot;parameter&quot;: &#123; &quot;path&quot;: [&quot;./&quot;], &quot;encoding&quot;: &quot;UTF-8&quot;, &quot;column&quot;: [ &#123; &quot;index&quot;: 0, &quot;type&quot;: &quot;String&quot; &#125;, &#123; &quot;index&quot;: 1, &quot;type&quot;: &quot;String&quot; &#125;, &#123; &quot;index&quot;: 2, &quot;type&quot;: &quot;long&quot; &#125;, &#123; &quot;index&quot;: 3, &quot;type&quot;: &quot;string&quot; &#125; ], &quot;fieldDelimiter&quot;: &quot;,&quot; &#125; &#125;, &quot;writer&quot;: &#123; &quot;name&quot;: &quot;doriswriter&quot;, &quot;parameter&quot;: &#123; &quot;loadUrl&quot;: [&quot;hxkj07:18030&quot;], &quot;loadProps&quot;: &#123; &#125;, &quot;column&quot;: [&quot;message_deviceId&quot;, &quot;message_taskId&quot;, &quot;date_partition&quot;,&quot;message_txt&quot;], &quot;username&quot;: &quot;root&quot;, &quot;password&quot;: &quot;root&quot;, &quot;postSql&quot;: [], &quot;preSql&quot;: [], &quot;flushInterval&quot;:30000, &quot;connection&quot;: [ &#123; &quot;jdbcUrl&quot;: &quot;jdbc:mysql://hxkj07:19030/test1&quot;, &quot;selectedDatabase&quot;: &quot;test1&quot;, &quot;table&quot;: [&quot;test_work_log&quot;] &#125; ], &quot;loadProps&quot;: &#123; &quot;format&quot;: &quot;json&quot;, &quot;strip_outer_array&quot;: true &#125; &#125; &#125; &#125;], &quot;setting&quot;: &#123; &quot;speed&quot;: &#123; &quot;channel&quot;: &quot;1&quot; &#125; &#125; &#125;&#125; 导入效果修改csv，把aaa改成new，再导入 生产环境配置(doris–&gt;hdfs)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&#123; &quot;job&quot;: &#123; &quot;content&quot;: [&#123; &quot;reader&quot;: &#123; &quot;name&quot;: &quot;mysqlreader&quot;, &quot;parameter&quot;: &#123; &quot;username&quot;: &quot;root&quot;, &quot;password&quot;: &quot;xxx&quot;, &quot;connection&quot;: [ &#123; &quot;querySql&quot;: [ &quot;SELECT message_deviceId,message_taskId,message_generateTime,date_partition,message_realSpeed,message_driverMode,message_reportTime,message_taskIndex,message_curPathNum,message_impleWorkState,message_chassisType,message_chassisInfo_chassisType,message_chassisInfo_engineSpeed,message_chassisInfo_fuelOilLevel,message_chassisInfo_remainFuel,message_chassisInfo_engineInstantaneousFuelEconomy,message_chassisInfo_ptoGearSta,message_chassisInfo_ptoRotationRate,message_chassisInfo_upgradeSysSta,message_chassisInfo_hydraulicOilLevel,message_chassisInfo_hydraulicOilTemp,message_chassisInfo_hydraulicOilPressure,message_chassisInfo_engOilTemp,message_chassisInfo_grainTankWeightKg,message_chassisInfo_grainTankFullSts,message_chassisInfo_unloadClutchSts,message_chassisInfo_grainUnloadTubLvl,message_chassisInfo_oilPressure,message_chassisInfo_coolantTemperature,message_chassisInfo_realOil,message_chassisInfo_remainingOil,message_chassisInfo_currentWheelAngle,message_chassisInfo_steerMotorState,message_chassisInfo_remainingOilPercent,message_chassisInfo_threePointPromote,message_chassisInfo_tillingDepthFb,message_positionInfo_yaw,message_positionInfo_rtkStatus,message_positionInfo_pitchAngle,message_positionInfo_rollAngle,message_positionInfo_position_longitude,message_positionInfo_position_latitude,message_positionInfo_xyPosition_longitude,message_positionInfo_xyPosition_latitude,message_positionInfo_xyImpl_longitude,message_positionInfo_xyImpl_latitude,message_positionInfo_gnssNum,message_positionInfo_networkSignal,message_controlTaskInfo_fieldId,message_controlTaskInfo_fieldName,message_controlTaskInfo_fieldCode,message_controlTaskInfo_typeName,message_controlTaskInfo_totalArea,message_controlTaskInfo_operatedArea,message_controlTaskInfo_noOperateArea,message_controlTaskInfo_totalUsedTime,message_controlTaskInfo_percent,message_controlTaskInfo_widthOfCloth,message_controlTaskInfo_totalMileage,message_controlTaskInfo_operatedMileage,message_controlTaskInfo_noOperatedMileage,message_controlTaskInfo_speedPerHour,message_controlTaskInfo_operatedOffset,message_controlTaskInfo_operatedOffsetDirection,message_controlTaskInfo_needLastTime,message_controlTaskInfo_machineName,message_controlTaskInfo_implementName,message_controlTaskInfo_startTime,message_controlTaskInfo_operateStatus,message_controlTaskInfo_segmentPercent,message_statusInfo_deviceId,message_statusInfo_taskId,message_statusInfo_connected,message_statusInfo_ready,message_statusInfo_canTask,message_statusInfo_status,gis_farmcode,gis_farmlandcode,message_gsmStatusInfo_signalRssi,message_gsmStatusInfo_optGsm,message_gsmStatusInfo_networkType,message_gsmStatusInfo_simNumber,message_gsmStatusInfo_cardStatus,gis_is_exception FROM hx_farm_sit.ods_machine_work_log_uq where date_partition=20230503;&quot; ], &quot;jdbcUrl&quot;: [ &quot;jdbc:mysql://bigdata01:9030/hx_farm_sit&quot; ] &#125; ] &#125; &#125;, &quot;writer&quot;: &#123; &quot;name&quot;: &quot;hdfswriter&quot;, &quot;parameter&quot;: &#123; &quot;column&quot;: [ &#123;&quot;name&quot;: &quot;message_deviceId&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_taskId&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_generateTime&quot;,&quot;type&quot;: &quot;bigint&quot;&#125;,&#123;&quot;name&quot;: &quot;date_partition&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_realSpeed&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_driverMode&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_reportTime&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_taskIndex&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_curPathNum&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_impleWorkState&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisType&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_chassisType&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_engineSpeed&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_fuelOilLevel&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_remainFuel&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_engineInstantaneousFuelEconomy&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_ptoGearSta&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_ptoRotationRate&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_upgradeSysSta&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_hydraulicOilLevel&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_hydraulicOilTemp&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_hydraulicOilPressure&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_engOilTemp&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_grainTankWeightKg&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_grainTankFullSts&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_unloadClutchSts&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_grainUnloadTubLvl&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_oilPressure&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_coolantTemperature&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_realOil&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_remainingOil&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_currentWheelAngle&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_steerMotorState&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_remainingOilPercent&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_threePointPromote&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_chassisInfo_tillingDepthFb&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_yaw&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_rtkStatus&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_pitchAngle&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_rollAngle&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_position_longitude&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_position_latitude&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_xyPosition_longitude&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_xyPosition_latitude&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_xyImpl_longitude&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_xyImpl_latitude&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_gnssNum&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_positionInfo_networkSignal&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_fieldId&quot;,&quot;type&quot;: &quot;bigint&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_fieldName&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_fieldCode&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_typeName&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_totalArea&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_operatedArea&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_noOperateArea&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_totalUsedTime&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_percent&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_widthOfCloth&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_totalMileage&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_operatedMileage&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_noOperatedMileage&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_speedPerHour&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_operatedOffset&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_operatedOffsetDirection&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_needLastTime&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_machineName&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_implementName&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_startTime&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_operateStatus&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_controlTaskInfo_segmentPercent&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_statusInfo_deviceId&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_statusInfo_taskId&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_statusInfo_connected&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_statusInfo_ready&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_statusInfo_canTask&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;message_statusInfo_status&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;gis_farmcode&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;gis_farmlandcode&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_gsmStatusInfo_signalRssi&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_gsmStatusInfo_optGsm&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_gsmStatusInfo_networkType&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_gsmStatusInfo_simNumber&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;name&quot;: &quot;message_gsmStatusInfo_cardStatus&quot;,&quot;type&quot;: &quot;int&quot;&#125;,&#123;&quot;name&quot;: &quot;gis_is_exception&quot;,&quot;type&quot;: &quot;int&quot;&#125; ], &quot;defaultFS&quot;: &quot;hdfs://nameservice1&quot;, &quot;fieldDelimiter&quot;: &quot;&quot;, &quot;compress&quot;:&quot;SNAPPY&quot;, &quot;fileName&quot;: &quot;ods_machine_work_log_uq.orc&quot;, &quot;fileType&quot;: &quot;orc&quot;, &quot;path&quot;: &quot;/bigdata/doris/hx_farm_sit.db/ods_machine_work_log_uq/dt=20230503/&quot;, &quot;writeMode&quot;: &quot;append&quot;, &quot;hadoopConfig&quot;:&#123; &quot;dfs.nameservices&quot; : &quot;nameservice1&quot;, &quot;dfs.ha.namenodes.nameservice1&quot; : &quot;bigdata01,bigdata02&quot;, &quot;dfs.namenode.rpc-address.nameservice1.bigdata01&quot; : &quot;bigdata01:8020&quot;, &quot;dfs.namenode.rpc-address.nameservice1.bigdata02&quot; : &quot;bigdata02:8020&quot;, &quot;dfs.client.failover.proxy.provider.nameservice1&quot; : &quot;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&quot; &#125; &#125; &#125; &#125;], &quot;setting&quot;: &#123; &quot;speed&quot;: &#123; &quot;channel&quot;: &quot;1&quot; &#125; &#125; &#125;&#125; 生产环境配置(hdfs–&gt;doris)，基于datax-202303版本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&#123; &quot;job&quot;: &#123; &quot;setting&quot;: &#123; &quot;speed&quot;: &#123; &quot;channel&quot;: 3 &#125; &#125;, &quot;content&quot;: [ &#123; &quot;reader&quot;: &#123; &quot;name&quot;: &quot;hdfsreader&quot;, &quot;parameter&quot;: &#123; &quot;path&quot;: &quot;/tmp/test/*/*&quot;, &quot;defaultFS&quot;: &quot;hdfs://nameservice1&quot;, &quot;fileType&quot;: &quot;orc&quot;, &quot;fieldDelimiter&quot;: &quot;&quot;, &quot;encoding&quot;: &quot;UTF-8&quot;, &quot;hadoopConfig&quot;:&#123; &quot;dfs.nameservices&quot; : &quot;nameservice1&quot;, &quot;dfs.ha.namenodes.nameservice1&quot; : &quot;bigdata2&quot;, &quot;dfs.namenode.rpc-address.nameservice1.bigdata2&quot; : &quot;bigdata2:8020&quot;, &quot;dfs.client.failover.proxy.provider.nameservice1&quot; : &quot;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&quot; &#125;, &quot;column&quot;: [ &#123;&quot;index&quot;: &quot;0&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;1&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;2&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;3&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;4&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;5&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;6&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;7&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;8&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;9&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;10&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;11&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;12&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;13&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;14&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;15&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;16&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;17&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;18&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;19&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;20&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;21&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;22&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;23&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;24&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;25&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;26&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;27&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;28&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;29&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;30&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;31&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;32&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;33&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;34&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;35&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;36&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;37&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;38&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;39&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;40&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;41&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;42&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;43&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;44&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;45&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;46&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;47&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;48&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;49&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;50&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;51&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;52&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;53&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;54&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;55&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;56&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;57&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;58&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;59&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;60&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;61&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;62&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;63&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;64&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;65&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;66&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;67&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;68&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;69&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;70&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;71&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;72&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;73&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;74&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;75&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;76&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;77&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;78&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;79&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;80&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;81&quot;,&quot;type&quot;: &quot;string&quot;&#125;,&#123;&quot;index&quot;: &quot;82&quot;,&quot;type&quot;: &quot;long&quot;&#125;,&#123;&quot;index&quot;: &quot;83&quot;,&quot;type&quot;: &quot;long&quot;&#125; ] &#125; &#125;, &quot;writer&quot;: &#123; &quot;name&quot;: &quot;doriswriter&quot;, &quot;parameter&quot;: &#123; &quot;username&quot;: &quot;root&quot;, &quot;password&quot;: &quot;root&quot;, &quot;database&quot;: &quot;hx_farm_sit&quot;, &quot;table&quot;: &quot;ods_machine_work_log_uq&quot;, &quot;column&quot;: [&quot;message_deviceId&quot;,&quot;message_taskId&quot;,&quot;message_generateTime&quot;,&quot;date_partition&quot;,&quot;message_realSpeed&quot;,&quot;message_driverMode&quot;,&quot;message_reportTime&quot;,&quot;message_taskIndex&quot;,&quot;message_curPathNum&quot;,&quot;message_impleWorkState&quot;,&quot;message_chassisType&quot;,&quot;message_chassisInfo_chassisType&quot;,&quot;message_chassisInfo_engineSpeed&quot;,&quot;message_chassisInfo_fuelOilLevel&quot;,&quot;message_chassisInfo_remainFuel&quot;,&quot;message_chassisInfo_engineInstantaneousFuelEconomy&quot;,&quot;message_chassisInfo_ptoGearSta&quot;,&quot;message_chassisInfo_ptoRotationRate&quot;,&quot;message_chassisInfo_upgradeSysSta&quot;,&quot;message_chassisInfo_hydraulicOilLevel&quot;,&quot;message_chassisInfo_hydraulicOilTemp&quot;,&quot;message_chassisInfo_hydraulicOilPressure&quot;,&quot;message_chassisInfo_engOilTemp&quot;,&quot;message_chassisInfo_grainTankWeightKg&quot;,&quot;message_chassisInfo_grainTankFullSts&quot;,&quot;message_chassisInfo_unloadClutchSts&quot;,&quot;message_chassisInfo_grainUnloadTubLvl&quot;,&quot;message_chassisInfo_oilPressure&quot;,&quot;message_chassisInfo_coolantTemperature&quot;,&quot;message_chassisInfo_realOil&quot;,&quot;message_chassisInfo_remainingOil&quot;,&quot;message_chassisInfo_currentWheelAngle&quot;,&quot;message_chassisInfo_steerMotorState&quot;,&quot;message_chassisInfo_remainingOilPercent&quot;,&quot;message_chassisInfo_threePointPromote&quot;,&quot;message_chassisInfo_tillingDepthFb&quot;,&quot;message_positionInfo_yaw&quot;,&quot;message_positionInfo_rtkStatus&quot;,&quot;message_positionInfo_pitchAngle&quot;,&quot;message_positionInfo_rollAngle&quot;,&quot;message_positionInfo_position_longitude&quot;,&quot;message_positionInfo_position_latitude&quot;,&quot;message_positionInfo_xyPosition_longitude&quot;,&quot;message_positionInfo_xyPosition_latitude&quot;,&quot;message_positionInfo_xyImpl_longitude&quot;,&quot;message_positionInfo_xyImpl_latitude&quot;,&quot;message_positionInfo_gnssNum&quot;,&quot;message_positionInfo_networkSignal&quot;,&quot;message_controlTaskInfo_fieldId&quot;,&quot;message_controlTaskInfo_fieldName&quot;,&quot;message_controlTaskInfo_fieldCode&quot;,&quot;message_controlTaskInfo_typeName&quot;,&quot;message_controlTaskInfo_totalArea&quot;,&quot;message_controlTaskInfo_operatedArea&quot;,&quot;message_controlTaskInfo_noOperateArea&quot;,&quot;message_controlTaskInfo_totalUsedTime&quot;,&quot;message_controlTaskInfo_percent&quot;,&quot;message_controlTaskInfo_widthOfCloth&quot;,&quot;message_controlTaskInfo_totalMileage&quot;,&quot;message_controlTaskInfo_operatedMileage&quot;,&quot;message_controlTaskInfo_noOperatedMileage&quot;,&quot;message_controlTaskInfo_speedPerHour&quot;,&quot;message_controlTaskInfo_operatedOffset&quot;,&quot;message_controlTaskInfo_operatedOffsetDirection&quot;,&quot;message_controlTaskInfo_needLastTime&quot;,&quot;message_controlTaskInfo_machineName&quot;,&quot;message_controlTaskInfo_implementName&quot;,&quot;message_controlTaskInfo_startTime&quot;,&quot;message_controlTaskInfo_operateStatus&quot;,&quot;message_controlTaskInfo_segmentPercent&quot;,&quot;message_statusInfo_deviceId&quot;,&quot;message_statusInfo_taskId&quot;,&quot;message_statusInfo_connected&quot;,&quot;message_statusInfo_ready&quot;,&quot;message_statusInfo_canTask&quot;,&quot;message_statusInfo_status&quot;,&quot;gis_farmcode&quot;,&quot;gis_farmlandcode&quot;,&quot;message_gsmStatusInfo_signalRssi&quot;,&quot;message_gsmStatusInfo_optGsm&quot;,&quot;message_gsmStatusInfo_networkType&quot;,&quot;message_gsmStatusInfo_simNumber&quot;,&quot;message_gsmStatusInfo_cardStatus&quot;,&quot;gis_is_exception&quot;], &quot;preSql&quot;: [], &quot;postSql&quot;: [], &quot;connection&quot;: [ &#123; &quot;jdbcUrl&quot;:&quot;jdbc:mysql://bigdata1:19030/&quot; &quot;table&quot;:[&quot;ods_machine_work_log_uq&quot;], &quot;selectedDatabase&quot;:&quot;hx_farm_sit&quot; &#125; ], &quot;loadUrl&quot;: [&quot;bigdata1:18030&quot;, &quot;bigdata2:18030&quot;, &quot;bigdata3:18030&quot;], &quot;loadProps&quot;: &#123;&#125;, &quot;maxBatchRows&quot;: 10000, &quot;maxBatchByteSize&quot;: 10857600 &#125; &#125; &#125; ] &#125;&#125;","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/categories/bigdata/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/tags/bigdata/"}]},{"title":"Canal将mysql变化数据投送（同步）到MQ","slug":"Canal将mysql变化数据投送（同步）到MQ","date":"2023-04-24T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2023/04/25/Canal将mysql变化数据投送（同步）到MQ/","link":"","permalink":"https://biglovewheat.gihub.io/2023/04/25/Canal%E5%B0%86mysql%E5%8F%98%E5%8C%96%E6%95%B0%E6%8D%AE%E6%8A%95%E9%80%81%EF%BC%88%E5%90%8C%E6%AD%A5%EF%BC%89%E5%88%B0MQ/","excerpt":"","text":"Canal将mysql变化数据投送（同步）到MQ清单123456192.168.8.221 bigdata1 ## admin,deployer192.168.8.222 bigdata2 ## deployer192.168.8.223 bigdata3 ## deployercanal.admin-1.1.5.tar.gzcanal.deployer-1.1.5.tar.gz 集群安装前提java 1.8 （安装略） zookeeper （安装略） mysql（安装略） mysql配置1234567--集群安装需要mysql存储集群数据mysql -u root -p &lt; /data/canal/admin/conf/canal_manager.sqlcreate user &#x27;canal&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;Abc123!!!&#x27;;grant ALL PRIVILEGES ON canal_manager.* TO &#x27;canal&#x27;@&#x27;%&#x27;;flush privileges; 需复制的mysql配置1234需要给canal用户赋予复制的权限create user &#x27;canal&#x27;@&#x27;%&#x27; identified WITH mysql_native_password by &#x27;Abc123@!!!&#x27;;GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#x27;canal&#x27;@&#x27;%&#x27;;flush privileges; 安装admin12345678910111213141516171819202122232425262728293031323334## 解压vi conf/application.ymlserver: port: 18089spring: jackson: date-format: yyyy-MM-dd HH:mm:ss time-zone: GMT+8spring.datasource: address: 192.168.8.211:3306 database: canal_manager username: canal password: Abc123!!! driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://$&#123;spring.datasource.address&#125;/$&#123;spring.datasource.database&#125;?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&amp;allowPublicKeyRetrieval=true hikari: maximum-pool-size: 30 minimum-idle: 1canal: adminUser: admin adminPasswd: 123456## 启动admin./startup_admin.sh# 启动脚本cat startup_admin.sh export JAVA_HOME=/data/soft/jdk1.8.0_301export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar/data/canal/admin/bin/startup.sh 登录控制台http://192.168.8.211 admin&#x2F;123456 新建一个集群 配置并启动deployer123456789101112131415161718192021222324vi deployer/conf/canal_local.properties# register ipcanal.register.ip = # canal admin configcanal.admin.manager = 192.168.8.221:18089canal.admin.port = 11110canal.admin.user = admincanal.admin.passwd = 6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9# admin auto registercanal.admin.register.auto = truecanal.admin.register.cluster = canal-clustercanal.admin.register.name = ## 启动脚本export JAVA_HOME=/data/soft/jdk1.8.0_301export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar/data/canal/deployer/bin/startup.sh local## 启动正常的话，控制台就能看到3台server，否则请看log排错。 控制台配置server(集群配置)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149########################################################## common argument ############################################################### tcp bind ipcanal.ip =# register ip to zookeepercanal.register.ip = canal.port = 11111canal.metrics.pull.port = 11112# canal instance user/passwd# canal.user = canal# canal.passwd = E3619321C1A937C46A0D8BD1DAC39F93B27D4458# canal admin configcanal.admin.manager = 192.168.8.221:18089canal.admin.port = 11110canal.admin.user = admincanal.admin.passwd = 6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9# admin auto registercanal.admin.register.auto = truecanal.admin.register.cluster = canal-cluster#canal.admin.register.name = bigdata01canal.zkServers = 192.168.8.221:12181,192.168.8.222:12181,192.168.8.223:12181# flush data to zkcanal.zookeeper.flush.period = 1000canal.withoutNetty = false# tcp, kafka, rocketMQ, rabbitMQcanal.serverMode = rocketMQ# flush meta cursor/parse position to filecanal.file.data.dir = $&#123;canal.conf.dir&#125;canal.file.flush.period = 1000## memory store RingBuffer size, should be Math.pow(2,n)canal.instance.memory.buffer.size = 16384## memory store RingBuffer used memory unit size , default 1kbcanal.instance.memory.buffer.memunit = 1024 ## meory store gets mode used MEMSIZE or ITEMSIZEcanal.instance.memory.batch.mode = MEMSIZEcanal.instance.memory.rawEntry = true## detecing configcanal.instance.detecting.enable = false#canal.instance.detecting.sql = insert into retl.xdual values(1,now()) on duplicate key update x=now()canal.instance.detecting.sql = select 1canal.instance.detecting.interval.time = 3canal.instance.detecting.retry.threshold = 3canal.instance.detecting.heartbeatHaEnable = false# support maximum transaction size, more than the size of the transaction will be cut into multiple transactions deliverycanal.instance.transaction.size = 1024# mysql fallback connected to new master should fallback timescanal.instance.fallbackIntervalInSeconds = 60# network configcanal.instance.network.receiveBufferSize = 16384canal.instance.network.sendBufferSize = 16384canal.instance.network.soTimeout = 30# binlog filter configcanal.instance.filter.druid.ddl = truecanal.instance.filter.query.dcl = truecanal.instance.filter.query.dml = truecanal.instance.filter.query.ddl = truecanal.instance.filter.table.error = truecanal.instance.filter.rows = falsecanal.instance.filter.transaction.entry = truecanal.instance.filter.dml.insert = falsecanal.instance.filter.dml.update = falsecanal.instance.filter.dml.delete = false# binlog format/image checkcanal.instance.binlog.format = ROW,STATEMENT,MIXED canal.instance.binlog.image = FULL,MINIMAL,NOBLOB# binlog ddl isolationcanal.instance.get.ddl.isolation = false# parallel parser configcanal.instance.parser.parallel = true## concurrent thread number, default 60% available processors, suggest not to exceed Runtime.getRuntime().availableProcessors()#canal.instance.parser.parallelThreadSize = 16## disruptor ringbuffer size, must be power of 2canal.instance.parser.parallelBufferSize = 256# table meta tsdb infocanal.instance.tsdb.enable = falsecanal.instance.tsdb.dir = $&#123;canal.file.data.dir:../conf&#125;/$&#123;canal.instance.destination:&#125;#canal.instance.tsdb.url = jdbc:h2:$&#123;canal.instance.tsdb.dir&#125;/h2;CACHE_SIZE=1000;MODE=MYSQL;canal.instance.tsdb.dbUsername = canalcanal.instance.tsdb.dbPassword = canal# dump snapshot interval, default 24 hourcanal.instance.tsdb.snapshot.interval = 24# purge snapshot expire , default 360 hour(15 days)canal.instance.tsdb.snapshot.expire = 360########################################################## destinations ##############################################################canal.destinations = # conf root dircanal.conf.dir = ../conf# auto scan instance dir add/remove and start/stop instancecanal.auto.scan = truecanal.auto.scan.interval = 5# set this value to &#x27;true&#x27; means that when binlog pos not found, skip to latest.# WARN: pls keep &#x27;false&#x27; in production env, or if you know what you want.canal.auto.reset.latest.pos.mode = false#canal.instance.tsdb.spring.xml = classpath:spring/tsdb/h2-tsdb.xmlcanal.instance.tsdb.spring.xml = classpath:spring/tsdb/mysql-tsdb.xmlcanal.instance.global.mode = springcanal.instance.global.lazy = falsecanal.instance.global.manager.address = $&#123;canal.admin.manager&#125;#canal.instance.global.spring.xml = classpath:spring/memory-instance.xml#canal.instance.global.spring.xml = classpath:spring/file-instance.xmlcanal.instance.global.spring.xml = classpath:spring/default-instance.xml########################################################### MQ Properties ################################################################ aliyun ak/sk , support rds/mqcanal.aliyun.accessKey =canal.aliyun.secretKey =canal.aliyun.uid=canal.mq.flatMessage = truecanal.mq.canalBatchSize = 50canal.mq.canalGetTimeout = 100# Set this value to &quot;cloud&quot;, if you want open message trace feature in aliyun.canal.mq.accessChannel = localcanal.mq.database.hash = truecanal.mq.send.thread.size = 30canal.mq.build.thread.size = 8########################################################### RocketMQ ###############################################################rocketmq.producer.group = mysql-canal-mqrocketmq.enable.message.trace = falserocketmq.customized.trace.topic =rocketmq.namespace =rocketmq.namesrv.addr = hxkj07:9876rocketmq.retry.times.when.send.failed = 0rocketmq.vip.channel.enabled = falserocketmq.tag = 创建并配置instance控制台新建一个instance，配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859################################################### mysql serverId , v1.0.26+ will autoGen# canal.instance.mysql.slaveId=0# enable gtid use true/falsecanal.instance.gtidon=false# position infocanal.instance.master.address=hxkj07:3306canal.instance.master.journal.name=canal.instance.master.position=canal.instance.master.timestamp=canal.instance.master.gtid=# rds oss binlogcanal.instance.rds.accesskey=canal.instance.rds.secretkey=canal.instance.rds.instanceId=# table meta tsdb infocanal.instance.tsdb.enable=false#canal.instance.tsdb.url=jdbc:mysql://127.0.0.1:3306/canal_tsdb#canal.instance.tsdb.dbUsername=canal#canal.instance.tsdb.dbPassword=canal#canal.instance.standby.address =#canal.instance.standby.journal.name =#canal.instance.standby.position =#canal.instance.standby.timestamp =#canal.instance.standby.gtid=# username/passwordcanal.instance.dbUsername=canalcanal.instance.dbPassword=Hxkj2022!!!canal.instance.connectionCharset = UTF-8# enable druid Decrypt database passwordcanal.instance.enableDruid=false#canal.instance.pwdPublicKey=MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBALK4BUxdDltRRE5/zXpVEVPUgunvscYFtEip3pmLlhrWpacX7y7GCMo2/JM6LeHmiiNdH1FWgGCpUfircSwlWKUCAwEAAQ==# table regexcanal.instance.filter.regex=front_telematics.machinery_implement_combination_record,baseinfo.t_implement_sku,baseinfo.t_device_sku,iot.t_device,front_telematics.t_bg_agronomy_operate,baseinfo.t_fault_definittion_description# table black regexcanal.instance.filter.black.regex=# table field filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)#canal.instance.filter.field=test1.t_product:id/subject/keywords,test2.t_company:id/name/contact/ch# table field black filter(format: schema1.tableName1:field1/field2,schema2.tableName2:field1/field2)#canal.instance.filter.black.field=test1.t_product:subject/product_image,test2.t_company:id/name/contact/ch# mq configcanal.mq.topic=mysql_canal_mq# dynamic topic route by schema or table regex#canal.mq.dynamicTopic=canal.mq.partition=0# hash partition configcanal.mq.partitionsNum=4canal.mq.partitionHash=.*\\\\..*:$pk$,.*\\\\..*:id#canal.mq.partitionHash=test.table:id^name,.*\\\\..*################################################# 检查mq所有配置正常情况下，修改目标mysql，就能在rocketmq看到相应的message 错误解决12Caused by: java.io.IOException: caching_sha2_password Auth failedalter user &#x27;canal&#x27;@&#x27;%&#x27; identified with mysql_native_password by &#x27;Abc123!!!&#x27;;","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/categories/bigdata/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/tags/bigdata/"}]},{"title":"Cloudera-CM+CDH6安装","slug":"Cloudera-CM+CDH6安装","date":"2023-04-12T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2023/04/13/Cloudera-CM+CDH6安装/","link":"","permalink":"https://biglovewheat.gihub.io/2023/04/13/Cloudera-CM+CDH6%E5%AE%89%E8%A3%85/","excerpt":"","text":"Cloudera CM+CDH6 安装环境清单192.168.8.221 bigdata1192.168.8.221 bigdata2192.168.8.221 bigdata3 服务器设置关闭firewall，关闭selinux，设置ssh互信（略） 禁止透明大页12echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledecho never &gt; /sys/kernel/mm/transparent_hugepage/defrag mysql5.7安装（略） 创建数据库1234567891011121314151617create database scm default character set utf8 default collate utf8_general_ci;grant all on scm.* to &#x27;scm&#x27;@&#x27;%&#x27; identified by &#x27;Hxkj2022!!!&#x27;;create database amon default character set utf8 default collate utf8_general_ci;grant all on amon.* to &#x27;amon&#x27;@&#x27;%&#x27; identified by &#x27;Hxkj2022!!!&#x27;;create database rman default character set utf8 default collate utf8_general_ci;grant all on rman.* to &#x27;rman&#x27;@&#x27;%&#x27; identified by &#x27;Hxkj2022!!!&#x27;;create database hue default character set utf8 default collate utf8_general_ci;grant all on hue.* to &#x27;hue&#x27;@&#x27;%&#x27; identified by &#x27;Hxkj2022!!!&#x27;;create database metastore default character set utf8 default collate utf8_general_ci;grant all on metastore.* to &#x27;hive&#x27;@&#x27;%&#x27; identified by &#x27;Hxkj2022!!!&#x27;;create database sentry default character set utf8 default collate utf8_general_ci;grant all on sentry.* to &#x27;sentry&#x27;@&#x27;%&#x27; identified by &#x27;Hxkj2022!!!&#x27;;create database nav default character set utf8 default collate utf8_general_ci;grant all on nav.* to &#x27;nav&#x27;@&#x27;%&#x27; identified by &#x27;Hxkj2022!!!&#x27;;create database oozie default character set utf8 default collate utf8_general_ci;grant all on oozie.* to &#x27;oozie&#x27;@&#x27;%&#x27; identified by &#x27;Hxkj2022!!!&#x27;;flush privileges; 本地yum仓库搭建123456789101112131415161718192021222324252627282930313233343536[root@hy-base-01 bigdata_repo]# tree .├── CDH-6.3.2-1.cdh6.3.2.p0.1605554-el7.parcel├── CDH-6.3.2-1.cdh6.3.2.p0.1605554-el7.parcel.sha1├── CDH-6.3.2-1.cdh6.3.2.p0.1605554-el7.parcel.sha256├── manifest.json├── allkeys.asc├── cloudera-manager-agent-6.3.1-1466458.el7.x86_64.rpm├── cloudera-manager-daemons-6.3.1-1466458.el7.x86_64.rpm├── cloudera-manager-server-6.3.1-1466458.el7.x86_64.rpm├── cloudera-manager-server-db-2-6.3.1-1466458.el7.x86_64.rpm├── enterprise-debuginfo-6.3.1-1466458.el7.x86_64.rpmyum install -y createrepocd bigdata_repocreaterepo .## nginx 配置server &#123; listen 80; location / &#123; root /data/bigdata_repo; autoindex on; &#125;&#125;## yum仓库配置# cat /etc/yum.repos.d/local.repo [bigdata]name=bigdatabaseurl=http://bigdata1/gpgcheck=0enabled=1 java设置12345678910111213## mysql链接驱动mkdir -p /usr/share/java cp mysql-connector-java-8.0.21.jar /usr/share/java/mysql-connector-java.jar## 默认javamkdir -p /usr/java/ln -s /data/soft/jdk1.8.0_301/ /usr/java/default## 配置java环境vi /etc/profileexport JAVA_HOME=/data/soft/jdk1.8.0_301export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 安装(服务器)12345678910111213141516yum install -y cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server## 初始化数据库# mysql在本地/opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm# mysql不在本地/opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h &lt;mysql-host-ip&gt; --scm-host &lt;cm-server-ip&gt; scm scm## 数据库初始化成功后启动serversystemctl start cloudera-scm-serversystemctl enable cloudera-manager-agent cloudera-manager-serversystemctl start cloudera-manager-agent cloudera-manager-server## 查看日志tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log 登录界面，在界面完成其他节点安装和配置http://bigdata-01:7180/cmf/login admin&#x2F;admin 按照图形界面向导安装即可","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/categories/bigdata/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/tags/bigdata/"}]},{"title":"Doris-集群搭建","slug":"doris-集群搭建","date":"2023-04-10T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/04/11/doris-集群搭建/","link":"","permalink":"https://biglovewheat.gihub.io/2023/04/11/doris-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"Doris-集群搭建清单123192.168.8.221 bigdata1 ## fe,be192.168.8.222 bigdata2 ## fe,be192.168.8.223 bigdata3 ## fe,be 检查CPU是否支持AVX2指令集1234cat /proc/cpuinfo |grep -i avx2## cpu是否支持avx2命令集决定下载对应的doris版本，版本不对be可能启动不了，/var/log/message 会产生类似错误kernel: traps: palo_be[18318] trap invalid opcode ip:1222ed6 下载安装文件12345## 编译好的http://palo.baidu.com/docs/%E4%B8%8B%E8%BD%BD%E4%B8%93%E5%8C%BA/%E9%A2%84%E7%BC%96%E8%AF%91%E7%89%88%E6%9C%AC%E4%B8%8B%E8%BD%BD/## 或官网下载对应版本https://doris.apache.org/zh-CN/download chrony时间同步时间不同步会导致doris集群出问题无法访问外网的话，内网拿一台作为chrony服务端，配置如下： 12345678910111213141516171819202122## 服务端vim /etc/chrony.confserver 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst# Allow NTP client access from local network.allow 192.168.8.0/24# Serve time even if not synchronized to a time source.local stratum 10#其他默认## client端，把服务器改成上面的地址，其他默认，配置如下：server hy-base-01 iburst## 重启systemctl enable chronyd;systemctl restart chronyd 关掉swap1234## swap开启会影响doris性能，需要关闭swapoff -avi /etc/fstab## 注释掉swap的一行 修改系统最大文件打开数12345678vi /etc/security/limits.conf* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535#重新登录看是否生效 ulimit -a 端口规划由于doris默认端口都是常用的端口，很容易造成冲突，建议更改所有默认端口，这里把所有默认端口前面都加1 doris配置12#如本机有多个IP（比如装了docker），be和fe都需要配置使用网段priority_networks = 192.168.8.0/24 启动第一台fe1234#第一次启动最好清空元元素文件件rm rf fe/doris-meta/*#启动 fe/bin/start_fe.sh 启动三台be12#启动be/bin/start_be.sh 登录第一台fe，并把3台be，2台fe注册上去，初始密码为空1234567mysql -h 192.168.8.221 -u root -P 19030 -pALTER SYSTEM ADD BACKEND &quot;192.168.8.221:19050&quot;;ALTER SYSTEM ADD BACKEND &quot;192.168.8.222:19050&quot;;ALTER SYSTEM ADD BACKEND &quot;192.168.8.223:19050&quot;;ALTER SYSTEM ADD FOLLOWER &quot;192.168.8.222:19010&quot;;ALTER SYSTEM ADD FOLLOWER &quot;192.168.8.223:19010&quot;; 启动剩余两台fe12345rm rf fe/doris-meta/*#第一次启动：fe/bin/start_fe.sh --helper 192.168.8.221:19010 --daemon#以后可以去掉helper参数fe/bin/start_fe.sh 192.168.8.221:19010 --daemon 查询fe、be状态,alive均为true则为正常12SHOW PROC &#x27;/backends&#x27;;SHOW PROC &#x27;/frontends&#x27;; 修改root密码1SET PASSWORD FOR &#x27;root&#x27; = PASSWORD(&#x27;root&#x27;);","categories":[{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/categories/bigdata/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/tags/bigdata/"}]},{"title":"Mysql-忘记root密码处理","slug":"mysql-忘记root密码处理","date":"2023-03-26T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2023/03/27/mysql-忘记root密码处理/","link":"","permalink":"https://biglovewheat.gihub.io/2023/03/27/mysql-%E5%BF%98%E8%AE%B0root%E5%AF%86%E7%A0%81%E5%A4%84%E7%90%86/","excerpt":"","text":"Mysql-忘记root密码处理原理：修改配置文件&#x2F;etc&#x2F;my.cnf，在mysqld项增加skip-grant-tables，重启后跳过权限验证，登录成功后，清除root密码。 1234567891011121314151617181920vi /etc/my.cnf[mysqld]skip-grant-tables## 重启mysqlsystemctl restart mysqld## 登录并清除root密码mysql -u root### 直接回车，登录成功后清空root密码mysql&gt; use mysql;mysql&gt; update user set authentication_string=&#x27;&#x27; where user=&#x27;root&#x27;;mysql&gt; quit;## 配置文件去掉skip-grant-tables，并重启动mysqlsystemctl restart mysqld### 登录并修改密码mysql&gt; alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;2dcP2$LWpcc1&#x27;;mysql&gt; flush privileges;mysql&gt; quit","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Linux-日志相关","slug":"linux-日志系统","date":"2023-03-02T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2023/03/03/linux-日志系统/","link":"","permalink":"https://biglovewheat.gihub.io/2023/03/03/linux-%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"Linux-日志相关综述centos7系统中有两个日志服务，分别是传统的rsyslog和新添加的systemd-journal 图 rsyslog12345678910111213141516## 系统日志/var/log/message //绝大多数的系统日志都记录到文件/var/log/secure //所有跟安全和认知授权等日志都会记录到此文件中 *****/var/log/maillog //邮件服务日志/var/log/cron //计划任务日志 *****/var/log/boot.log //系统启动相关的日志/var/log/demsg //系统引导日志，dmesg命令查看 ## 程序日志/var/log/mysql.log //mysql日志 *****... ## 特殊日志，二进制文件，不能直接查看/var/log/wtmp //登录用户信息，使用last命令 *****/var/log/btmp //最近登录用户信息，使用lastb命令 ***/var/log/lastlog //所有用户登录信息，使用lastlog命令 systemd-journal123456789101112131415161718192021222324252627282930313233343536373839404142434445## 显示最后10条journalctl -n 100## 显示err以及以上级别的系统信息journalctl -p err## 滚动输出journalctl -f## 查看某个服务的日志journalctl -u mysqld## 某段时间的日志journalctl --since=&quot;2022-07-06 09:00&quot; --until=&quot;2022-07-06 10:00&quot;## journald配置文件cat /etc/systemd/journald.conf [Journal]#Storage=auto#Compress=yes#Seal=yes#SplitMode=uid#SyncIntervalSec=5m#RateLimitInterval=30s#RateLimitBurst=1000#SystemMaxUse=#SystemKeepFree=#SystemMaxFileSize=#RuntimeMaxUse=#RuntimeKeepFree=#RuntimeMaxFileSize=#MaxRetentionSec=#MaxFileSec=1month#ForwardToSyslog=yes#ForwardToKMsg=no#ForwardToConsole=no#ForwardToWall=yes#TTYPath=/dev/console#MaxLevelStore=debug#MaxLevelSyslog=debug#MaxLevelKMsg=notice#MaxLevelConsole=info#MaxLevelWall=emerg#LineMax=48K","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Ansible-新装系统初始化","slug":"ansible-roles-新装系统初始化","date":"2022-12-15T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2022/12/16/ansible-roles-新装系统初始化/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/16/ansible-roles-%E6%96%B0%E8%A3%85%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96/","excerpt":"","text":"Ansible-新装系统初始化介绍ansible是一个自动化运维工具，基于Python开发，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。Ansible架构相对比较简单，无需agnet，仅需通过SSH连接客户机即可执行任务。 简单任务可以直接使用命令行方式运行，较复杂任务可以通过编写playbook方式运行，以下例子通过编写palybook方式，使用角色区分，简单初始化centos7。 语法参考：https://docs.ansible.com/ansible/latest/modules/modules_by_category.htmAnsible Galaxy命令，用于安装指定的角色或集合：https://galaxy.ansible.com/ 初始化文件夹1234567891011121314151617181920212223242526272829303132## 创建整个项目文件夹mkdir ansible-initcd ansible-initmkdir rolestouch ansible-host.lst## 初始化rolescd rolesansible-galaxy init commonansible-init/├── ansible-host.lst└── roles └── common ├── defaults │ └── main.yml ├── files ├── handlers │ └── main.yml ├── meta │ └── main.yml ├── README.md ├── tasks │ └── main.yml ├── templates ├── tests │ ├── inventory │ └── test.yml └── vars └── main.yml10 directories, 9 files 配置主机清单 ansible&#x2F;ansible-host.lst将主机分组，并定义变量，指定运行的用户或明文密码 12345678910[all]192.168.8.252 hostname=vm252 server_type=app192.168.8.253 hostname=vm252 server_type=db[db]192.168.8.253 hostname=vm252 server_type=db[all:vars]ansible_user=rootansible_password=12341234 入口脚本 ansible&#x2F;init.yml这个是整个playbook入口，可以按不同主机组运行不同角色（roles） 1234567891011121314---## 全部运行common角色- hosts: all user: root gather_facts: true roles: - common## db组运行db1角色、db2角色- hosts: db user: root gather_facts: true roles: - db1 - db2 配置主脚本 ansible&#x2F;roles&#x2F;common&#x2F;task&#x2F;main.yml主脚本默认为main.yml，里面可以包含各种子任务 12345678---- include_tasks: set-hosts.yml ##- include_tasks: set-yum-repo-cdrom.yml- include_tasks: set-centos7.yml#- include_tasks: set-yum-repo-local.yml- include_tasks: install-base-tools.yml#- include_tasks: set-hy.yml 子任务1，ansible&#x2F;roles&#x2F;common&#x2F;task&#x2F;set-hosts.yml这里用到copy，表示会在当前roles的files文件夹里查找hosts文件，并复制到目标主机 123---- name: set /etc/hosts copy: src=hosts dest=/etc/hosts 子任务2，ansible&#x2F;roles&#x2F;common&#x2F;task&#x2F;set-yum-repo-local.yml这里用到template，表示会将当前roles的templates文件夹查找local.repo.j2文件，并替换里面的变量后，复制到目标主机。需要修改为变量的场景，适合使用template模块。template使用jinja2语法。 123&#123;&#123; &#125;&#125; ：用来装载表达式，比如变量、运算表达式、比较表达式等。&#123;% %&#125; ：用来装载控制语句，比如 if 控制结构，for循环控制结构。&#123;# #&#125; ：用来装载注释，模板文件被渲染后，注释不会包含在最终生成的文件中。 123456---- name: backup yum repo files shell: &#x27;find /etc/yum.repos.d/ -name &quot;*.repo&quot; -exec mv &#123;&#125; &#123;&#125;.$(date +&quot;%Y%m%d%H%M&quot;) \\;&#x27;- name: set yum repo template: src=local.repo.j2 dest=/etc/yum.repos.d/local.repo 用到的变量在vars&#x2F;main.yml里定义 123456789prometheus: base_path: /data/moni server: 192.168.8.201:9090 consul: 192.168.8.201:18500chrony: server: 192.168.8.201 priority_networks: 192.168.8.0/24yum: server: 192.168.8.251:18001 template放在templates文件夹里，上面用到的是local.repo.j2 12345[base]name=localbaseurl=http://&#123;&#123; yum.server &#125;&#125;/gpgcheck=0enabled=1 运行1234## 测试ansible-playbook -i ansible_host.lst -C init.yml## 运行ansible-playbook -i ansible_host.lst init.yml 总结整个初始化脚本框架搭建完毕 接下来需要添加各种子脚本，然后在主脚本main.yml引入即可","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://biglovewheat.gihub.io/tags/ansible/"},{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"}]},{"title":"Nginx-ssl双向认证","slug":"nginx-ssl双向认证","date":"2022-12-14T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/12/15/nginx-ssl双向认证/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/15/nginx-ssl%E5%8F%8C%E5%90%91%E8%AE%A4%E8%AF%81/","excerpt":"","text":"Nginx-ssl双向认证脚本-生成ca&#x2F;server&#x2F;client证书1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#!/bin/shDOMAIN=&quot;biglovewheat.cn&quot;IP=&quot;192.168.0.23&quot;WORK_DIR=./temprm -rf $WORK_DIRmkdir ./temprm -rf $DOMAIN## CAopenssl genrsa -out $WORK_DIR/ca.key 4096 openssl req -x509 -new -nodes -sha512 -days 3650 \\ -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=$DOMAIN&quot; \\ -key $WORK_DIR/ca.key \\ -out $WORK_DIR/ca.crt## serveropenssl genrsa -out $WORK_DIR/server.key 4096 openssl req -sha512 -new \\ -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=example/OU=Personal/CN=$DOMAIN&quot; \\ -key $WORK_DIR/server.key \\ -out $WORK_DIR/server.csrcat &gt; $WORK_DIR/server.ext &lt;&lt;-EOFauthorityKeyIdentifier=keyid,issuerbasicConstraints=CA:FALSEkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEnciphermentextendedKeyUsage = serverAuthsubjectAltName = @alt_names[alt_names]DNS.1=$DOMAINDNS.2=*.$DOMAINIP.1=$IPEOF ## server visaopenssl x509 -req -sha512 -days 3650 \\ -extfile $WORK_DIR/server.ext \\ -CA $WORK_DIR/ca.crt -CAkey $WORK_DIR/ca.key -CAcreateserial \\ -in $WORK_DIR/server.csr \\ -out $WORK_DIR/server.crt## clientopenssl genrsa -out $WORK_DIR/client-ca.key 2048openssl req -x509 -new -nodes -key $WORK_DIR/client-ca.key -subj &quot;/CN=ca.client&quot; -days 3650 -out $WORK_DIR/client-ca.crtopenssl genrsa -out $WORK_DIR/client.key 2048openssl req -new -key $WORK_DIR/client.key -subj &quot;/CN=client&quot; -out $WORK_DIR/client.csrcat &gt; $WORK_DIR/client.ext &lt;&lt; EOFextendedKeyUsage=clientAuthEOFopenssl x509 -req -in $WORK_DIR/client.csr -CA $WORK_DIR/client-ca.crt -CAkey $WORK_DIR/client-ca.key -CAcreateserial \\ -extfile $WORK_DIR/client.ext -out $WORK_DIR/client.crt -days 3650 ## output mkdir -p ./$DOMAINcp $WORK_DIR/*.crt $WORK_DIR/*.key ./$DOMAIN## convert to pfxopenssl pkcs12 -export -inkey ./$DOMAIN/client.key -in ./$DOMAIN/client.crt -out ./$DOMAIN/client.pfx nginx 配置123456789101112131415161718192021222324252627server &#123; listen 80; listen 443 ssl; ssl_certificate /data/openssl-test/biglovewheat.cn/server.crt; ssl_certificate_key /data/openssl-test/biglovewheat.cn/server.key; ssl_client_certificate /data/openssl-test/biglovewheat.cn/client-ca.crt; ssl_verify_client on; ssl_verify_depth 3; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_prefer_server_ciphers on; location / &#123; root /data/webapp/www; if (!-e $request_filename)&#123; rewrite ^(.*)$ /$1.html last; break; &#125;# try_files $uri $uri/ /index.html; index index.html; &#125;&#125; 效果不带clinet证书，报400-No required SSL certificate was sent 带client证书和key，正常访问 123456789101112[root@hw-gz-1 biglovewheat.cn]# curl https://www.biglovewheat.cn -k &lt;html&gt;&lt;head&gt;&lt;title&gt;400 No required SSL certificate was sent&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;h1&gt;400 Bad Request&lt;/h1&gt;&lt;/center&gt;&lt;center&gt;No required SSL certificate was sent&lt;/center&gt;&lt;hr&gt;&lt;center&gt;nginx/1.20.1&lt;/center&gt;&lt;/body&gt;&lt;/html&gt;[root@hw-gz-1 biglovewheat.cn]# curl --cert ./client.crt --key ./client.key https://www.biglovewheat.cn -k www windows浏览器访问导出pfx格式，可加密码，双击安装后，重启浏览器即可 12## 脚本最后一步，转成pfx格式openssl pkcs12 -export -inkey ./$DOMAIN/client.key -in ./$DOMAIN/client.crt -out ./$DOMAIN/client.pfx","categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://biglovewheat.gihub.io/tags/nginx/"}]},{"title":"Consul-启动失败排查","slug":"consul-启动失败排查","date":"2022-12-12T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2022/12/13/consul-启动失败排查/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/13/consul-%E5%90%AF%E5%8A%A8%E5%A4%B1%E8%B4%A5%E6%8E%92%E6%9F%A5/","excerpt":"","text":"Consul-不能启动问题排查现象123456supervisorctl statusalertmanager RUNNING pid 2910405, uptime 1 day, 22:39:07consul FATAL Exited too quickly (process log may have details)prometheus RUNNING pid 1842, uptime 1299 days, 16:51:21prometheus-webhook-dingtalk STOPPED Jul 04 03:47 PM 查看日志1234567891011tail -f supervisord.log-20220704 2022-07-04 15:50:43,730 INFO gave up: consul entered FATAL state, too many start retries too quickly2022-07-06 14:27:46,651 INFO spawned: &#x27;consul&#x27; with pid 12481362022-07-06 14:27:46,854 INFO exited: consul (exit status 1; not expected)2022-07-06 14:27:47,855 INFO spawned: &#x27;consul&#x27; with pid 12484462022-07-06 14:27:48,043 INFO exited: consul (exit status 1; not expected)2022-07-06 14:27:50,046 INFO spawned: &#x27;consul&#x27; with pid 12487972022-07-06 14:27:50,599 INFO exited: consul (exit status 1; not expected)2022-07-06 14:27:53,602 INFO spawned: &#x27;consul&#x27; with pid 12493892022-07-06 14:27:53,847 INFO exited: consul (exit status 1; not expected)2022-07-06 14:27:54,847 INFO gave up: consul entered FATAL state, too many start retries too quickly 再次排查1234567891011121314supervisorctl tail consul stdout.245:8301: bind: address already in usebootstrap_expect = 2: A cluster with 2 servers will provide no failure tolerance. See https://www.consul.io/docs/internals/consensus.html#deployment-tablebootstrap_expect &gt; 0: expecting 2 servers==&gt; Starting Consul agent...==&gt; Error starting agent: Failed to start Consul server: Failed to start LAN Serf: Failed to create memberlist: Could not set up network transport: failed to obtain an address: Failed to start TCP listener on &quot;10.9.127.245&quot; port 8301: listen tcp 10.9.127.245:8301: bind: address already in usebootstrap_expect = 2: A cluster with 2 servers will provide no failure tolerance. See https://www.consul.io/docs/internals/consensus.html#deployment-tablebootstrap_expect &gt; 0: expecting 2 servers==&gt; Starting Consul agent...==&gt; Error starting agent: Failed to start Consul server: Failed to start LAN Serf: Failed to create memberlist: Could not set up network transport: failed to obtain an address: Failed to start TCP listener on &quot;10.9.127.245&quot; port 8301: listen tcp 10.9.127.245:8301: bind: address already in usebootstrap_expect = 2: A cluster with 2 servers will provide no failure tolerance. See https://www.consul.io/docs/internals/consensus.html#deployment-tablebootstrap_expect &gt; 0: expecting 2 servers==&gt; Starting Consul agent...==&gt; Error starting agent: Failed to start Consul server: Failed to start LAN Serf: Failed to create memberlist: Could not set up network transport: failed to obtain an address: Failed to start TCP listener on &quot;10.9.127.245&quot; port 8301: listen tcp 10.9.127.245:8301: bind: address already in use 总结1## address already in use --&gt; 端口被占用，清理端口后重新启动即可","categories":[{"name":"故障排查","slug":"故障排查","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"}],"tags":[{"name":"consul","slug":"consul","permalink":"https://biglovewheat.gihub.io/tags/consul/"},{"name":"supervisor","slug":"supervisor","permalink":"https://biglovewheat.gihub.io/tags/supervisor/"}]},{"title":"Java-启动参数修改","slug":"java-启动参数修改","date":"2022-12-12T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/12/13/java-启动参数修改/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/13/java-%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E4%BF%AE%E6%94%B9/","excerpt":"","text":"java启动参数修改java8转换成java11参数修改12345678910## java8JAVA_OPS=&quot;-Xms512m -Xmx2g -Xmn1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$&#123;LOG_HOME&#125;/analyzeGc/ -XX:+PrintGCDetails -verbosegc -Xloggc:$&#123;LOG_HOME&#125;/analyzeGc/gc.$&#123;svc&#125;.log&quot;## 启动报warning[0.001s][warning][gc] -Xloggc is deprecated. Will use -Xlog:gc:/data/logs/analyzeGc/gc.hx-task.log instead.[0.002s][warning][gc] -XX:+PrintGCDetails is deprecated. Will use -Xlog:gc* instead.## java11JAVA_OPS=&quot;-Xms512m -Xmx1g -Xmn512m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$&#123;LOG_HOME&#125;/analyzeGc/ -Xlog:gc* -verbosegc -Xlog:gc:$&#123;LOG_HOME&#125;/analyzeGc/gc.$&#123;svc&#125;.log&quot;","categories":[{"name":"java","slug":"java","permalink":"https://biglovewheat.gihub.io/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"https://biglovewheat.gihub.io/tags/java/"}]},{"title":"数据库隔离级别","slug":"数据库隔离级别","date":"2022-12-05T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/12/06/数据库隔离级别/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","excerpt":"","text":"数据库隔离级别","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"database","slug":"database","permalink":"https://biglovewheat.gihub.io/tags/database/"}]},{"title":"Arthas-java性能分析工具","slug":"arthas-java性能分析工具","date":"2022-12-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2022/12/05/arthas-java性能分析工具/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/05/arthas-java%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/","excerpt":"","text":"Arthas-java性能分析工具Arthas简介Arthas 是阿里开源的 Java 诊断工具 https://arthas.aliyun.com/doc/ 安装使用12345678910111213141516171819## github下载wget https://github.com/alibaba/arthas/releases/download/arthas-all-3.6.7/arthas-bin.zip## 解压unzip arthas-all-3.6.7/arthas-bin.zip## 运行./as.sh## 选择需要监控的java进程## 常用命令dashboard## 更多详见帮助help## 退出exit","categories":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"java","slug":"java","permalink":"https://biglovewheat.gihub.io/tags/java/"},{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"K8s-允许master节点参与调度","slug":"k8s-允许master节点参与调度","date":"2022-12-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/12/05/k8s-允许master节点参与调度/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/05/k8s-%E5%85%81%E8%AE%B8master%E8%8A%82%E7%82%B9%E5%8F%82%E4%B8%8E%E8%B0%83%E5%BA%A6/","excerpt":"","text":"k8s-允许master节点参与调度默认情况下，master由于有node-role.kubernetes.io&#x2F;master:NoSchedule污点，不参与任务调度。想让master节点参与任务调度，需去除此污点(Taints) 去除污点123456789101112131415## 去除污点### 查看nodekubectl get nodes### 查看污点kubectl describe node k8s-master |grep TaintsTaints: node-role.kubernetes.io/master:NoSchedule### 去除污点 kubectl taint nodes --all node-role.kubernetes.io/master-## 添加master为worker角色(可选)### 让master节点参与调度，#如果想删除，把=换成-kubectl label nodes k8s-master node-role.kubernetes.io/worker=","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"Linux-时区操作","slug":"linux-时区操作","date":"2022-12-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/12/05/linux-时区操作/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/05/linux-%E6%97%B6%E5%8C%BA%E6%93%8D%E4%BD%9C/","excerpt":"","text":"linux-时区操作ubuntu&#x2F;centos 更改时区12timedatectl list-timezones |grep -i shanghaitimedatectl set-timezone Asia/Shanghai alpine 更改时区1cp -a /usr/share/zoneinfo/Asia/Shanghai /etc/localtime","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Postgresql-创建只读用户","slug":"postgresql-创建只读用户","date":"2022-12-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/12/05/postgresql-创建只读用户/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/05/postgresql-%E5%88%9B%E5%BB%BA%E5%8F%AA%E8%AF%BB%E7%94%A8%E6%88%B7/","excerpt":"","text":"Postgresql-创建只读用户1234create user bigdata with password &#x27;ch2)x7jzReZN&#x27;;alter user bigdata set default_transaction_read_only=on;GRANT USAGE ON SCHEMA public to bigdata;grant select on all tables in schema public to bigdata;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://biglovewheat.gihub.io/tags/postgresql/"}]},{"title":"Shell-备份工具","slug":"shell-备份工具","date":"2022-12-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/12/05/shell-备份工具/","link":"","permalink":"https://biglovewheat.gihub.io/2022/12/05/shell-%E5%A4%87%E4%BB%BD%E5%B7%A5%E5%85%B7/","excerpt":"","text":"Shell-备份工具一个自己写的shell脚本备份工具 配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647## 主配置文件cat backup.lst #1pg|2gis_sit|3IP|4Port|5user|6password|7cycle|pg|gis_sit|172.31.34.25|5083|postgres|abc123!!!|days|pg|gis_prod|172.31.56.16|5083|postgres|abc123!!!|days|pg|gis_jx|172.31.71.117|5083|postgres|abc123!!!|days|pg|gis_old_lite|172.31.45.42|5083|postgres|abc123!!!|days|pg|gis_old|172.31.45.42|5083|postgres|abc123!!!|weeks|mysql|jx|3|4|5|6|days|mysql|sit|3|4|5|6|days|mysql|show|3|4|5|6|days|mysql|prod|3|4|5|6|days|mysql|wiki|3|4|5|6|days|mysql|bigdata|3|4|5|6|days|## mysql-client配置文件cat ./mysql_cnf/jx.lst [client]user=rootpassword=abc123!!!host=172.31.71.117port=3306## ansible配置cat ansible_host.lst[nginx_default]aws-prod-app-01aws-prod-app-02aws-prod-app-03aws-prod-app-04aws-prod-app-05aws-sit-app-01aws-sit-app-02aws-sit-app-04aws-show-app-01[nginx_data]aws-jx-app-01aws-jx-app-02[nginx_default:vars]ansible_user=ops_rootansible_password=dNqzrKHu8UQsuxcX[nginx_data:vars]ansible_user=ops_rootansible_password=dNqzrKHu8UQsuxcX 主脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109#!/bin/shDATETIME=$(date +&quot;%Y%m%d%H%M&quot;)ROOT=/nfs_hy_backup/backupv_backuplist=$ROOT/backup.lstv_weekday=$(date +%w)v_day=$(date +%d)cd $ROOTecho &quot;***********************************************************************&quot;echo $(date) &quot; -- backup bgein&quot;echo &quot;***********************************************************************&quot;## backupfor row in $(cat $v_backuplist|grep -v ^$|grep -v ^#)do#pg|gis-sit|172.31.34.25|5083|postgres|Hxkj2022!!!| v_type=$(echo $row |awk -F\\| &#x27;&#123;print $1&#125;&#x27;) v_name=$(echo $row |awk -F\\| &#x27;&#123;print $2&#125;&#x27;) v_ip=$(echo $row |awk -F\\| &#x27;&#123;print $3&#125;&#x27;) v_port=$(echo $row |awk -F\\| &#x27;&#123;print $4&#125;&#x27;) v_user=$(echo $row |awk -F\\| &#x27;&#123;print $5&#125;&#x27;) v_pass=$(echo $row |awk -F\\| &#x27;&#123;print $6&#125;&#x27;) case $v_type in pg) export PGPASSWORD=$v_pass case $v_name in gis_old_lite) v_backupfile=$&#123;v_type&#125;_$&#123;v_name&#125;_$&#123;DATETIME&#125;.tar pg_dumpall -h $v_ip -U $v_user -p $v_port --exclude-database=common -c --if-exists |gzip &gt; $&#123;v_type&#125;_$&#123;v_name&#125;_$&#123;DATETIME&#125;.1.sql.gz pg_dump -h $v_ip -U $v_user -p $v_port --dbname=common --exclude-schema=offline_map -c --if-exists|gzip &gt; $&#123;v_type&#125;_$&#123;v_name&#125;_$&#123;DATETIME&#125;.2.sql.gz tar -cvf $v_backupfile $&#123;v_type&#125;_$&#123;v_name&#125;_$&#123;DATETIME&#125;.*.sql.gz --remove-files# /usr/local/bin/aws s3 cp $v_backupfile s3://hxs3/backup/# if [[ &quot;v$&#123;v_day&#125;&quot; == &quot;v01&quot; ]] || [[ &quot;v$&#123;v_day&#125;&quot; == &quot;v15&quot; ]]; then /usr/local/bin/aws s3 cp $v_backupfile s3://hxs3/backup/ s3://hxarchive/永久备份/; fi ;; gis_old) if [[ &quot;v$&#123;v_weekday&#125;&quot; == &quot;v6&quot; ]] then v_backupfile=$&#123;v_type&#125;_$&#123;v_name&#125;_$&#123;DATETIME&#125;.sql.gz pg_dumpall -h $v_ip -U $v_user -p $v_port -c --if-exists |gzip &gt; $v_backupfile# /usr/local/bin/aws s3 cp $v_backupfile s3://hxs3/backup/ fi ;; *) v_backupfile=$&#123;v_type&#125;_$&#123;v_name&#125;_$&#123;DATETIME&#125;.sql.gz pg_dumpall -h $v_ip -U $v_user -p $v_port -c --if-exists |gzip &gt; $v_backupfile# /usr/local/bin/aws s3 cp $v_backupfile s3://hxs3/backup/# if [[ &quot;v$&#123;v_day&#125;&quot; == &quot;v01&quot; ]] || [[ &quot;v$&#123;v_day&#125;&quot; == &quot;v15&quot; ]]; then /usr/local/bin/aws s3 cp $v_backupfile s3://hxs3/backup/ s3://hxarchive/永久备份/; fi ;; esac ;; mysql) v_mysqllst=./mysql_cnf/$&#123;v_name&#125;.lst v_backupfile=$&#123;v_type&#125;_$&#123;v_name&#125;_$&#123;DATETIME&#125;.sql.gz if [[ &quot;v$&#123;v_name&#125;&quot; == &quot;vbigdata&quot; ]]; then mysql_ops=&#x27; --skip-column-statistics&#x27; ; fi mysqldump --defaults-extra-file=$v_mysqllst --all-databases --set-gtid-purged=OFF $mysql_ops -C | gzip &gt; $v_backupfile# /usr/local/bin/aws s3 cp $v_backupfile s3://hxs3/backup/# if [[ &quot;v$&#123;v_day&#125;&quot; == &quot;v01&quot; ]] || [[ &quot;v$&#123;v_day&#125;&quot; == &quot;v15&quot; ]]; then /usr/local/bin/aws s3 cp $v_backupfile s3://hxs3/backup/ s3://hxarchive/永久备份/; fi ;; *) ;; esacdone## nacos backup./nacos_backup.py## nginx backupansible nginx_data -i ansible_hosts.lst -m synchronize -a &quot;src=/data/nginx/conf/conf.d dest=nginx_&#123;&#123;inventory_hostname&#125;&#125; mode=pull&quot;tar -czvf nginx_$&#123;DATETIME&#125;.tar.gz nginx_hy* --remove#/usr/local/bin/aws s3 cp nginx_$&#123;DATETIME&#125;.tar.gz s3://hxs3/backup/## clenaupfind $ROOT -mtime +10 -type f -name &quot;*.gz&quot; | xargs rm -fvfind $ROOT -mtime +10 -type f -name &quot;*.zip&quot; | xargs rm -fvfind $ROOT -mtime +10 -type f -name &quot;*.tgz&quot; | xargs rm -fvfind $ROOT -mtime +10 -type f -name &quot;*.tar&quot; | xargs rm -fvfind /nfs_hy_backup/gitlab_hy/ -name &quot;*_gitlab_backup.tar&quot; -mtime +30 | xargs rm -fvfind /nfs_hy_backup/gitlab_hx/ -name &quot;*_gitlab_backup.tar&quot; -mtime +30 | xargs rm -fvfind /nfs_hy_backup/gitlab_aws/ -name &quot;*_gitlab_backup.tar&quot; -mtime +30 | xargs rm -fv## sync svnrsync -avzut -P --progress --delete root@10.77.114.99:/date/svn/ /nfs_hy_backup/svn_rsync/## sync hx-confluencersync -avzut -P --progress --delete root@10.77.114.101:/var/atlassian/ /nfs_hy_backup/confluence_rsync/confluence-data/rsync -avzut -P --progress --delete root@10.77.114.101:/opt/atlassian/confluence /nfs_hy_backup/confluence_rsync/confluence/## sync hx-jirarsync -avzut -P --progress --delete root@10.77.114.102:/var/atlassian/ /nfs_hy_backup/jira_rsync/jira-data/rsync -avzut -P --progress --delete root@10.77.114.102:/opt/atlassian/jira /nfs_hy_backup/jira_rsync/jira/## sync jenkinsrsync -avzut -P --progress --delete root@hy-base-01:/data/jenkins/ /nfs_hy_backup/jenkins_sync/jenkins/ --exclude logs --exclude temprsync -avzut -P --progress --delete root@hy-base-01:/data/jenkins_data/ /nfs_hy_backup/jenkins_sync/jenkins_data/ --exclude workspace## sync nexusrsync -avzut -P --progress --delete root@hy-base-01:/data/nexus/ /nfs_hy_backup/nexus_sync/nexus/ --exclude sonatype-work/nexus3/log## sync aws confluence,jirarsync -avzut -P --progress --delete root@hy-base-03:/data/atlassian/ /nfs_hy_backup/wiki_jira_rsync/atlassian/ --exclude confluence/logs --exclude confluence-data/logs --exclude jira/logs --exclude jira-data/logecho &quot;***********************************************************************&quot;echo $(date) &quot; -- backup end&quot;echo &quot;***********************************************************************&quot; nacos 备份脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/data/anaconda3/bin/python3.9from fileinput import filenameimport requestsimport jsonimport datetimeimport osfrom boto3.session import Session## s3 configaws_key = &quot;AKIAUPGCAPWX4FD5N2CO&quot;aws_secret = &quot;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&quot;region_name = &quot;cn-northwest-1&quot;session = Session(aws_access_key_id=aws_key,aws_secret_access_key=aws_secret,region_name=region_name)s3 = session.resource(&quot;s3&quot;)client = session.client(&quot;s3&quot;)bucket = &quot;hxs3&quot;## nacosnacos_list=[# &#x27;http://10.9.127.244:8848|c23a1b4c-e97f-45ae-a5c0-1e7f1a8d22e9|nacos|nacos|nacos-dev&#x27;, &#x27;http://nacos.farmbgy.net:8848|da7aaaa2-7505-4c1d-98c6-9e2e7778ef55|nacos|abc123!!!|nacos-prod&#x27;, &#x27;http://aws-sit-code-pro-01:8848|09a89c03-8f14-40a7-a44b-2be7e9f87e14|nacos|abc123!!!|nacos-sit&#x27;, &#x27;http://aws-jx-middle-01:8848|c876967c-d8dd-4318-9bf1-e7e72eb47d13|nacos|abc123!!!|nacos-jx&#x27;, &#x27;http://aws-show-middle-01:8848|da7aaaa2-7505-4c1d-98c6-9e2e7778ef55|nacos|abc123!!!|nacos-show&#x27;]for row in nacos_list: url,namespace,username,password,filename = row.strip().split(&#x27;|&#x27;) login_url = url+&#x27;/nacos/v1/auth/users/login&#x27; data = &#123;&#x27;username&#x27;:username, &#x27;password&#x27;:password&#125; s = requests.session() resp = s.post(login_url,data) token = json.loads(resp.text)[&#x27;accessToken&#x27;] backup_url = url+&#x27;/nacos/v1/cs/configs?export=true&amp;tenant=&#x27;+namespace+&#x27;&amp;group=&amp;appName=&amp;dataId=&amp;ids=&amp;accessToken=&#x27;+token filename = os.path.abspath(os.path.dirname(__file__))+&#x27;/&#x27;+filename+&#x27;-&#x27;+datetime.datetime.now().strftime(&#x27;%Y%m%d&#x27;)+&#x27;.zip&#x27; r = requests.get(backup_url) with open(filename, &quot;wb&quot;) as code: code.write(r.content) upload_data = open(filename,&quot;rb&quot;) upload_key = &quot;backup/&quot;+os.path.basename(filename) file_obj = s3.Bucket(bucket).put_object(Key=upload_key, Body=upload_data) print(file_obj)","categories":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"}]},{"title":"Docker-基本操作","slug":"docker-基本操作","date":"2022-11-27T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2022/11/28/docker-基本操作/","link":"","permalink":"https://biglovewheat.gihub.io/2022/11/28/docker-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"","text":"Docker-基本操作更改默认目录12345678## /etc/docker/daemon.json 加上docker -vDocker version 24.0.2, build cb74dfc&#123; &quot;data-root&quot;: &quot;/data/docker&quot;,&#125; Docker镜像导入导出123456docker save 605c77e624dd &gt;nginx.tardocker load &lt; nginx.tar## 多个镜像打一个包docker save nginx:latest rocketmq-exporter:latest -o aa.tardocker load -i aa.tar","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://biglovewheat.gihub.io/tags/docker/"}]},{"title":"Skywalking-链路跟踪部署","slug":"skywalking-链路跟踪部署","date":"2022-11-23T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/11/24/skywalking-链路跟踪部署/","link":"","permalink":"https://biglovewheat.gihub.io/2022/11/24/skywalking-%E9%93%BE%E8%B7%AF%E8%B7%9F%E8%B8%AA%E9%83%A8%E7%BD%B2/","excerpt":"","text":"skywalking链路跟踪部署Skywalking介绍Skywalking是分布式系统的应用程序性能监视工具，专为微服务，云原生架构和基于容器（Docker，K8S,Mesos）架构而设计，它是一款优秀的APM（Application Performance Management）工具，包括了分布式追踪，性能指标分析和服务依赖分析等。 skywalking架构图 Skywalking agent 和业务端绑定在一起，负责收集各种监控数据 Skywalking oapservice 是负责处理监控数据，接受agent的数据并存储在数据库中，接受来自UI的请求，查询监控数据。 Skywalking UI提供给用户，展现各种监控数据和告警。 skywalking安装部署-ESelasticsearch安装（略） skywalking安装部署-obs(server端)官网下载，解压压缩包 修改配置文件 vi skywalking&#x2F;config&#x2F;application.yml 123456789101112131415161718192021## 修改配置文件，使用nacos作为注册中心cluster: selector: $&#123;SW_CLUSTER:nacos&#125; nacos: serviceName: $&#123;SW_SERVICE_NAME:&quot;SkyWalking_OAP_Cluster&quot;&#125; hostPort: $&#123;SW_CLUSTER_NACOS_HOST_PORT:192.168.8.101:8848&#125; # Nacos Configuration namespace namespace: $&#123;SW_CLUSTER_NACOS_NAMESPACE:&quot;c23a1b4c-e97f-45ae-a5c0-1e7f1a8d22e9&quot;&#125; # Nacos auth username username: $&#123;SW_CLUSTER_NACOS_USERNAME:&quot;&quot;&#125; password: $&#123;SW_CLUSTER_NACOS_PASSWORD:&quot;&quot;&#125; # Nacos auth accessKey accessKey: $&#123;SW_CLUSTER_NACOS_ACCESSKEY:&quot;&quot;&#125; secretKey: $&#123;SW_CLUSTER_NACOS_SECRETKEY:&quot;&quot;&#125;## es作为后端存储storage: selector: $&#123;SW_STORAGE:elasticsearch&#125; elasticsearch: namespace: $&#123;SW_NAMESPACE:&quot;&quot;&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:10.9.127.36:9200&#125; 修改UI配置 12345## 主要修改端口skywalking/webapp/webapp.ymlserver: port: 12080 同时启动oap和UI 1skywalking/bin/startup.sh 启动成功后，可以在nacos上看到SkyWalking_OAP_Cluster skywalking安装部署-agent(spring boot)123456789101112## 下载agentwget https://www.apache.org/dyn/closer.cgi/skywalking/java-agent/8.13.0/apache-skywalking-java-agent-8.13.0.tgz## 修改配置vi ./config/agent.config#主要修改oap的IP，多个IP可用逗号隔开collector.backend_service=$&#123;SW_AGENT_COLLECTOR_BACKEND_SERVICES:192.168.8.101:11800&#125;## sprintboot增加启动参数nohup java -javaagent:/data/skywalking/skywalking-agent/skywalking-agent.jar \\ -Dskywalking.agent.service_name=$&#123;svc&#125; \\ $&#123;JAVA_OPS&#125; -jar $&#123;APP_HOME&#125;/$&#123;svc&#125;.jar --spring.profiles.active=$ \\&#123;SPRING_ENV&#125; &gt;&gt; $&#123;APP_HOME&#125;/$&#123;svc&#125;.log 2&gt;&amp;1 &amp; 登录UI，可以查看到监控情况日志默认是没有开启日志监控，需要修改java程序（自行百度） 告警&lt;待补充&gt;","categories":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"skywalking","slug":"skywalking","permalink":"https://biglovewheat.gihub.io/tags/skywalking/"}]},{"title":"Softether-vpn搭建vpn","slug":"softether-vpn搭建vpn","date":"2022-11-03T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/11/04/softether-vpn搭建vpn/","link":"","permalink":"https://biglovewheat.gihub.io/2022/11/04/softether-vpn%E6%90%AD%E5%BB%BAvpn/","excerpt":"","text":"Softether-vpn搭建vpn服务器端官网下载http://softether.fishinfo.cn/cn.aspx 12345## 解压后安装./.install.sh## 运行vpnserver start windows 服务器端管理官网下载Manager for Windows 1、新建链接，输入IP，确定。2、第一次链接需输入管密码。3、链接server","categories":[{"name":"network","slug":"network","permalink":"https://biglovewheat.gihub.io/categories/network/"}],"tags":[{"name":"network","slug":"network","permalink":"https://biglovewheat.gihub.io/tags/network/"},{"name":"vpn","slug":"vpn","permalink":"https://biglovewheat.gihub.io/tags/vpn/"}]},{"title":"将域名绑定到非80端口","slug":"将域名绑定到非80端口","date":"2022-10-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/10/26/将域名绑定到非80端口/","link":"","permalink":"https://biglovewheat.gihub.io/2022/10/26/%E5%B0%86%E5%9F%9F%E5%90%8D%E7%BB%91%E5%AE%9A%E5%88%B0%E9%9D%9E80%E7%AB%AF%E5%8F%A3/","excerpt":"","text":"将域名绑定到非80端口需求某些情况下，无法获取到80&#x2F;433端口，这里提供一个临时办法，将域名绑定到主机非80&#x2F;443端口 例子阿里云-云解析为例 域名：abc.com 主机：123.123.123.123:8080 a记录:xxx.abc.com 绑定到 123.123.123.123 隐性URL:www.abc.com 绑定到 http://xxx.abc.com:8080 完成后，访问www.abc.com 解析到 123.123.123.123:8080 问题设置隐性URL后，由于多了一层跳转，可能会造成网站显示不正常，无法获取标题等一系列问题","categories":[{"name":"云原生","slug":"云原生","permalink":"https://biglovewheat.gihub.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"dns","slug":"dns","permalink":"https://biglovewheat.gihub.io/tags/dns/"}]},{"title":"Jenkins-按视图批量复制项目","slug":"jenkins-按视图批量复制项目","date":"2022-10-11T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/10/12/jenkins-按视图批量复制项目/","link":"","permalink":"https://biglovewheat.gihub.io/2022/10/12/jenkins-%E6%8C%89%E8%A7%86%E5%9B%BE%E6%89%B9%E9%87%8F%E5%A4%8D%E5%88%B6%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"Jenkins-按视图批量复制项目新建一个视图jenkins–Manage Jenkins–Script Console1234567891011121314151617181920212223242526272829303132333435363738394041import hudson.model.* //源view def str_view = &quot;2dev前端&quot; //目标view def str_new_view = &quot;test&quot; //源job名称(模糊匹配) def str_search = &quot;-dev&quot; //目标job名称(模糊匹配后替换) def str_replace = &quot;-dev-copy&quot; def view = Hudson.instance.getView(str_view) Hudson.instance.addView(new ListView(str_new_view)) //copy all projects of a view for(item in view.getItems()) &#123; //跳过未模糊匹配到的构建 任务 if (!item.getName().contains(str_search)) &#123; // 说明文字，表示跳过未匹配到的job，可加可不加 // println(&quot;but $item.name ignore &quot;) continue &#125; //create the new project name newName = item.getName().replace(str_search, str_replace) // copy the job, disable and save it def job try &#123; job = Hudson.instance.copy(item, newName) &#125; catch(IllegalArgumentException e) &#123; println(&quot;$newName job is exists&quot;) continue &#125; catch(Exception e) &#123; println(e.toString()) continue &#125;// job.disabled = true job.save() println(&quot; $item.name copied as $newName is success&quot;) &#125;","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"jenkins","slug":"jenkins","permalink":"https://biglovewheat.gihub.io/tags/jenkins/"}]},{"title":"Centos7-安装gcc8","slug":"centos7-安装gcc8","date":"2022-09-27T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2022/09/28/centos7-安装gcc8/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/28/centos7-%E5%AE%89%E8%A3%85gcc8/","excerpt":"","text":"Centos7-安装gcc812345678910111213141516## centos7#安装scl源yum install centos-release-scl scl-utils-build#安装工具链8yum install -y devtoolset-8-toolchainscl enable devtoolset-8 bash#确认版本gcc --versionstrings /usr/lib64/libstdc++.so.6 | grep GLIBCcd /usr/lib64/; ls -l libstdc++.so.6*libstdc++.so.6.0.26ln -sf libstdc++.so.6.0.26 libstdc++.so.6","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Seata-安装","slug":"seata-安装","date":"2022-09-20T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/09/21/seata-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/21/seata-%E5%AE%89%E8%A3%85/","excerpt":"","text":"Seata-安装Seata 是一款开源的分布式事务解决方案 http://seata.io/zh-cn/ 版本v1.4.2 数据库配置创建seata数据库，然后运行以下建表语句 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576--https://github.com/seata/seata/tree/develop/script/server/db-- -------------------------------- The script used when storeMode is &#x27;db&#x27; ---------------------------------- the table to store GlobalSession dataCREATE TABLE IF NOT EXISTS `global_table`( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_status_gmt_modified` (`status` , `gmt_modified`), KEY `idx_transaction_id` (`transaction_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4;-- the table to store BranchSession dataCREATE TABLE IF NOT EXISTS `branch_table`( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`)) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4;-- the table to store lock dataCREATE TABLE IF NOT EXISTS `lock_table`( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(128), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `status` TINYINT NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;0:locked ,1:rollbacking&#x27;, `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_status` (`status`), KEY `idx_branch_id` (`branch_id`), KEY `idx_xid` (`xid`)) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4;CREATE TABLE IF NOT EXISTS `distributed_lock`( `lock_key` CHAR(20) NOT NULL, `lock_value` VARCHAR(20) NOT NULL, `expire` BIGINT, primary key (`lock_key`)) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4;INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES (&#x27;AsyncCommitting&#x27;, &#x27; &#x27;, 0);INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES (&#x27;RetryCommitting&#x27;, &#x27; &#x27;, 0);INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES (&#x27;RetryRollbacking&#x27;, &#x27; &#x27;, 0);INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES (&#x27;TxTimeoutCheck&#x27;, &#x27; &#x27;, 0); nacos配置新建配置seataServer.properties 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111#For details about configuration items, see https://seata.io/zh-cn/docs/user/configurations.html#Transport configuration, for client and servertransport.type=TCPtransport.server=NIOtransport.heartbeat=truetransport.enableTmClientBatchSendRequest=falsetransport.enableRmClientBatchSendRequest=truetransport.enableTcServerBatchSendResponse=falsetransport.rpcRmRequestTimeout=30000transport.rpcTmRequestTimeout=30000transport.rpcTcRequestTimeout=30000transport.threadFactory.bossThreadPrefix=NettyBosstransport.threadFactory.workerThreadPrefix=NettyServerNIOWorkertransport.threadFactory.serverExecutorThreadPrefix=NettyServerBizHandlertransport.threadFactory.shareBossWorker=falsetransport.threadFactory.clientSelectorThreadPrefix=NettyClientSelectortransport.threadFactory.clientSelectorThreadSize=1transport.threadFactory.clientWorkerThreadPrefix=NettyClientWorkerThreadtransport.threadFactory.bossThreadSize=1transport.threadFactory.workerThreadSize=defaulttransport.shutdown.wait=3transport.serialization=seatatransport.compressor=none#Transaction routing rules configuration, only for the client# 默认的事务分组service.vgroupMapping.default_tx_group=default#If you use a registry, you can ignore itservice.default.grouplist=172.31.43.98:8491service.enableDegrade=falseservice.disableGlobalTransaction=false#Transaction rule configuration, only for the clientclient.rm.asyncCommitBufferLimit=10000client.rm.lock.retryInterval=10client.rm.lock.retryTimes=30client.rm.lock.retryPolicyBranchRollbackOnConflict=trueclient.rm.reportRetryCount=5client.rm.tableMetaCheckEnable=trueclient.rm.tableMetaCheckerInterval=60000client.rm.sqlParserType=druidclient.rm.reportSuccessEnable=falseclient.rm.sagaBranchRegisterEnable=falseclient.rm.sagaJsonParser=fastjsonclient.rm.tccActionInterceptorOrder=-2147482648client.tm.commitRetryCount=5client.tm.rollbackRetryCount=5client.tm.defaultGlobalTransactionTimeout=60000client.tm.degradeCheck=falseclient.tm.degradeCheckAllowTimes=10client.tm.degradeCheckPeriod=2000client.tm.interceptorOrder=-2147482648client.undo.dataValidation=trueclient.undo.logSerialization=jacksonclient.undo.onlyCareUpdateColumns=trueserver.undo.logSaveDays=7server.undo.logDeletePeriod=86400000client.undo.logTable=undo_logclient.undo.compress.enable=trueclient.undo.compress.type=zipclient.undo.compress.threshold=64k#For TCC transaction modetcc.fence.logTableName=tcc_fence_logtcc.fence.cleanPeriod=1h#Log rule configuration, for client and serverlog.exceptionRate=100#Transaction storage configuration, only for the server. The file, DB, and redis configuration values are optional.# Seata服务器的数据存储方式设置为数据库存储store.mode=dbstore.lock.mode=dbstore.session.mode=file#Used for password encryptionstore.publicKey=#If `store.mode,store.lock.mode,store.session.mode` are not equal to `file`, you can remove the configuration block.store.file.dir=file_store/datastore.file.maxBranchSessionSize=16384store.file.maxGlobalSessionSize=512store.file.fileWriteBufferCacheSize=16384store.file.flushDiskMode=asyncstore.file.sessionReloadReadSize=100#These configurations are required if the `store mode` is `db`. If `store.mode,store.lock.mode,store.session.mode` are not equal to `db`, you can remove the configuration block.store.db.datasource=druidstore.db.dbType=mysqlstore.db.driverClassName=com.mysql.cj.jdbc.Driver### 设置数据库得连接信息store.db.url=jdbc:mysql://192.168.8.1:3306/seata?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=Asia/Shanghaistore.db.user=rootstore.db.password=123456store.db.minConn=5store.db.maxConn=30store.db.globalTable=global_tablestore.db.branchTable=branch_tablestore.db.distributedLockTable=distributed_lockstore.db.queryLimit=100store.db.lockTable=lock_tablestore.db.maxWait=5000#Transaction rule configuration, only for the serverserver.recovery.committingRetryPeriod=1000server.recovery.asynCommittingRetryPeriod=1000server.recovery.rollbackingRetryPeriod=1000server.recovery.timeoutRetryPeriod=1000server.maxCommitRetryTimeout=-1server.maxRollbackRetryTimeout=-1server.rollbackRetryTimeoutUnlockEnable=falseserver.distributedLockExpireTime=10000server.xaerNotaRetryTimeout=60000server.session.branchAsyncQueueSize=5000server.session.enableBranchAsyncRemove=false#Metrics configuration, only for the servermetrics.enabled=falsemetrics.registryType=compactmetrics.exporterList=prometheusmetrics.exporterPrometheusPort=9898 seata配置文件主要修改nacos部分 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798## vi registry.confregistry &#123; # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = &quot;nacos&quot; nacos &#123; application = &quot;seata-server&quot; serverAddr = &quot;192.168.8.1:8848&quot; group = &quot;DEFAULT_GROUP&quot; namespace = &quot;da7aaaa2-7505-4c1d-98c6-9e2e7778ef55&quot; cluster = &quot;default&quot; username = &quot;&quot; password = &quot;&quot; &#125; eureka &#123; serviceUrl = &quot;http://localhost:8761/eureka&quot; application = &quot;default&quot; weight = &quot;1&quot; &#125; redis &#123; serverAddr = &quot;localhost:6379&quot; db = 0 password = &quot;&quot; cluster = &quot;default&quot; timeout = 0 &#125; zk &#123; cluster = &quot;default&quot; serverAddr = &quot;127.0.0.1:2181&quot; sessionTimeout = 6000 connectTimeout = 2000 username = &quot;&quot; password = &quot;&quot; &#125; consul &#123; cluster = &quot;default&quot; serverAddr = &quot;127.0.0.1:8500&quot; aclToken = &quot;&quot; &#125; etcd3 &#123; cluster = &quot;default&quot; serverAddr = &quot;http://localhost:2379&quot; &#125; sofa &#123; serverAddr = &quot;127.0.0.1:9603&quot; application = &quot;default&quot; region = &quot;DEFAULT_ZONE&quot; datacenter = &quot;DefaultDataCenter&quot; cluster = &quot;default&quot; group = &quot;SEATA_GROUP&quot; addressWaitTime = &quot;3000&quot; &#125; file &#123; name = &quot;file.conf&quot; &#125;&#125;config &#123; # file、nacos 、apollo、zk、consul、etcd3 type = &quot;nacos&quot; nacos &#123; serverAddr = &quot;192.168.8.1:8848&quot; namespace = &quot;&quot; group = &quot;DEFAULT_GROUP&quot; username = &quot;&quot; password = &quot;&quot; dataId = &quot;seataServer.properties&quot; &#125; consul &#123; serverAddr = &quot;127.0.0.1:8500&quot; aclToken = &quot;&quot; &#125; apollo &#123; appId = &quot;seata-server&quot; ## apolloConfigService will cover apolloMeta apolloMeta = &quot;http://192.168.1.204:8801&quot; apolloConfigService = &quot;http://192.168.1.204:8080&quot; namespace = &quot;application&quot; apolloAccesskeySecret = &quot;&quot; cluster = &quot;seata&quot; &#125; zk &#123; serverAddr = &quot;127.0.0.1:2181&quot; sessionTimeout = 6000 connectTimeout = 2000 username = &quot;&quot; password = &quot;&quot; nodePath = &quot;/seata/seata.properties&quot; &#125; etcd3 &#123; serverAddr = &quot;http://localhost:2379&quot; &#125; file &#123; name = &quot;file.conf&quot; &#125;&#125; 启动脚本12345678910cat &lt;&lt;EOF &gt; /data/seata/startup.sh#!/bin/shexport JAVA_HOME=/data/soft/jdk-11.0.11export PATH=$JAVA_HOME/bin:$PATHnohup /data/seata/bin/seata-server.sh -p 8491 &gt;&gt; /data/seata/seata.log 2&gt;&amp;1 &amp;EOFchmod u+x /data/seata/startup.sh 做成service方便管理1234567891011121314151617181920cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/seata.service[Unit]Description=seataAfter=network.target[Service]Type=forkingUser=rootExecStart=/data/seata/startup.shExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPID[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reload systemctl enable seatasystemctl restart seata","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"seata","slug":"seata","permalink":"https://biglovewheat.gihub.io/tags/seata/"}]},{"title":"Jenkins-npm-构建报错","slug":"jenkins-npm-构建报错","date":"2022-09-12T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/09/13/jenkins-npm-构建报错/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/13/jenkins-npm-%E6%9E%84%E5%BB%BA%E6%8A%A5%E9%94%99/","excerpt":"","text":"Jenkins-npm-构建报错jenkins npm 编译报错，手工构建成功 问题排查 解决办法1234567891011121314151617## 构建脚本加上CI=false export CI=false yarn install npm run build## 或者代码加上CI=false# package.json &quot;scripts&quot;: &#123; &quot;start&quot;: &quot;craco start&quot;, &quot;build&quot;: &quot;CI=false &amp;&amp; craco build&quot;, &quot;test&quot;: &quot;craco test&quot;, &quot;eject&quot;: &quot;react-scripts eject&quot;, &quot;lint&quot;: &quot;eslint .&quot;, &quot;lint:fix&quot;: &quot;eslint --fix&quot;, &quot;format&quot;: &quot;prettier --write &#x27;./**/*.&#123;js,jsx,ts,tsx,css,md,json&#125;&#x27; --config ./.prettierrc&quot; &#125;,","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"jenkins","slug":"jenkins","permalink":"https://biglovewheat.gihub.io/tags/jenkins/"},{"name":"nodejs","slug":"nodejs","permalink":"https://biglovewheat.gihub.io/tags/nodejs/"}]},{"title":"Ansible-修改hosts","slug":"ansible-修改hosts","date":"2022-09-07T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2022/09/08/ansible-修改hosts/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/08/ansible-%E4%BF%AE%E6%94%B9hosts/","excerpt":"","text":"Ansible-修改hostsansible命令1234ansible all -i all.lst -m script -a &quot;script_hosts.sh&quot; -u ops_root -k## -i 指定清单文件## -m 模块 设置&#x2F;etc&#x2F;hosts命令1234567891011#!/bin/bashsudo /bin/bash -c &quot;cat &gt; /etc/hosts &quot; &lt;&lt;EOF127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6## prod172.31.62.90 aws-prod-app-01172.31.51.65 aws-prod-app-02172.31.58.171 aws-prod-app-03EOF","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"https://biglovewheat.gihub.io/tags/ansible/"},{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"}]},{"title":"Oracle-undo","slug":"oracle-undo","date":"2022-09-06T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/09/07/oracle-undo/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/07/oracle-undo/","excerpt":"","text":"Oracle-undo查看磁盘空间undo表空间使用率12345678910111213141516selecte.tablespace_name,max(total) total,sum(decode(e.status,&#x27;ACTIVE&#x27;,G,0)) active,sum(decode(e.status,&#x27;UNEXPIRED&#x27;,G,0)) unexpired,sum(decode(e.status,&#x27;EXPIRED&#x27;,G,0)) expired,round((sum(decode(e.status,&#x27;ACTIVE&#x27;,G,0))+sum(decode(e.status,&#x27;UNEXPIRED&#x27;,G,0)))/max(total)*100,2) real_use_pctfrom(select tablespace_name,round(sum(bytes)/1024/1024/1024,2) totalfrom dba_data_filesgroup by tablespace_name) f,(SELECT tablespace_name,status,round(SUM(bytes)/1024/1024/1024,2) Gfrom dba_undo_extentsgroup by tablespace_name,status) ewhere f.tablespace_name=e.tablespace_namegroup by e.tablespace_name; undo_retention 参数修改123456789101112SQL&gt; show parameter undoNAME TYPE VALUE------------------------------------ ----------- ------------------------------_in_memory_undo boolean FALSEundo_management string AUTOundo_retention integer 14400undo_tablespace string PSAPUNDOSQL&gt; alter system set undo_retention=10800 scope=both;System altered. undo占用语句查询12345select distinct s.machine,s.program,s.sid,round(t.used_ublk*8/1024/1024,2) undo_GB,used_urec undo_records,s.status,l.sql_textfrom v$transaction t,gv$session s,v$sqlstats lwhere t.ses_addr=s.saddrand s.sql_id=l.sql_id(+)order by undo_GB desc ; undo表空间扩容12345678910111213sqlplus -S / as sysdba &gt;undo.log &lt;&lt;EOFalter tablespace PSAPUNDO add datafile &#x27;/oradata6/EP1/sapdata13/undo.data27&#x27; size 30G ;alter tablespace PSAPUNDO add datafile &#x27;/oradata6/EP1/sapdata13/undo.data28&#x27; size 30G ;alter tablespace PSAPUNDO add datafile &#x27;/oradata6/EP1/sapdata13/undo.data29&#x27; size 30G ;alter tablespace PSAPUNDO add datafile &#x27;/oradata6/EP1/sapdata13/undo.data30&#x27; size 30G ;alter tablespace PSAPUNDO add datafile &#x27;/oradata6/EP1/sapdata13/undo.data31&#x27; size 30G ;alter tablespace PSAPUNDO add datafile &#x27;/oradata6/EP1/sapdata13/undo.data32&#x27; size 30G ;alter tablespace PSAPUNDO add datafile &#x27;/oradata6/EP1/sapdata13/undo.data33&#x27; size 30G ;alter tablespace PSAPUNDO add datafile &#x27;/oradata6/EP1/sapdata13/undo.data34&#x27; size 30G ;exitEOF undo隐藏参数调整12345678910111213141516SQL&gt; select a.ksppinm name,b.ksppstvl value,a.ksppdesc descriptionfrom x$ksppi a,x$ksppcv bwhere a.indx = b.indxand a.ksppinm like &#x27;%_undo_autotune%&#x27;;NAME--------------------------------------------------------------------------------VALUE----------------------------------------------------------------------------------------------------DESCRIPTION----------------------------------------------------------------------------------------------------_undo_autotuneTRUEenable auto tuning of undo_retentionSQL&gt; alter system set &quot;_undo_autotune&quot; = false; 创建undo表空间1create undo tablespace UNDOTBS1 datafile &#x27;/opt/oracle/oradata/CMCCWAP/undotbs01.dbf&#x27; size 200m autoextend on; undo相关视图12select * from v$undostat;select * from dba_hist_undostat;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://biglovewheat.gihub.io/tags/oracle/"}]},{"title":"Docker-Dockerfile","slug":"docker-dockerfile","date":"2022-09-05T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2022/09/06/docker-dockerfile/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/06/docker-dockerfile/","excerpt":"","text":"Docker-Dockerfilenginx12345From nginx:1.20-alpineRUN cp -a /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeCOPY ./dist /distCOPY ./nginx.conf /etc/nginx/nginx.confCMD [&quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;]","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://biglovewheat.gihub.io/tags/docker/"}]},{"title":"Oracle-sqluldr2-导出数据","slug":"oracle-sqluldr2-导出数据","date":"2022-09-05T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/09/06/oracle-sqluldr2-导出数据/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/06/oracle-sqluldr2-%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE/","excerpt":"","text":"Oracle-sqluldr2-导出数据命令行执行123456## user=oradds/oradds --登录用户名、密码## sql=ts.sql --提数sql## file=ts.csv --输出文件## head=yes --是否保留表头## log=ts.log --日志sqluldr2.bin user=oradds/oradds sql=ts.sql file=ts.csv head=yes log=ts.log array=500 每100w行分割成一个文件（batch&#x3D;yes，row&#x3D;1000000，file加上变量%b）1sqluldr2.bin user=oradds/oradds sql=ts.sql file=ts_%b.csv head=yes log=ts.log array=500 batch=yes row=1000000 以竖线（“|”）为分隔符1sqluldr2.bin user=oradds/oradds sql=ts.sql file=ts.csv head=yes log=ts.log array=500 field=0x7c","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://biglovewheat.gihub.io/tags/oracle/"}]},{"title":"Postgresql-dblink使用","slug":"postgresql-dblink使用","date":"2022-09-05T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/09/06/postgresql-dblink使用/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/06/postgresql-dblink%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Postgresql-dblink使用123456789101112131415161718-- 开启dblinkcreate EXTENSION dblink if not EXISTS;-- 新建dblinkselect dblink_connect(&#x27;dblinktest&#x27;,&#x27;host=192.168.8.201 dbname=hxtest user=postgres password=654321&#x27;); -- 查询现有dblinkselect dblink_get_connections();-- 通过dblink查询表select * from dblink(&#x27;dblinktest&#x27;,&#x27;select gid,code from d_farmland;&#x27;)as t_d_farmland(gid int,d_farmland varchar(20));-- 断开dblinkselect dblink_disconnect(&#x27;dblinktest&#x27;);-- 断开所有select dblink_disconnect();","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://biglovewheat.gihub.io/tags/postgresql/"}]},{"title":"Oracle-表空间扩容","slug":"oracle-表空间扩容","date":"2022-09-05T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/09/06/oracle-表空间扩容/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/06/oracle-%E8%A1%A8%E7%A9%BA%E9%97%B4%E6%89%A9%E5%AE%B9/","excerpt":"","text":"Oracle-表空间扩容查看磁盘空间查看表空间使用率123456789101112131415161718192021222324252627282930313233343536373839Select ts.tablespace_name, ts.status, ts.contents, ts.extent_management, ts.bigfile, size_info.megs_alloc, size_info.megs_free, size_info.megs_used, size_info.pct_free, size_info.pct_used, size_info.max From ( select a.tablespace_name, round(a.bytes_alloc / 1024 / 1024) megs_alloc, round(nvl(b.bytes_free, 0) / 1024 / 1024) megs_free, round((a.bytes_alloc - nvl(b.bytes_free, 0)) / 1024 / 1024) megs_used, round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) Pct_Free, 100 - round((nvl(b.bytes_free, 0) / a.bytes_alloc) * 100) Pct_used, round(maxbytes/1048576) Max from ( select f.tablespace_name, sum(f.bytes) bytes_alloc, sum(decode(f.autoextensible, &#x27;YES&#x27;,f.maxbytes,&#x27;NO&#x27;, f.bytes)) maxbytes from dba_data_files f group by tablespace_name) a, ( select f.tablespace_name, sum(f.bytes) bytes_free from dba_free_space f group by tablespace_name) b where a.tablespace_name = b.tablespace_name (+) union all select h.tablespace_name, round(sum(h.bytes_free + h.bytes_used) / 1048576) megs_alloc, round(sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / 1048576) megs_free, round(sum(nvl(p.bytes_used, 0))/ 1048576) megs_used, round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) Pct_Free, 100 - round((sum((h.bytes_free + h.bytes_used) - nvl(p.bytes_used, 0)) / sum(h.bytes_used + h.bytes_free)) * 100) pct_used, round(sum(decode(f.autoextensible, &#x27;YES&#x27;, f.maxbytes, &#x27;NO&#x27;, f.bytes) / 1048576)) max from sys.v_$TEMP_SPACE_HEADER h, sys.v_$Temp_extent_pool p, dba_temp_files f where p.file_id(+) = h.file_id and p.tablespace_name(+) = h.tablespace_name and f.file_id = h.file_id and f.tablespace_name = h.tablespace_name group by h.tablespace_name ) size_info, sys.dba_tablespaces ts where ts.tablespace_name = size_info.tablespace_name; 表空间扩容12--数据文件一般按序号添加，所以首先要找到最大一个数据文件的编号，再按顺序增加alter tablespace PSAPSR3 add datafile &#x27;/dataQF/qfdata/oradata/qfdata3/PSAPSR780.DBF&#x27; size 30G;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://biglovewheat.gihub.io/tags/oracle/"}]},{"title":"Python-Nacos-备份","slug":"python-nacos-备份","date":"2022-09-01T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/09/02/python-nacos-备份/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/02/python-nacos-%E5%A4%87%E4%BB%BD/","excerpt":"","text":"Python-Nacos-备份一个python写的nacos配置备份，并上传到s3的脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#!/usr/bin/python3 from fileinput import filenameimport requestsimport jsonimport datetimeimport osfrom boto3.session import Session## s3 configaws_key = &quot;XXXX&quot;aws_secret = &quot;XXXX&quot;region_name = &quot;cn-northwest-1&quot;session = Session(aws_access_key_id=aws_key,aws_secret_access_key=aws_secret,region_name=region_name)s3 = session.resource(&quot;s3&quot;)client = session.client(&quot;s3&quot;)bucket = &quot;hxs3&quot;## nacosnacos_list=[ &#x27;http://10.9.127.244:8848|c23a1b4c-e97f-45ae-a5c0-1e7f1a8d22e9|nacos|nacos|nacos-dev&#x27;, &#x27;http://10.9.127.245:8848|da7aaaa2-7505-4c1d-98c6-9e2e7778ef55|nacos|nacos|nacos-prod&#x27;]for row in nacos_list: url,namespace,username,password,filename = row.strip().split(&#x27;|&#x27;) login_url = url+&#x27;/nacos/v1/auth/users/login&#x27; data = &#123;&#x27;username&#x27;:username, &#x27;password&#x27;:password&#125; s = requests.session() resp = s.post(login_url,data) token = json.loads(resp.text)[&#x27;accessToken&#x27;] backup_url = url+&#x27;/nacos/v1/cs/configs?export=true&amp;tenant=&#x27;+namespace+&#x27;&amp;group=&amp;appName=&amp;dataId=&amp;ids=&amp;accessToken=&#x27;+token filename = os.path.abspath(os.path.dirname(__file__))+&#x27;/&#x27;+filename+&#x27;-&#x27;+datetime.datetime.now().strftime(&#x27;%Y%m%d&#x27;)+&#x27;.zip&#x27; r = requests.get(backup_url) with open(filename, &quot;wb&quot;) as code: code.write(r.content) upload_data = open(filename,&quot;rb&quot;) upload_key = &quot;backup/&quot;+os.path.basename(filename) file_obj = s3.Bucket(bucket).put_object(Key=upload_key, Body=upload_data) print(file_obj)","categories":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"},{"name":"nacos","slug":"nacos","permalink":"https://biglovewheat.gihub.io/tags/nacos/"}]},{"title":"Java-程序占用cpu高排查","slug":"java-程序占用cpu高排查","date":"2022-08-31T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/09/01/java-程序占用cpu高排查/","link":"","permalink":"https://biglovewheat.gihub.io/2022/09/01/java-%E7%A8%8B%E5%BA%8F%E5%8D%A0%E7%94%A8cpu%E9%AB%98%E6%8E%92%E6%9F%A5/","excerpt":"","text":"Java程序占用cpu高排查1234567891011## top + 大写C 用cpu占用率排序，记录进程top## top -Hp ，记录该进程中的线程号top -Hp 26750## 找到占用最高的线程，将pid换算成16进制printf &#x27;%x\\n&#x27; 26751## 通过jstack找到线程信息jstack 26750 |grep xxxxx","categories":[{"name":"故障排查","slug":"故障排查","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"}],"tags":[{"name":"java","slug":"java","permalink":"https://biglovewheat.gihub.io/tags/java/"}]},{"title":"K8s-crontabjob","slug":"k8s-crontabjob","date":"2022-08-29T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/30/k8s-crontabjob/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/30/k8s-crontabjob/","excerpt":"","text":"K8s-crontabjob123456789101112131415161718## Cronjob的时区和kube-controller-manager服务的时区一致,默认为0时区,需-8小时## 或修改kube-controller-manager时区apiVersion: batch/v1beta1kind: CronJobmetadata: name: hx-python-jiage namespace: devspec: schedule: &quot;2 16 * * *&quot; jobTemplate: spec: template: spec: containers: - name: hx-python-jiage image: 10.9.127.243:30002/library/hx-python-jiage:1.0 imagePullPolicy: IfNotPresent restartPolicy: OnFailure","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"K8s-组件安装","slug":"k8s-组件安装","date":"2022-08-29T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/30/k8s-组件安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/30/k8s-%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/","excerpt":"","text":"K8s-组件安装12345678## metricskubectl apply -f https://download.osichina.net/tools/kubernetes/metrics-server/components.yaml## deshboardkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml## calicokubectl apply -f https://docs.projectcalico.org/v3.19/manifests/calico.yaml","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"Lvs-keepalived-安装配置","slug":"lvs-keepalive-安装","date":"2022-08-29T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/30/lvs-keepalive-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/30/lvs-keepalive-%E5%AE%89%E8%A3%85/","excerpt":"","text":"Lvs-keepalived-安装配置实验 主机 软件 IP vip 192.168.8.209 lvs1 lvs+keepalived 192.168.8.201 lvs2 lvs+keepalived 192.168.8.202 nginx1 nginx 192.168.8.203 nginx2 nginx 192.168.8.204 lvs和keepalived安装12345678910111213141516## 安装lvs管理工具ipvsadmyum install -y gcc openssl openssl-devel ipvsadm## keepalived 编译安装./configure --prefix=/usr/local/keepalivedmake &amp;&amp; make install## keepalived 注册服务 &amp; 开机启动cp /soft/keepalived-2.0.20/keepalived/etc/init.d/keepalived /etc/init.d/cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/mkdir -p /etc/keepalived/cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/cp /usr/local/keepalived/sbin/keepalived /usr/sbinsystemctl enable keepalivedsystemctl restart keepalived lvs1(主机)配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152cat /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; #xxxx@itcast.com # 发生故障时发送的邮箱 &#125; #notification_email_from xxxx@itcast.com # 使用哪个邮箱发送 #smtp_server xxx.com # 发件服务器 smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_instance VI_1 &#123; state MASTER # 标示为主lvs interface ens33 # HA检测端口 virtual_router_id 66 # 主备的virtual_router_id 必须相同 priority 100 # 优先级,备lvs要比主lvs稍小 advert_int 1 # VRRP Multicast 广播周期秒数 authentication &#123; # 定义认证 auth_type PASS # 认证方式为口令认证 auth_pass 6666 # 定义口令 &#125; virtual_ipaddress &#123; # 定义vip 192.168.3.209 # 多个vip可换行添加 &#125;&#125;virtual_server 192.168.3.209 80 &#123; delay_loop 6 # 每隔6秒查看realserver状态 lb_algo wlc # 调度算法为加权最小连接数 lb_kind DR # lvs工作模式为DR(直接路由)模式 nat_mask 255.255.255.0 persistence_timeout 50 # 同一IP 的连接50秒内被分配到同一台realserver(测试时建议改为0) protocol TCP # 用TCP监测realserver的状态 real_server 192.168.3.203 80 &#123; # 定义realserver weight 3 # 定义权重 TCP_CHECK &#123; # 注意TCP_CHECK和&#123;之间的空格,如果没有的话只会添加第一个realserver connect_timeout 3 # 三秒无响应超时 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.3.204 80 &#123; weight 3 TCP_CHECK &#123; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; lvs2(备机)配置配置和主机相同，唯一区别是priority的值要少于主机 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152cat /etc/keepalived/keepalived.conf! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; #xxxx@itcast.com # 发生故障时发送的邮箱 &#125; #notification_email_from xxxx@itcast.com # 使用哪个邮箱发送 #smtp_server xxx.com # 发件服务器 smtp_connect_timeout 30 router_id LVS_DEVEL&#125;vrrp_instance VI_1 &#123; state BACKUP # 标示为主lvs interface ens33 # HA检测端口 virtual_router_id 66 # 主备的virtual_router_id 必须相同 priority 99 # 优先级,备lvs要比主lvs稍小 advert_int 1 # VRRP Multicast 广播周期秒数 authentication &#123; # 定义认证 auth_type PASS # 认证方式为口令认证 auth_pass 6666 # 定义口令 &#125; virtual_ipaddress &#123; # 定义vip 192.168.3.209 # 多个vip可换行添加 &#125;&#125;virtual_server 192.168.3.209 80 &#123; delay_loop 6 # 每隔6秒查看realserver状态 lb_algo wlc # 调度算法为加权最小连接数 lb_kind DR # lvs工作模式为DR(直接路由)模式 nat_mask 255.255.255.0 persistence_timeout 50 # 同一IP 的连接50秒内被分配到同一台realserver(测试时建议改为0) protocol TCP # 用TCP监测realserver的状态 real_server 192.168.3.203 80 &#123; # 定义realserver weight 3 # 定义权重 TCP_CHECK &#123; # 注意TCP_CHECK和&#123;之间的空格,如果没有的话只会添加第一个realserver connect_timeout 3 # 三秒无响应超时 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125; real_server 192.168.3.204 80 &#123; weight 3 TCP_CHECK &#123; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 connect_port 80 &#125; &#125;&#125; lvs配置将lvs启动配置成服务，随开机启动（lvs1、lvs2都需配置） 1234567891011121314151617181920212223242526272829303132vi /etc/init.d/lvs_dr_rs#!/bin/sh#chkconfig:345 85 15#description:lvs_dr_rsVIP=192.168.3.209. /etc/rc.d/init.d/functionscase $1 in start) echo &quot;lo:0 port starting&quot; ifconfig lo:0 $VIP broadcast $VIP netmask 255.255.255.255 up echo &quot;1&quot; &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo &quot;2&quot; &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;1&quot; &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo &quot;2&quot; &gt; /proc/sys/net/ipv4/conf/all/arp_announce ;; stop) echo &quot;lo:0 port closing&quot; ifconfig lo:0 down echo &quot;0&quot; &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo &quot;0&quot; &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo &quot;0&quot; &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo &quot;0&quot; &gt; /proc/sys/net/ipv4/conf/all/arp_announce ;; *) echo &quot;Usage: $0 &#123;start ¦ stop&#125;&quot; exit 1esacchmod u+x /etc/init.d/lvs_dr_rssystemctl enable lvs_dr_rssystemctl start lvs_dr_rs","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"lvs","slug":"lvs","permalink":"https://biglovewheat.gihub.io/tags/lvs/"},{"name":"keepalived","slug":"keepalived","permalink":"https://biglovewheat.gihub.io/tags/keepalived/"}]},{"title":"ssl证书类型和价格","slug":"ssl证书-类型和价格","date":"2022-08-29T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/30/ssl证书-类型和价格/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/30/ssl%E8%AF%81%E4%B9%A6-%E7%B1%BB%E5%9E%8B%E5%92%8C%E4%BB%B7%E6%A0%BC/","excerpt":"","text":"ssl证书类型和价格ssl证书简介 ssl证书类型 ssl证书价格 免费证书各大云的免费证书，一般是DigCert提供的单域名的证书 aws有泛域名的证书，需绑定aws服务（lb等）使用","categories":[{"name":"理论知识","slug":"理论知识","permalink":"https://biglovewheat.gihub.io/categories/%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"ssl","slug":"ssl","permalink":"https://biglovewheat.gihub.io/tags/ssl/"}]},{"title":"AWS-S3","slug":"aws-s3","date":"2022-08-28T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2022/08/29/aws-s3/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/29/aws-s3/","excerpt":"","text":"AWS-S3中国区价格https://www.amazonaws.cn/s3/pricing/ 存储类别 client安装配置1234567891011121314151617## 安装curl &quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot;unzip awscliv2.zip./aws/installvi /etc/profileexport PATH=$PATH:/usr/local/bin## 帮助/usr/local/bin/aws s3 cp help## 配置/usr/local/bin/aws configureAWS Access Key ID [None]: AKIAUPGCAPWX4FXXXXXXAWS Secret Access Key [None]: SsOupysZ4ZBptxGCxPm+aLWq+dTfShrgsdXXXXXXDefault region name [None]: cn-northwest-1Default output format [None]: 上传下载12345/usr/local/bin/aws s3 cp mysqlbackup_all_202109280515.tar.gz s3://aas3## 复制和排除文件夹/usr/local/bin/aws s3 cp miniodata s3://aas3/permanent_backup/minio_backup/ --exclude sensordata/* --exclude .minio.sys/* --recursive/usr/local/bin/aws s3 cp s3://aas3/AWSLogs/307497041326/vpcflowlogs/cn-northwest-1/2021/11/19/ . --recursive 挂载S3为文件系统12345678910111213141516171819202122232425## 1.参考文档## https://aws.amazon.com/cn/blogs/china/s3fs-amazon-ec2-linux/## 2.安装elepyum install -y epel-release## 3.安装s3fs-fuseyum install s3fs-fuse -y## 4.配置登录信息 echo AKIAUPGCAPWX6FD5N3CO:SsOupysZ4ZBptxGCxPm+aLWq+dTfShrgsdITVib4 &gt; /etc/passwd-s3fschmod 600 /etc/passwd-s3fs## 5.手工挂载mkdir -p /s3mnts3fs hxs3 /s3mnt -o passwd_file=/etc/passwd-s3fs -o url=http://s3.cn-northwest-1.amazonaws.com.cn -o endpoint=cn-northwest-1## 6.自动挂载vi /etc/fstabs3fs#hxs3 /s3mnt fuse allow_other,url=http://s3.cn-northwest-1.amazonaws.com.cn,endpoint=cn-northwest-1 0 0mount -a## 7.卸载umount /s3mntumount -l /s3mnt","categories":[{"name":"云原生","slug":"云原生","permalink":"https://biglovewheat.gihub.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"aws","slug":"aws","permalink":"https://biglovewheat.gihub.io/tags/aws/"},{"name":"s3","slug":"s3","permalink":"https://biglovewheat.gihub.io/tags/s3/"}]},{"title":"AWS-阿里云对比","slug":"aws-阿里云对比","date":"2022-08-28T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2022/08/29/aws-阿里云对比/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/29/aws-%E9%98%BF%E9%87%8C%E4%BA%91%E5%AF%B9%E6%AF%94/","excerpt":"","text":"AWS-阿里云对比AWS为中国区价格 云服务器 厂商 阿里云 阿里云 AWS AWS 型号 ecs.g7.xlarge ecs.r7.xlarge m5.xlarge r5.xlarge 类型 通用型 内存型 通用型 内存型 规格 4c16g 4c32g 4c16g 4c32g 小时价 1.0465 1.392442 2.026 2.437 小时-月 753.48 1002.55824 1458.72 1754.64 包月价 502.32 668.37 303.12 396 包年-月 426.97 568.12 282.96 369.36 块存储 厂商 阿里云 阿里云 AWS 型号 PL0 PL1 GP3 性能指标 10000IOPS&#x2F;180MB 50000IOPS&#x2F;350MB 3000IOPS&#x2F;125MB 计价方式 按量-小时&#x2F;GiB 按量-小时&#x2F;GiB 按量-小时&#x2F;GiB 单价 0.00105 0.0021 折算 0.756 1.512 0.5312 计价方式 包月-月&#x2F;GiB 包月-月&#x2F;GiB 单价 0.5 1 对象存储 厂商 阿里云 AWS 型号 oss标准型单价 S3标准存储 单价 0.12 0.1755 流量费用 0.25gb(闲时)&#x2F;0.5gb（忙时） 0.933&#x2F;gb 请求费用 PUT:0.01元&#x2F;万次 PUT:0.0405&#x2F;万次，GET:0.0135&#x2F;万次","categories":[{"name":"云原生","slug":"云原生","permalink":"https://biglovewheat.gihub.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"aws","slug":"aws","permalink":"https://biglovewheat.gihub.io/tags/aws/"},{"name":"阿里云","slug":"阿里云","permalink":"https://biglovewheat.gihub.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"}]},{"title":"Nexus减肥","slug":"nexus-减肥","date":"2022-08-28T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/29/nexus-减肥/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/29/nexus-%E5%87%8F%E8%82%A5/","excerpt":"","text":"Nexus减肥nexus默认安装时，没有开启清理的任务，时间一长，容易占用大量磁盘空间 清理maven-snapshot库system–task–create task–Maven - Delete SNAPSHOT Task 默认策略，只保留一个，多于1个且超过30天将删除 释放blob store空间清理完成后，不会马上释放空间，需要运行另外一个任务释放 system–task–create task–Create Admin - Compact blob store Task","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"nexus","slug":"nexus","permalink":"https://biglovewheat.gihub.io/tags/nexus/"}]},{"title":"正则表达式","slug":"正则表达式","date":"2022-08-23T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/24/正则表达式/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/24/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"正则表达式身份证校验1234567891011121314151617## 前六位，地区([1-6][1-9]|50)\\d&#123;4&#125;## 7-8位置，年份前两位，1800-2099(18|19|20)## 9-10位置，年份后两位\\d&#123;2&#125;## 11-12，月份((0[1-9])|10|11|12)## 13-14，日期(([0-2][1-9])|10|20|30|31) ## 15-17，顺序码\\d&#123;3&#125;## 校验码： [0-9Xx]## 校验18位的身份证^([1-6][1-9]|50)\\d&#123;4&#125;(18|19|20)\\d&#123;2&#125;((0[1-9])|10|11|12)(([0-2][1-9])|10|20|30|31)\\d&#123;3&#125;[0-9Xx]$ email校验1^[a-zA-Z0-9_-]+@[a-zA-Z0-9_-]+(\\.[a-zA-Z0-9_-]+)+$/; ip校验1(1-255).(0-255).(0-255).(0-255) python使用正则1234567891011import reidlist=[&#x27;440107199808180637&#x27;,&#x27;100107199808180637&#x27;]pat=r&#x27;^([1-6][1-9]|50)\\d&#123;4&#125;(18|19|20)\\d&#123;2&#125;((0[1-9])|10|11|12)(([0-2][1-9])|10|20|30|31)\\d&#123;3&#125;[0-9Xx]$&#x27;for id in idlist: if re.search(pat,id): print(&#x27;OK&#x27;) else: print(&#x27;NO&#x27;)","categories":[{"name":"all","slug":"all","permalink":"https://biglovewheat.gihub.io/categories/all/"}],"tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"https://biglovewheat.gihub.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"Redis-编译安装","slug":"redis-编译安装","date":"2022-08-22T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/23/redis-编译安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/23/redis-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","excerpt":"","text":"Redis-编译安装版本redis 6 升级gcc版本12345yum -y install centos-release-sclyum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutilsscl enable devtoolset-9 bashecho &quot;source /opt/rh/devtoolset-9/enable&quot; &gt;&gt; /etc/profilegcc -v 编译安装12make &amp;&amp; make PREFIX=/usr/local/redis installredis-cli --pass &#x27;123456&#x27; shutdown 系统配置1234567891011121314151617181920212223useradd -s /sbin/nologin redisecho 1024 &gt;/proc/sys/net/core/somaxconnsysctl vm.overcommit_memory=1echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledif test -f /sys/kernel/mm/transparent_hugepage/enabled; thenecho never &gt; /sys/kernel/mm/transparent_hugepage/enabledfiif test -f /sys/kernel/mm/transparent_hugepage/defrag; thenecho never &gt; /sys/kernel/mm/transparent_hugepage/defragfi## 修改--session生效ulimit -n 65535## 修改--重启永久生效vi /etc/security/limits.conf* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535 参数配置123456789101112131415## 放开其他服务器登录bind 0.0.0.0## 端口port 6379## 后台运行daemonize yes## 后台运行后pidfilepidfile /var/run/redis_6379.pid## 日志文件路径logfile &quot;/usr/local/redis/log/redis-6379.log&quot;## 数据文件路径dir /usr/local/redis/data-6379/## 复制相关replicaof 192.168.8.199 6379masterauth &#x27;123456&#x27; 复制相关12345## 查看复制info replication## slave 变 masterslaveof no one","categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/tags/middleware/"},{"name":"redis","slug":"redis","permalink":"https://biglovewheat.gihub.io/tags/redis/"}]},{"title":"K8s-helm-安装常用软件","slug":"k8s-helm-安装常用软件","date":"2022-08-17T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/18/k8s-helm-安装常用软件/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/18/k8s-helm-%E5%AE%89%E8%A3%85%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/","excerpt":"","text":"K8s-helm-安装常用软件helm安装1234wget https://get.helm.sh/helm-v3.9.3-linux-amd64.tar.gztar -xvf helm-v3.9.3-linux-amd64.tar.gzchmod u+x helmcp helm /usr/sbin 添加仓库123helm repo add bitnami https://charts.bitnami.com/bitnamihelm repo add c7n https://openchart.choerodon.com.cn/choerodon/c7nhelm repo add apphub https://apphub.aliyuncs.com/ helm-nfs-subdir-external-provisioner12345678910111213##https://github.com/kubernetes-sigs/nfs-subdir-external-provisionerhelm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/helm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\ --namespace=kube-system \\ --set image.repository=willdockerhub/nfs-subdir-external-provisioner \\ --set image.tag=v4.0.2 \\ --set replicaCount=2 \\ --set storageClass.name=sc-nfs \\ --set storageClass.defaultClass=true \\ --set nfs.server=192.168.8.201 \\ --set nfs.path=/nfsdata helm-jenkins123456helm repo add bitnami https://charts.bitnami.com/bitnamihelm upgrade --install jenkins bitnami/jenkins -n tools \\--set jenkinsUser=admin \\--set jenkinsPassword=&#x27;admin123&#x27; \\--set javaOpts=&#x27;-Duser.timezone=Asia/Shanghai&#x27; helm-mysql123456789101112### https://hub.kubeapps.com/charts/bitnami/mysqlhelm repo add bitnami https://charts.bitnami.com/bitnamihelm upgrade --install mysql bitnami/mysql -n tools \\--set global.storageClass=sc-nfs \\--set image.tag=8.0.23-debian-10-r84 \\--set auth.database=&quot;&quot; \\--set architecture=standalone \\--set auth.rootPassword=admin123 \\--set primary.service.type=NodePort \\--set primary.service.nodePort=30036 \\--set primary.persistence.size=100Gi helm-nexus12345678910111213141516171819202122232425262728293031helm upgrade --install sonatype-nexus apphub/sonatype-nexus -n middleware \\--set ingress.tls.enabled=false \\--set persistence.storageClass=sc-nfs \\--set nexusProxy.enabled=falsecat &lt;&lt; EOF &gt; svc-nexus.yamlapiVersion: v1kind: Servicemetadata: name: sonatype-nexus namespace: middleware labels: app: sonatype-nexusspec: type: NodePort ports: - port: 8081 name: http1 targetPort: 8081 nodePort: 31001 - port: 8082 name: http2 targetPort: 8082 nodePort: 31002 selector: app: sonatype-nexusEOFkubectl apply -f svc-nexus.yamlrm -f svc-nexus.yaml helm-gafana12345helm repo add bitnami https://charts.bitnami.com/bitnamihelm upgrade --install grafana bitnami/grafana -n tools \\--set global.storageClass=sc-nfs \\--set image.tag=8.1.2-debian-10-r6 \\--set admin.password=admin123 helm-nacos123456789101112131415161718#!/bin/bash## setp1. git clone https://github.com/nacos-group/nacos-k8s.git#### setp2. wget https://github.com/alibaba/nacos/blob/develop/distribution/conf/nacos-mysql.sql#### setp3. run sql in your mysql#### setp4. sed -i s/&#x27;mysql.port: &#123;&#123; .port | default 3306&#125;&#125;&#x27;/&#x27;mysql.port: &quot;&#123;&#123; .port | default 3306&#125;&#125;&quot;&#x27;/g ./nacos-k8s/helm/templates/configmap.yamlhelm upgrade --install nacos ./nacos-k8s/helm/ -n tools \\--set global.mode=standalone \\--set nacos.image.tag=1.4.2 \\--set nacos.storage.type=mysql \\--set nacos.storage.db.host=mysql \\--set nacos.storage.db.name=nacos_config \\--set nacos.storage.db.port=3306 \\--set nacos.storage.db.username=root \\--set nacos.storage.db.password=admin123 helm-redis12345678helm repo add bitnami https://charts.bitnami.com/bitnamihelm upgrade --install redis bitnami/redis -n tools \\--set global.storageClass=sc-nfs \\--set global.redis.password=admin123 \\--set image.tag=6.2.5-debian-10-r34 \\--set architecture=standalone \\--set master.service.type=NodePort \\--set master.service.nodePort=30379 helm-gitlab1234567891011helm upgrade --install gitlab c7n/gitlab-ha --version 0.2.4 -n tools \\--set expose.type=clusterIP \\--set persistence.enabled=true \\--set persistence.persistentVolumeClaim.core.storageClass=sc-nfs \\--set persistence.persistentVolumeClaim.core.size=10Gi \\--set persistence.persistentVolumeClaim.database.storageClass=sc-nfs \\--set persistence.persistentVolumeClaim.database.size=10Gi \\--set persistence.persistentVolumeClaim.redis.storageClass=sc-nfs \\--set persistence.persistentVolumeClaim.redis.size=5Gi \\--set core.replicas=1##--set core.image.tag=v12.3.5 \\","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"ELK-安装","slug":"elk-安装","date":"2022-08-16T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/17/elk-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/17/elk-%E5%AE%89%E8%A3%85/","excerpt":"","text":"ELK-安装ElasticSearch 安装配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849## 安装tar -xvf elasticsearch-7.13.1-linux-x86_64.tar.gzmv elasticsearch-7.13.1-linux-x86_64 /usr/local/elasticsearch## 创建用户useradd espasswd eschown -R es:es /usr/local/elasticsearch## linux参数设置vi /etc/sysctl.conffs.file-max=655360vm.max_map_count = 262144sysctl -pvi /etc/security/limits.conf* soft nproc 20480* hard nproc 20480* soft nofile 65536* hard nofile 65536* soft memlock unlimited* hard memlock unlimited## 重新登录生效，查看ulimit -arm -f /etc/security/limits.d/20-nproc.conf## 配置vi /usr/local/elasticsearch/config/elasticsearch.yml#cluster.name: elkbigdata#node.name: server1#node.master: true#node.data: truepath.data: /data/elasticsearch#path.logs: /usr/local/elasticsearch/logs#bootstrap.memory_lock: truenetwork.host: 192.168.8.221#http.port: 9200#discovery.zen.minimum_master_nodes: 1#discovery.seed_hosts: [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]#discovery.seed_providers: filecluster.initial_master_nodes: &quot;vm221&quot;##discovery.zen.ping.unicast.hosts: [&quot;172.16.213.37:9300&quot;,&quot;172.16.213.78:9300&quot;]## 启动脚本#!/bin/bashsu - es -c &quot;/usr/local/elasticsearch/bin/elasticsearch -d&quot; ES常用命令12#查看索引curl localhost:9200/_cat/indices?v zookepper 安装配置123456789101112131415161718192021## 安装tar -xvf tar -xvf apache-zookeeper-3.6.3-bin.tar.gzmv apache-zookeeper-3.6.3-bin /usr/local/zookeeper## 配置vi /usr/local/zookeeper/conf/zoo.cfgtickTime=2000initLimit=10syncLimit=5dataDir=/data/zookeeperclientPort=2181server.1=192.168.8.225:2888:3888server.2=192.168.8.226:2888:3888server.3=192.168.8.227:2888:3888set myid fileecho &quot;1&quot; &gt;/data/zookeeper/myid## 启动脚本#!/bin/bash/usr/local/zookeeper/bin/zkServer.sh start kafka 安装配置123456789101112131415161718192021222324252627282930313233343536373839## 安装tar -xvf kafka_2.11-2.2.2.tgzmv kafka_2.11-2.2.2 /usr/local/kafka## 配置文件vi /usr/local/kafka/config/server.propertiesbroker.id=0num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/usr/local/kafka/logsnum.partitions=3num.recovery.threads.per.data.dir=1offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1log.retention.hours=60log.segment.bytes=1073741824log.retention.check.interval.ms=300000zookeeper.connect=192.168.8.225:2181,192.168.8.226:2181,192.168.8.227:2181zookeeper.connection.timeout.ms=6000group.initial.rebalance.delay.ms=0## 启动脚本#!/bin/bashnohup /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties 1&gt;kafka.log 2&gt;&amp;1 &amp;tail -f kafka.log## 常用操作# 查看topicbin/kafka-topics.sh --zookeeper 192.168.8.225:2181,192.168.8.226:2181,192.168.8.227:2181 --list# 创建topicbin/kafka-topics.sh --zookeeper 192.168.8.225:2181,192.168.8.226:2181,192.168.8.227:2181 --create --topic elktopic \\&gt; --partitions 3 --replication-factor 1# 查看topic内容bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic elktopic --from-beginning filebeat 安装配置1234567891011121314151617181920212223242526272829## 安装tar -xvf filebeat-7.13.1-linux-x86_64.tar.gzmv filebeat-7.13.1-linux-x86_64 /usr/local/filebeat## 配置vi /usr/local/filebeat/filebeat.ymlfilebeat.inputs:- type: log enabled: true paths: - /var/log/secure fields: log_topic: topic1output.kafka: hosts: [&quot;192.168.8.225:9092&quot;, &quot;192.168.8.226:9092&quot;, &quot;192.168.8.227:9092&quot;] enabled: true topic: &#x27;%&#123;[fields.log_topic]&#125;&#x27; partition.round_robin: reachable_only: false required_acks: 1 compression: gzip max_message_bytes: 1000000## 启动脚本#!/bin/bash/usr/local/filebeat/filebeat -e -c /usr/local/filebeat/filebeat.yml &gt;filebeat.log 2&gt;&amp;1 &amp;tail -f filebeat.log logstash 安装配置12345678910111213141516171819202122## 安装tar -xvf logstash-7.13.1-linux-x86_64.tar.gzmv logstash-7.13.1-linux-x86_64 /usr/local/logstash## 配置cat /usr/local/logstash/config/logstash.confinput &#123; kafka &#123; bootstrap_servers =&gt; &quot;192.168.8.225:9092,192.168.8.226:9092,192.168.8.227:9092&quot; topics =&gt; [&quot;topic1&quot;] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;192.168.8.221:9200&quot; index =&gt; &quot;securelog-%&#123;+YYYY-MM-dd&#125;&quot; &#125;&#125;## 启动脚本#!/bin/bash/usr/local/logstash/bin/logstash -f /usr/local/logstash/config/logstash.conf &gt;logstash.log 2&gt;&amp;1 &amp; Kibana 安装配置12345678910111213141516## 安装tar -xvf logstash-7.13.1-linux-x86_64.tar.gzmv logstash-7.13.1-linux-x86_64 /usr/local/logstash## 配置vi /usr/local/kibana/config/kibana.ymlserver.port: 5601server.host: &quot;192.168.8.221&quot;elasticsearch.hosts: &quot;http://192.168.8.221:9200&quot;## 启动脚本#!/bin/bashnohup /usr/local/kibana/bin/kibana --allow-root &gt;kibana.log 2&gt;&amp;1 &amp;## 索引设置## Management--&gt;Stack Management--&gt;Kibana--&gt;Index Patterns","categories":[{"name":"日志","slug":"日志","permalink":"https://biglovewheat.gihub.io/categories/%E6%97%A5%E5%BF%97/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://biglovewheat.gihub.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"Linux-Vsftp-安装","slug":"linux-vsftp-安装","date":"2022-08-14T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/15/linux-vsftp-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/15/linux-vsftp-%E5%AE%89%E8%A3%85/","excerpt":"","text":"Linux-Vsftp-安装版本安装12345678910111213yum install -y vsftpd ftpuseradd vsftpecho vsftp@123\\! |passwd vsftp --stdinmkdir /ftpusermod vsftp -d /ftpchown vsftp:vsftp /ftpvi /etc/vsftpd/vsftpd.conf#anonymous_enable=YESsystemctl start vsftpdsystemctl enable vsftpd shell12345678910#!/bin/bashftp -n &lt;&lt;- EOFopen 192.168.1.1user vsftp vsftp@123!cd /ftpbinpromptmput *.logbyeEOF 配置123456789101112## 关闭匿名anonymous_enable=NO## 开放本地用户local_enable=YES## 需要开放其他用户编辑:#1 /etc/vsftpd/ftpusers --&gt;ftp黑名单,名单上的用户不能登录（与设置无关）#2 /etc/vsftpd/userlist --&gt;ftp黑名单,名单上的用户不能登录（userlist_enable=YES、userlist_deny=YES；都是默认）#/etc/vsftpd/vsftpd.conf #主配置文件 或 /etc/vsftpd.conf#/etc/vsftpd/ftpusers #不能访问FTP用户列表 或 /etc/ftpusers#/etc/vsftpd/user_list #不能访问FTP用户列表","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Mysql-主从复制配置","slug":"mysql-主从复制配置","date":"2022-08-10T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/11/mysql-主从复制配置/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/11/mysql-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Mysql-主从复制配置master开启binlog12345678vi /etc/my.cnflog-bin=mysql-binbinlog_format=mixedserver-id=1auto_increment_increment=2auto_increment_offset=1replicate-do-db=monitor master重启1systemctl restart mysqld master设置复制用户12345678910mysql&gt;GRANT REPLICATION SLAVE ON *.* TO &#x27;repuser&#x27;@&#x27;192.168.8.%&#x27; IDENTIFIED BY &#x27;2014Picc!!!&#x27;;mysql&gt;FLUSH PRIVILEGES;mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 1977 | | | |+------------------+----------+--------------+------------------+-------------------+--记录file和position slave设置参数123vi /etc/my.cnfserver-id=2 slave重启1systemctl restart mysqld slave开启复制1mysql&gt;change master to master_host=&#x27;192.168.8.201&#x27;, master_user=&#x27;repuser&#x27;, master_password=&#x27;2014Picc!!!&#x27;, master_log_file=&#x27;mysql-bin.000001&#x27;, master_log_pos=612; slave查看状态1mysql&gt;show slave status\\G","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Mysql-慢日志处理","slug":"mysql-慢日志处理","date":"2022-08-10T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/11/mysql-慢日志处理/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/11/mysql-%E6%85%A2%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86/","excerpt":"","text":"Mysql-慢日志处理查看参数12345678mysql&gt; show variables like &#x27;slow_query%&#x27;;+---------------------+-------------------------------+| Variable_name | Value |+---------------------+-------------------------------+| slow_query_log | OFF || slow_query_log_file | /var/lib/mysql/vm201-slow.log |+---------------------+-------------------------------+3 rows in set (0.00 sec) 开启慢日志123456vi /etc/my.cnfslow_query_log=1slow_query_log_file=/var/lib/mysql/vm201-slow.log#default 10log_query_time=10 分析工具1234mysqldumpslow -s at -t 20 /var/lib/mysql/vm201-slow.log-s at sort by query time-t 20 top 20","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"AWS-Linux-Chrony-时间同步","slug":"aws-linux-chrony-时间同步","date":"2022-08-09T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2022/08/10/aws-linux-chrony-时间同步/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/10/aws-linux-chrony-%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/","excerpt":"","text":"AWS-Linux-Chrony-时间同步配置chrony同步12345678910111213141516171819202122232425262728293031323334353637383940## 配置aws时间服务器vi /etc/chrony.conf server 169.254.169.123 prefer iburst minpoll 4 maxpoll 4## 重启chronysystemctl restart chronyd## 查看同步情况chronyc sources -v210 Number of sources = 1 .-- Source mode &#x27;^&#x27; = server, &#x27;=&#x27; = peer, &#x27;#&#x27; = local clock. / .- Source state &#x27;*&#x27; = current synced, &#x27;+&#x27; = combined , &#x27;-&#x27; = not combined,| / &#x27;?&#x27; = unreachable, &#x27;x&#x27; = time may be in error, &#x27;~&#x27; = time too variable.|| .- xxxx [ yyyy ] +/- zzzz|| Reachability register (octal) -. | xxxx = adjusted offset,|| Log2(Polling interval) --. | | yyyy = measured offset,|| \\ | | zzzz = estimated error.|| | | \\MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* 169.254.169.123 3 4 377 11 -5483ns[ -10us] +/- 410us## 验证 chronyc trackingReference ID : A9FEA97B (169.254.169.123)Stratum : 4Ref time (UTC) : Wed Aug 10 03:04:51 2022System time : 0.000002134 seconds fast of NTP timeLast offset : +0.000002142 secondsRMS offset : 0.000007061 secondsFrequency : 2.554 ppm slowResidual freq : +0.003 ppmSkew : 0.200 ppmRoot delay : 0.000296080 secondsRoot dispersion : 0.000277362 secondsUpdate interval : 16.3 secondsLeap status : Normal","categories":[{"name":"云原生","slug":"云原生","permalink":"https://biglovewheat.gihub.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"aws","slug":"aws","permalink":"https://biglovewheat.gihub.io/tags/aws/"},{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Jenkins-Gitlab-webhook配置","slug":"jenkins-gitlab-webhook配置","date":"2022-08-08T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/09/jenkins-gitlab-webhook配置/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/09/jenkins-gitlab-webhook%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Jenkins-Gitlab-webhook配置Gitlab设置access token用户头像–Preferences–访问令牌 把key复制下来 Gitlab项目配置webhook项目–设置–webhook 分别填入： 网址：jenkins网址+generic-webhook-trigger&#x2F;invoke?token&#x3D;yourtoken 推送事件：可以指定分支或tag 去掉启用ssl验证 jenkins安装Generic Webhook Trigger插件jenkins项目配置webhook 配置完成后，只要分支有推送事件，会触发jenkins构建","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"git","slug":"git","permalink":"https://biglovewheat.gihub.io/tags/git/"},{"name":"jenkins","slug":"jenkins","permalink":"https://biglovewheat.gihub.io/tags/jenkins/"}]},{"title":"K8s-Evicted-Pod处理","slug":"k8s-evicted-pod处理","date":"2022-08-08T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/09/k8s-evicted-pod处理/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/09/k8s-evicted-pod%E5%A4%84%E7%90%86/","excerpt":"","text":"K8s-Evicted-Pod处理现象k8s出现很多Evicted Pod 排查12kubectl describe pods farm-server-789ddb7b4c-5jltb -n dev-3 |grep -i messageMessage: Pod The node had condition: [DiskPressure]. 原因k8s节点磁盘达到85%触发node驱逐pod 解决12345678910## 1.降低磁盘使用率## 2.修改kubelet启动参数vi /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.confEnvironment=&quot;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --eviction-hard=nodefs.available&lt;5%&quot;systemctl daemon-reloadsystemctl restart kubelet## 删除evicted的podkubectl -n base get pods |grep Evicted |awk &#x27;&#123;print $1&#125;&#x27; |xargs kubectl -n base delete pods","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"K8s-ingress-安装","slug":"k8s-ingress-安装","date":"2022-08-08T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/09/k8s-ingress-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/09/k8s-ingress-%E5%AE%89%E8%A3%85/","excerpt":"","text":"K8s-ingress-安装安装1234567891011helm repo add nginx-stable https://helm.nginx.com/stablehelm upgrade --install nginx-ingress nginx-stable/nginx-ingress -n kube-system \\--set controller.kind=daemonset \\--set ingressClass=nginx \\--set setAsDefaultIngress=truekubectl patch daemonset nginx-ingress-nginx-ingress -n kube-system -p=&#x27;&#123;&quot;spec&quot;:&#123;&quot;template&quot;: &#123;&quot;spec&quot;: &#123;&quot;tolerations&quot;: [&#123;&quot;key&quot;: &quot;node-role.kubernetes.io/master&quot;, &quot;effect&quot;: &quot;NoSchedule&quot;&#125;]&#125;&#125;&#125;&#125;&#x27;## for k8s 1.18--version 0.10.4 例子1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: ing-nginx namespace: app annotations: kubernetes.io/ingress.class: nginxspec: rules: - host: ng.biglovewheat1.com http: paths: - pathType: Prefix path: &quot;/&quot; backend: service: name: nginx port: number: 80---apiVersion: networking.k8s.io/v1beta1kind: Ingressmetadata: name: saas-operation namespace: dev-3 annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/cors-allow-credentials: &quot;true&quot; nginx.ingress.kubernetes.io/cors-allow-headers: &#x27;*&#x27; nginx.ingress.kubernetes.io/cors-allow-methods: PUT, GET, POST, OPTIONS, DELETE nginx.ingress.kubernetes.io/cors-allow-origin: http://saas-operation.abc.com nginx.ingress.kubernetes.io/enable-cors: &quot;true&quot;spec: rules: - host: saas-operation.abc.com http: paths: - path: / backend: serviceName: saas-operation servicePort: 80 ingress-413-错误1234567## ingress error## 413 Request Entity Too Largemetadata: annotations: nginx.ingress.kubernetes.io/proxy-body-size: &quot;0&quot; nginx.ingress.kubernetes.io/proxy-read-timeout: &quot;600&quot; nginx.ingress.kubernetes.io/proxy-send-timeout: &quot;600&quot;","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"Linux-iftop-流量监控","slug":"linux-iftop-流量监控","date":"2022-08-08T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/09/linux-iftop-流量监控/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/09/linux-iftop-%E6%B5%81%E9%87%8F%E7%9B%91%E6%8E%A7/","excerpt":"","text":"Linux-iftop-流量监控1234567891011## 安装yum install -y epel-releaseyum install -y iftop## 参数-i 指定网卡-n 直接显示IP-N 直接显示端口号-P 同时显示IP和端口号iftop -i eth0 -PNn","categories":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Chattr-Crontab加锁","slug":"chattr-crontab加锁","date":"2022-08-07T16:00:00.000Z","updated":"2023-08-24T12:15:39.768Z","comments":true,"path":"2022/08/08/chattr-crontab加锁/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/08/chattr-crontab%E5%8A%A0%E9%94%81/","excerpt":"","text":"Chattr-Crontab加锁linux安全加固，利用chattr命令对文件加锁，防止非法修改crontab 12345678## crontab加锁for a in `ls /var/spool/cron/`; do chattr +i /var/spool/cron/$a; done## 查看锁lsattr /var/spool/cron/*## 解锁for a in `ls /var/spool/cron/`; do chattr -i /var/spool/cron/$a; done","categories":[{"name":"安全","slug":"安全","permalink":"https://biglovewheat.gihub.io/categories/%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"},{"name":"安全","slug":"安全","permalink":"https://biglovewheat.gihub.io/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"Nmon-监控脚本","slug":"nmon-监控脚本","date":"2022-08-07T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/08/nmon-监控脚本/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/08/nmon-%E7%9B%91%E6%8E%A7%E8%84%9A%E6%9C%AC/","excerpt":"","text":"Nmon-监控脚本监控脚本1234567891011121314##保留一周cat /data/nmon/moni.sha=`hostname`b=`date |awk &#x27;&#123;print substr($3,1,2)&#125;&#x27;`/usr/bin/nmon -f -s 300 -c 288 -t -F /tmp/nmondata/$a&quot;_&quot;$b.nmon##保留一月a=`hostname`b=`date | awk &#x27;&#123;print substr($0,1,3)&#125;&#x27;`if [ -f /tmp/nmondata/$a&quot;_&quot;$b.nmon ];thenrm /tmp/nmondata/$a&quot;_&quot;$b.nmonfi/usr/bin/nmon -f -s 300 -c 288 -t -F /tmp/nmondata/$a&quot;_&quot;$b.nmon crontab10 0 * * * /data/nmon/moni.sh","categories":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"Shell-if判断","slug":"shell-if判断","date":"2022-08-07T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/08/shell-if判断/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/08/shell-if%E5%88%A4%E6%96%AD/","excerpt":"","text":"Shell-if判断12345if [[ &quot;v$&#123;MODE&#125;&quot; == &quot;vstandalone&quot; ]]thenecho 111echo 222fi","categories":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"}]},{"title":"Shell-清理脚本","slug":"shell-清理脚本","date":"2022-08-07T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/08/shell-清理脚本/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/08/shell-%E6%B8%85%E7%90%86%E8%84%9A%E6%9C%AC/","excerpt":"","text":"Shell清理脚本清理脚本12345678910111213141516171819#!/bin/bashdate## cleanup /data/webapp/*/bak/*.tar.gz; leave last 10 file##find /data/webapp/*/bak -type d |while read rowdocd $rowls -t *.tar.gz |sed -n &#x27;11,$p&#x27; | xargs rm -vfdone## cleanup /data/*/logs/*.log## 找到并清空文件find /data/*/logs/ -name &quot;*.log&quot; |awk &#x27;&#123;print &quot;echo 11 &gt;&quot;$0&#125;&#x27; |sh## cleanup /data/*/app/*.jar; leave last 10 file##find /data/*/app -type d |while read rowdocd $rowls -t *.jar |sed -n &#x27;11,$p&#x27; | xargs rm -vfdone crontab133 5 * * * /data/cleanup.sh &gt;&gt; /data/cleanup.log 2&gt;&amp;1","categories":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"}]},{"title":"Https-握手流程","slug":"https-握手流程","date":"2022-08-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/05/https-握手流程/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/05/https-%E6%8F%A1%E6%89%8B%E6%B5%81%E7%A8%8B/","excerpt":"","text":"Https-握手流程1）客户端向服务器端发起https通信请求 2 服务器端响应并发送公钥 3、客户端验证公钥 4、客户端生成通信秘钥（随机数） 5、客户端用公钥加密通信秘钥并发送到服务器端 6、服务器端用私钥解密获取通信秘钥 7、服务器端和客户端利用通信秘钥对数据进行加密通讯","categories":[{"name":"基础概念","slug":"基础概念","permalink":"https://biglovewheat.gihub.io/categories/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"}],"tags":[{"name":"http","slug":"http","permalink":"https://biglovewheat.gihub.io/tags/http/"},{"name":"基础概念","slug":"基础概念","permalink":"https://biglovewheat.gihub.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"}]},{"title":"Nginx-too-many-open-files","slug":"nginx-too-many-open-files","date":"2022-08-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/05/nginx-too-many-open-files/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/05/nginx-too-many-open-files/","excerpt":"","text":"Nginx-too-many-open-files现象Too many open files 处理12345678910111213141516171819202122232425262728293031323334353637## 查看ulimit -aulimit -n## 修改-session生效ulimit -n 65535## 修改-永久生效-需重启vi /etc/security/limits.conf* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535reboot## 修改配置文件events &#123;worker_connections 4096;use epoll;multi_accept on;&#125;## 修改service参数systemctl status nginxvi /usr/lib/systemd/system/nginx.service[Service]增加LimitNOFILE=65535## 重启nginxsystemctl daemon-reloadsystemctl restart nginx## 检查ps -ef |grep nginxcat /proc/31668/limitsMax open files 65535 65535 files","categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"},{"name":"nginx","slug":"nginx","permalink":"https://biglovewheat.gihub.io/tags/nginx/"}]},{"title":"Nginx-安装配置","slug":"nginx-编译安装","date":"2022-08-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/05/nginx-编译安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/05/nginx-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","excerpt":"","text":"Nginx-安装配置版本centos 7 nginx 1.2x 安装12345678910yum -y install gcc gcc-c++ make automake autoconf pcre \\pcre-devel zlib zlib-devel openssl openssl-devel libtool./configure --prefix=/usr/local/nginx \\--with-http_ssl_module \\--with-http_stub_status_module \\--with-http_gzip_static_module \\--with-pcre --with-streammake &amp;&amp; make install 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061user root;worker_processes auto;# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.include /usr/share/nginx/modules/*.conf;events &#123;use epoll;worker_connections 65535;#worker工作方式：串行multi_accept on;&#125;#stream &#123;# log_format proxy &#x27;$remote_addr [$time_local] &#x27;# &#x27;$protocol $status $bytes_sent $bytes_received &#x27;# &#x27;$session_time &quot;$upstream_addr&quot; &#x27;# &#x27;&quot;$upstream_bytes_sent&quot; &quot;$upstream_bytes_received&quot; &quot;$upstream_connect_time&quot;&#x27;;# access_log /var/log/nginx/tcp-access.log proxy ;# open_log_file_cache off;# include /etc/nginx/conf.d/*.stream;#&#125;http &#123;include mime.types;default_type application/octet-stream;sendfile on;tcp_nopush on;## uploadclient_max_body_size 2g;#keepalive_timeout 0;keepalive_timeout 65;#### gzip module begin ####gzip on;#gzip_comp_level 4;#gzip_buffers 4 16k;#gzip_types text/plain application/javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;#gzip_min_length 5k;#gzip_vary on;#gzip_proxied any#### gzip module end ###include /usr/local/nginx/conf/conf.d/*.conf;server &#123;listen 80;server_name localhost;location / &#123;root html;index index.html index.htm;&#125;location = /50x.html &#123;root html;&#125;&#125; stream模块1234567891011121314151617181920## nginx从1.9.0开始，新增加了一个stream模块，用来实现四层协议的转发、代理或者负载均衡等## stream模块的用法和http模块差不多，语法基本一致，支持server，hash， listen， proxy_pass等指令stream &#123; upstream cloudsocket &#123; hash $remote_addr consistent; # $binary_remote_addr; server 172.19.20.7:3306 weight=5 max_fails=3 fail_timeout=300s; &#125; server &#123; listen 3306;#数据库服务器监听端口 server_name mysql1.tools.hrtop.net; proxy_connect_timeout 120s; proxy_send_timeout 120; proxy_read_timeout 120; proxy_buffer_size 256k; proxy_buffers 8 128k; proxy_pass cloudsocket;&#125; ssl配置123456789101112131415161718server &#123; listen 443 ssl; server_name sit.biglovewheat.com; ssl_certificate certs/ssl.crt; ssl_certificate_key certs/ssl.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / &#123; root /nfsdata/dist; index index.html index.htm; &#125;&#125; websocket123456789101112131415161718upstream websocket&#123;server hx-app-01:8100 weight=1;&#125;server &#123;listen 8100;location / &#123;client_max_body_size 100M;proxy_set_header Host $host;proxy_set_header Upgrade $http_upgrade; #支持wssproxy_set_header Connection &quot;upgrade&quot;; #支持wssproxy_pass http://websocket;&#125;location = /50x.html &#123;root /usr/share/nginx/html;&#125;&#125; 重定向问题1234## https://blog.csdn.net/weixin_34186128/article/details/91742483if (-d $request_filename)&#123;rewrite [^/]$ $scheme://$http_host$uri/ permanent;&#125; retry123456location / &#123; add_header &#x27;Access-Control-Allow-Origin&#x27; &#x27;*&#x27; always; root /opt/nginx/dist-saas-operation-new; try_files $uri $uri/ /index.html; index index.html index.htm;&#125; 自动目录123456 location / &#123; autoindex on; #是否打开配置自动列目录 autoindex_exact_size on; #是否打开文件大小展示 autoindex_localtime on; #是否打开显示文件的时间 root /filepath/&#125; 允许参数带有下划线12## http模块增加underscores_in_headers on","categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://biglovewheat.gihub.io/tags/nginx/"}]},{"title":"Postgresql-数据库导入导出","slug":"postgresql-数据库导入导出","date":"2022-08-04T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/05/postgresql-数据库导入导出/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/05/postgresql-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/","excerpt":"","text":"Postgresql-导入导出版本postgresql 13 备份脚本1234567891011121314#!/bin/shDATETIME=$(date +&quot;%Y%m%d%H%M&quot;)cd /pgdata_backup#pg_dumpall -p 5083 &gt; all.sqlpg_dumpall --exclude-database=common -p 5083 -c --if-exists |gzip &gt; part1-all-exclude-common.sql.gzpg_dump --dbname=common --exclude-schema=offline_map -p 5083 -c --if-exists|gzip &gt; part2-common-excluede-offline_map.sql.gztar -cvf pgbackup_all_$&#123;DATETIME&#125;.tar part*.sql.gz --remove-files/usr/local/bin/aws s3 cp pgbackup_all_$&#123;DATETIME&#125;.gz s3://aaa/backup/find /pgdata_backup -mtime +30 -type f -name &quot;*.gz&quot; | xargs rm -f 数据库导出123456pg_dumpall -p 5083 -c --if-exists |gzip &gt; all.sql.gzpg_dump --dbname=testdb -p 5083 -c --if-exists|gzip &gt; testdb.sql.gz## 只导结构pg_dump --dbname=testdb -p 5083 -c --if-exists -s | &gt; testdb.sql.gz 数据库导入1234567## 整库psql -f alldb.sql## 单个数据库create database testdb;psql -f testdb.sql -d testdb 导出到文本123456789101112131415PG_HOST=`grep PG_HOST= ./cfg/system.cfg |awk -F\\= &#x27;&#123;print $2&#125;&#x27;`PG_PATH=`grep PG_PATH= ./cfg/system.cfg |awk -F\\= &#x27;&#123;print $2&#125;&#x27;`PG_LD_LIBRARY_PATH=`grep PG_LD_LIBRARY_PATH= ./cfg/system.cfg |awk -F\\= &#x27;&#123;print $2&#125;&#x27;`export PATH=$PATH:$PG_PATHexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$PG_LD_LIBRARY_PATHexport PGPASSWORD=$PASSWORDpsql -h $PG_HOST -U $USERNAME -d $DBNAME &lt;&lt;! 2&gt;&gt; $LOG 1&gt;&amp;2create temp table tmp_101 (pkeyvalue varchar(200));insert into tmp_101select policyno from prpcmainwhere startdate&gt;=&#x27;$BDATE&#x27; and startdate&lt;=&#x27;$EDATE&#x27;and policyno is not null and policyno&lt;&gt;&#x27;&#x27; and policyno&lt;&gt;&#x27; &#x27;;\\copy tmp_101 to &#x27;$OUT&#x27;;! 文本导入12345678910PG_HOST=`grep PG_HOST= ./cfg/system.cfg |awk -F\\= &#x27;&#123;print $2&#125;&#x27;`PG_PATH=`grep PG_PATH= ./cfg/system.cfg |awk -F\\= &#x27;&#123;print $2&#125;&#x27;`PG_LD_LIBRARY_PATH=`grep PG_LD_LIBRARY_PATH= ./cfg/system.cfg |awk -F\\= &#x27;&#123;print $2&#125;&#x27;`export PATH=$PATH:$PG_PATHexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$PG_LD_LIBRARY_PATHexport export PGPASSWORD=$PASSWORDpsql -h $PG_HOST -U $USERNAME -d $DBNAME &lt;&lt;! 2&gt;&gt; $LOG 1&gt;&amp;2\\copy tmp_pkey from &#x27;$TMP_OUT1&#x27;;!","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"postgresql","slug":"postgresql","permalink":"https://biglovewheat.gihub.io/tags/postgresql/"}]},{"title":"Gitlab-异库同步","slug":"gitlab-异库同步","date":"2022-08-03T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/04/gitlab-异库同步/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/04/gitlab-%E5%BC%82%E5%BA%93%E5%90%8C%E6%AD%A5/","excerpt":"","text":"Gitlab-异库同步结构123456├── gitlab_sync_ignore.lst # 不同步的库├── gitlab_sync_lib.py # 计算本次需同步的库，分全量和增量├── gitlab_sync.sh # 同步脚本├── gitlab_sync_old.lst├── gitlab_sync_to_full.lst # 全同步列表，脚本生成├── gitlab_sync_to_inc.lst # 增量同步列表，脚本生成 gitlab_sync.sh12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#!/bin/bashROOT_PATH=/home/gitlab_synccd $ROOT_PATHgit_url1=&quot;192.168.8.1:8090&quot;git_user1=jenkinsgit_key1=xxxxxxxxxxxgit_url2=&quot;10.249.2.40:8690&quot;git_user2=abcgit_key2=xxxxxxxxxxxxgit_group2=&#x27;aa/bb/10/operations&#x27;mkdir -p $ROOT_PATH/repo_fullmkdir -p $ROOT_PATH/repo_incrm -f $ROOT_PATH/gitlab_sync_to_full.lstrm -f $ROOT_PATH/gitlab_sync_to_inc.lst$ROOT_PATH/gitlab_sync_lib.py $git_url1 $git_key1if [ -f &quot;$ROOT_PATH/gitlab_sync_to_full.lst&quot; ]; thencat $ROOT_PATH/gitlab_sync_to_full.lst | while read row;do gitname1=$(echo $row |awk -F &quot;:8090/&quot; &#x27;&#123;print $2&#125;&#x27;) gitname2=$(echo $gitname1| sed &#x27;s/\\//-/g&#x27;) echo &quot;***start full sync ... $row&quot; rm -rf $ROOT_PATH/repo_full/$gitname2 git clone --bare http://$&#123;git_user1&#125;:$&#123;git_key1&#125;@$&#123;git_url1&#125;/$gitname1 $ROOT_PATH/repo_full/$gitname2 cd $ROOT_PATH/repo_full/$gitname2 git push --mirror http://$&#123;git_user2&#125;:$&#123;git_key2&#125;@$&#123;git_url2&#125;/$&#123;git_group2&#125;/$gitname2 cd $ROOT_PATH rm -rf $ROOT_PATH/repo_inc/$gitname2 git clone http://$&#123;git_user1&#125;:$&#123;git_key1&#125;@$&#123;git_url1&#125;/$gitname1 $ROOT_PATH/repo_inc/$gitname2 echo $row &gt;&gt; $ROOT_PATH/gitlab_sync_old.lstcd $ROOT_PATHdonefiif [ -f &quot;$ROOT_PATH/gitlab_sync_to_inc.lst&quot; ]; thencat $ROOT_PATH/gitlab_sync_to_inc.lst | while read row;do gitname1=$(echo $row |awk -F &quot;:8090/&quot; &#x27;&#123;print $2&#125;&#x27;) gitname2=$(echo $gitname1| sed &#x27;s/\\//-/g&#x27;) echo &quot;***start inc sync ... $row&quot; cd $ROOT_PATH/repo_inc/$gitname2 git branch -r | grep -v &#x27;\\-&gt;&#x27; | while read remote; do git branch --track &quot;$&#123;remote#origin/&#125;&quot; &quot;$remote&quot;; done git fetch --all git branch -r |grep -v HEAD |awk -F&quot;origin/&quot; &#x27;&#123;print $2&#125;&#x27; | while read repo; do git checkout $repo;git pull --rebase; done git pull --all --rebase git push --all http://$&#123;git_user2&#125;:$&#123;git_key2&#125;@$&#123;git_url2&#125;/$&#123;git_group2&#125;/$gitname2cd $ROOT_PATHdonefi gitlab_sync_lib.py123456789101112131415161718192021222324252627282930313233343536#!/usr/bin/python3import gitlabimport timeimport osimport sysimport pandas as pdrepo_url = &quot;http://&quot; + sys.argv[1]token = sys.argv[2]df1 = pd.DataFrame(columns=[&#x27;url&#x27;])g1 = gitlab.Gitlab(repo_url, private_token=token)projects = g1.projects.list(all=True)for project in projects: df1 = df1.append(&#123;&#x27;url&#x27;:project.http_url_to_repo&#125;, ignore_index=True)if os.path.isfile(&quot;gitlab_sync_ignore.lst&quot;): df2 = pd.read_csv(&quot;gitlab_sync_ignore.lst&quot;,sep=&#x27; &#x27;,header=None) df2.rename(columns=&#123;df2.columns[0]:&quot;url&quot;&#125;, inplace=True) ##df1-df2 df3 = pd.concat([df1, df2, df2]).drop_duplicates(keep=False)else: df3 = df1if os.path.isfile(&quot;gitlab_sync_old.lst&quot;): df4 = pd.read_csv(&quot;gitlab_sync_old.lst&quot;,sep=&#x27; &#x27;,header=None) df4.rename(columns=&#123;df4.columns[0]:&quot;url&quot;&#125;, inplace=True) ##df5=df3-df4,df4=df3-df5 df5 = pd.concat([df3, df4, df4]).drop_duplicates(keep=False) df4 = pd.concat([df3, df5, df5]).drop_duplicates(keep=False) df4.to_csv(&quot;gitlab_sync_to_inc.lst&quot;,index=0,header=0) df5.to_csv(&quot;gitlab_sync_to_full.lst&quot;,index=0,header=0)else: df5 = df3 df5.to_csv(&quot;gitlab_sync_to_full.lst&quot;,index=0,header=0)","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"},{"name":"gitlab","slug":"gitlab","permalink":"https://biglovewheat.gihub.io/tags/gitlab/"},{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"}]},{"title":"K8s-Centos7-安装","slug":"k8s-centos7-安装","date":"2022-08-03T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/04/k8s-centos7-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/04/k8s-centos7-%E5%AE%89%E8%A3%85/","excerpt":"","text":"Kubernetes-Centos7-安装关闭swap&#x2F;selinux&#x2F;firewalld12345678910111213## 关闭swapswapoff -avi /etc/fstab注释掉swap的一行## 关闭selinuxsetenforce 0sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config## 关闭防火墙systemctl disable firewalldsystemctl stop firewalldsystemctl status firewalld 安装docker123456yum install -y yum-utilsyum install -y bash-completionyum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum clean allyum install -y docker-ce-20.10.8sudo systemctl enable docker 配置阿里云镜像加速12345678mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;https://nn5bgten.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 修改docker cgroup驱动为systemd12345sed -i &quot;s|ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock|ExecStart=/usr/bin/dockerd --exec-opt native.cgroupdriver=systemd|g&quot; /usr/lib/systemd/system/docker.servicesystemctl daemon-reloadsystemctl restart dockerdocker info | grep -i cgroup 添加k8s仓库1234567cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=0EOF 安装kubeadm12345yum list kubeadm --showduplicatesyum install -y kubeadm-1.20.9 kubectl-1.20.9 kubelet-1.20.9systemctl enable kubelet.servicesystemctl restart kubelet 修改网络参数（centos7）123modprobe br_netfilterecho 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptablesecho 1 &gt; /proc/sys/net/ipv4/ip_forward kubeadm初始化12345kubeadm init --apiserver-advertise-address=0.0.0.0 --apiserver-cert-extra-sans=127.0.0.1 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.20.9 --pod-network-cidr=10.133.0.0/16 \\--image-repository=registry.aliyuncs.com/google_containers## kubeadm 初始化清理（如果失败，可以reset进行清理）kubeadm reset 配置文件123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config 安装calico（指定版本）1kubectl apply -f https://docs.projectcalico.org/v3.19/manifests/calico.yaml 节点加入123456789101112131415161718## 节点执行到安装完kubeadmkubeadm join 192.168.8.112:6443 --token 74kuf2.6f1pv9lbrkxw5n0k \\ --discovery-token-ca-cert-hash sha256:7566c21fdbc491dac295412629680d3778ba04de933902a842a028e5accbeb47## master节点加入### 主节点运行获取证书kubeadm init phase upload-certs --upload-certs### 新节点加入kubeadm join 192.168.8.112:6443 --token lb45cr.d5s17hnbgsj6sf5b \\ --discovery-token-ca-cert-hash sha256:7566c21fdbc491dac295412629680d3778ba04de933902a842a028e5accbeb47 \\--control-plane --certificate-key f3657ba47289c8994771aaf2ebd2a90ee335f0fff41b9c1470ad15d21e185094# 错误：# unable to add a new control plane instance a cluster that doesn&#x27;t have a stable controlPlaneEndpoint address# 解决办法：加上controlPlaneEndpointkubectl edit configmap -n kube-system kubeadm-config clusterName: kubernetes controlPlaneEndpoint: 192.168.8.112:6443 kubectl自动补全1echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; /etc/profile; source /etc/profile kubeadm安装后scheduler状态为unhealthy12345678kubectl get cs## 备份修改两个文件vi /etc/kubernetes/manifests/kube-controller-manager.yamlvi /etc/kubernetes/manifests/kube-scheduler.yaml## 去掉 --port=0## 重启kubeletsystemctl restart kubelet","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"K8s-Ubuntu-安装","slug":"k8s-ubuntu-安装","date":"2022-08-03T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/04/k8s-ubuntu-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/04/k8s-ubuntu-%E5%AE%89%E8%A3%85/","excerpt":"","text":"Kubernetes-Ubuntu-安装1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192## 关闭sudo密码vi /etc/sudoers%sudo ALL=(ALL:ALL) NOPASSWD:ALL## 设置光盘源sudo -imkdir cdrommount /dev/sr0 /cdromapt-cdrom -m -d=/cdrom addapt update## 设置静态IPsudo -iapt install network-manager -yvi /etc/netplan/01-network-all.yamlnetwork: version: 2 ethernets: ens33: dhcp4: no addresses: [192.168.8.201/24] gateway4: 192.168.8.2 nameservers: addresses: [8.8.8.8]netplan applyip a## 安装基本工具apt install curl net-tools apt-transport-https ca-certificates software-properties-common -y## 关闭swapsudo -ivi /etc/fstab注销掉swapreboot## 关闭防火墙sudo -isystemctl stop ufwsystemctl disable ufw## 修改内核参数## 安装dockercurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;apt-get -y updateapt-cache madison docker-ceapt install docker-cesystemctl enable docker## 复制主机+修改主机名+IPsudo -ihostnamectl set-hostname k8s-node1vi /etc/netplan/01-network-all.yamlreboot## SSH免密配置ssh-keygen -t rsassh-copy-id k8s-node1ssh-copy-id k8s-node2## 安装K8Scurl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -sudo apt-add-repository &quot;deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main&quot;apt-cache madison kubeadmapt install kubeadm=1.20.1-00 kubelet=1.20.1-00 kubectl=1.20.1-00 -ysystemctl enable kubelet## 初始化--mastersudo -ikubeadm init --apiserver-advertise-address 192.168.8.201 --pod-network-cidr=10.244.0.0/16# 国内镜像kubeadm init --apiserver-advertise-address 192.168.8.231 --pod-network-cidr=10.244.0.0/16 \\--image-repository=registry.aliyuncs.com/google_containers## 拷贝配置文件mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configscp -r .kube k8s-node1:/home/user1scp -r .kube k8s-node2:/home/user1## 安装flannelkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml## 初始化--nodesudo -isudo kubeadm join 192.168.8.201:6443 --token m7eb1a.napsviab32zfjo7c --discovery-token-ca-cert-hash sha256:8c8a0a5c87b1a14ee2f2d363a826a800a6f7b7bd8bcaeb2928f26459e149e421","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"}]},{"title":"Linux-swap扩容","slug":"linux-swap扩容","date":"2022-08-03T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/04/linux-swap扩容/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/04/linux-swap%E6%89%A9%E5%AE%B9/","excerpt":"","text":"Linux-swap扩容12345678910111213141516## 4Gdd if=/dev/zero of=/swapfile01 bs=1024 count=4096000## 8Gdd if=/dev/zero of=/swapfile01 bs=1024 count=8192000## 指定分区类型为swap/sbin/mkswap /swapfile01chmod 0600 /swapfile01## 激活swap分区/sbin/swapon /swapfile01## 设置自动挂载vi /etc/fstab/swapfile01 swap swap defaults 0 0mount -a","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Geoserver-安装","slug":"geoserver-安装","date":"2022-08-02T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/03/geoserver-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/03/geoserver-%E5%AE%89%E8%A3%85/","excerpt":"","text":"Geoserver-安装版本1234567centos7/8jdk-1.8geoserver-2.14tomcat-9postgresql-13.2postgis-3.1.1pgrouting-3.3.0 安装postgresql12345678910111213141516171819202122232425## 安装仓库# centos8yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm# centos7yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm## 安装postgresqlyum install -y postgresql13-server## 初始化/usr/pgsql-13/bin/postgresql-13-setup initdb## 放开访问，其中 trust--信任，不用输密码; md5--密码认证sed -i &#x27;s|host all all 127.0.0.1/32 scram-sha-256|host all all 0.0.0.0/0 md5|g&#x27; /var/lib/pgsql/13/data/pg_hba.conf## 修改监听网段sed -i &quot;s|#listen_addresses = &#x27;localhost&#x27;|listen_addresses = &#x27;*&#x27;|g&quot; /var/lib/pgsql/13/data/postgresql.conf## 修改监听端口sed -i &quot;s|#port = 5432|port = 5083|g&quot; /var/lib/pgsql/13/data/postgresql.conf## 重启数据库systemctl enable postgresql-13systemctl restart postgresql-13 安装postgis和pgrouting12345## 建议先配置epel yum源yum install -y postgis32_13.x86_64yum install -y postgis32_13-utilsyum install -y postgis32_13-clientyum install -y pgrouting_13.x86_64 数据库设置12345678--每个database都需创建create extension postgis;create extension postgis_topology;create extension fuzzystrmatch;create extension address_standardizer;create extension address_standardizer_data_us;create extension postgis_tiger_geocoder;create extension pgrouting; 安装tomcat和geoserver12345678#!/bin/sh## 下载tomcat9和gerserver.war包，把war包放到tomcat的webapps目录下## 启动脚本export JAVA_HOME=/data/soft/jdk1.8.0_301export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar/data/geoserver/apache-tomcat-9.0.64/bin/startup.sh systemd-service参考1234567891011121314151617181920cat &lt;&lt; EOF &gt;/usr/lib/systemd/system/geoserver.service[Unit]Description=geoserverAfter=network.target [Service]Type=forkingUser=rootExecStart=/data/geoserver/startup.shExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPID[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl enable geoserversystemctl restart geoserver 问题1404-bad-request 参考资料：https://docs.geoserver.org/stable/en/user/security/webadmin/csrf.html 1234## 启动脚本加上环境变量,关闭或开启白名单export GEOSERVER_CSRF_WHITELIST=xxx.com## orexport GEOSERVER_CSRF_DISABLED=true 问题2https代理后，链接还是代理前的链接 设置-全球-proxy base url设置为代理后的链接","categories":[{"name":"gis","slug":"gis","permalink":"https://biglovewheat.gihub.io/categories/gis/"}],"tags":[{"name":"gis","slug":"gis","permalink":"https://biglovewheat.gihub.io/tags/gis/"},{"name":"postgresql","slug":"postgresql","permalink":"https://biglovewheat.gihub.io/tags/postgresql/"}]},{"title":"Gitlab-批量操作","slug":"gitlab-批量操作","date":"2022-08-02T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/03/gitlab-批量操作/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/03/gitlab-%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C/","excerpt":"","text":"Gitlab-批量操作利用gitlab-api批量操作 123456789101112131415161718192021222324252627282930313233343536373839404142#!/opt/python3/bin/python3import gitlabimport timeimport osimport sysimport pandas as pdimport requestsimport jsonrepo_url = &quot;http://192.168.8.1:8090&quot;token = &quot;xxxxxxxxxxx&quot;headers=&#123; &quot;PRIVATE-TOKEN&quot; : token&#125;session=requests.Session()df1 = pd.DataFrame(columns=[&#x27;pid&#x27;,&#x27;url&#x27;,&#x27;uid&#x27;,&#x27;uname&#x27;,&#x27;role&#x27;])gl = gitlab.Gitlab(repo_url, private_token=token)projects = gl.projects.list(all=True) ## 获取所有projectfor p in projects:# print(p.id)# if p.id==370: url=repo_url+&quot;/api/v4/projects/&quot;+str(p.id)+&quot;/members&quot; ## 获取project下所有member resp=session.get(url,headers=headers) j_member=json.loads(resp.text) df_member=pd.json_normalize(j_member) for i in range(len(df_member)): df1 = df1.append(&#123;&#x27;pid&#x27;:p.id,&#x27;url&#x27;:p.http_url_to_repo,&#x27;uid&#x27;:df_member.iloc[i][&#x27;id&#x27;],&#x27;uname&#x27;:df_member.iloc[i][&#x27;username&#x27;],&#x27;role&#x27;:df_member.iloc[i][&#x27;access_level&#x27;]&#125;, ignore_index=True)print (df1)df1.to_csv(&#x27;project_member.csv&#x27;,index = False) ## 导出csv#for i in range(len(df1)):# if df1.iloc[i][&#x27;uname&#x27;]==&quot;maiqixian&quot;:# url=repo_url+&quot;/api/v4/projects/&quot;+str(df1.iloc[i][&#x27;pid&#x27;])+&quot;/members/&quot;+str(df1.iloc[i][&#x27;uid&#x27;]) ## 按条件更新member的access_level# print(url)# data=&#123;&quot;access_level&quot;:30&#125;# resp=session.put(url,headers=headers,data=data)# print(resp)","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"},{"name":"git","slug":"git","permalink":"https://biglovewheat.gihub.io/tags/git/"}]},{"title":"Python-Jira-自动受理工单","slug":"python-jira-自动受理工单","date":"2022-08-02T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/03/python-jira-自动受理工单/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/03/python-jira-%E8%87%AA%E5%8A%A8%E5%8F%97%E7%90%86%E5%B7%A5%E5%8D%95/","excerpt":"","text":"Python-Jira-自动受理工单12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#coding:utf-8from bs4 import BeautifulSoupimport sysreload(sys)sys.setdefaultencoding( &quot;utf-8&quot; )import requestsimport bs4import sysimport ioimport datetimeimport commands as cmdbase_url = &#x27;http://10.8.17.24:8080&#x27;log = open(&#x27;/home/piccism/sapchk/jira_zdsl_gdzc.log&#x27;,&#x27;a&#x27;)now_time = datetime.datetime.now()print &gt;&gt;log,now_timedata = &#123;&#x27;os_username&#x27;:&#x27;yangwenwei&#x27;, &#x27;os_password&#x27;:&#x27;1111&#x27;, &#x27;os_cookie&#x27;:&#x27;true&#x27;&#125;login_url = base_url+&#x27;/rest/gadget/1.0/login&#x27;session = requests.Session()resp = session.post(login_url, data)query_url = base_url+&#x27;/secure/IssueNavigator!executeAdvanced.jspa&#x27;query_str = &quot;project = GDZC AND (assignee = aaa or assignee = bbb ) AND status=open&quot;query_data = &#123;&#x27;jqlQuery&#x27;:query_str, &#x27;runQuery&#x27;:&#x27;true&#x27;&#125;resp_query = session.post(query_url, query_data)htmlpage = resp_query.content.decode(&#x27;utf-8&#x27;)soup = BeautifulSoup(htmlpage,&#x27;lxml&#x27;) trs = soup.find_all(&#x27;tr&#x27;,&#123;&quot;rel&quot;:True&#125;)for tr in trs: rel = tr[&#x27;rel&#x27;] tds = tr.find_all(&#x27;td&#x27;) issuekey = tds[1].find(&#x27;a&#x27;).string assignee = tds[3].find(&#x27;a&#x27;).string status = tds[5].contents[2].strip() logstr = &#x27;new job &#x27; +rel+&#x27; &#x27;+issuekey+&#x27; &#x27;+assignee+&#x27; &#x27;+status print &gt;&gt;log,logstr if assignee != &#x27;zvb&#x27;: get_url = base_url+&#x27;/secure/AssignIssue.jspa?id=&#x27;+rel+&#x27;&amp;assignee=yangwenwei&#x27; session.get(get_url) get_url = base_url+&#x27;/secure/WorkflowUIDispatcher.jspa?id=&#x27;+rel+&#x27;&amp;action=4&#x27; session.get(get_url) else: get_url = base_url+&#x27;/secure/WorkflowUIDispatcher.jspa?id=&#x27;+rel+&#x27;&amp;action=4&#x27; session.get(get_url)log.close()","categories":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"}]},{"title":"Linux-设置最大文件打开数","slug":"linux-设置最大文件打开数","date":"2022-08-01T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/08/02/linux-设置最大文件打开数/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/02/linux-%E8%AE%BE%E7%BD%AE%E6%9C%80%E5%A4%A7%E6%96%87%E4%BB%B6%E6%89%93%E5%BC%80%E6%95%B0/","excerpt":"","text":"Linux-设置最大文件打开数系统级123456789## file-max一般为内存大小（KB）的10%来计算，一般我们不需要主动设置这个值，除非这个值确实较小cat /proc/sys/fs/file-max## 修改方法vi /etc/sysctl.conffs.file-max = 2000000## 生效sysctl -p 用户级1234567891011121314## 查看ulimit -a或ulimit -n## 修改（session生效）ulimit -n 65535## 修改（永久）vi /etc/security/limits.conf* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"}]},{"title":"Mysql-Mysqldump-备份恢复","slug":"mysql-mysqldump-备份恢复","date":"2022-08-01T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/02/mysql-mysqldump-备份恢复/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/02/mysql-mysqldump-%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/","excerpt":"","text":"Mysql-Mysqldump-备份恢复mysqldump备份恢复12345678910111213141516#!/bin/bashROOT_PATH=/mysqldata_backupDATETIME=$(date +&quot;%Y%m%d%H%M&quot;)passwd=$(grep password /etc/my.cnf |awk &#x27;&#123;print $3&#125;&#x27; |head -1)mysqldump -uroot -p$passwd --all-databases --set-gtid-purged=OFF |gzip &gt;$ROOT_PATH/mysqlbackup_all_show_$DATETIME.sql.gz## 上传到aws s3/usr/local/bin/aws s3 cp $ROOT_PATH/mysqlbackup_all_show_$DATETIME.sql.gz s3://aaa/backup/## 清理过期find $ROOT_PATH -mtime +1 -type f -name &quot;*.sql.gz&quot; | xargs rm -vf## 恢复gunzip &lt; test.tar.gz |mysql -hlocalhost -uroot -pxxxxx xtrabackup备份恢复12345678910111213141516171819202122## 全量备份$ xtrabackup --backup --target-dir=/data/backups/## 异地恢复1-修改root密码为备份数据库密码use mysql；ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;2014Picc!!!&#x27;;ALTER USER &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;2014Picc!!!&#x27;;FLUSH PRIVILEGES;## 异地恢复2-新建目录，修改my.cnf指向目录，并修改目录权限mysql:mysql## 异地恢复3-准备步骤$ xtrabackup --prepare --target-dir=/&lt;备份文件所在目录&gt;/## 异地恢复4-拷贝文件$ xtrabackup --copy-back --target-dir=/&lt;备份文件所在目录&gt;/## 异地恢复5-修改目录权限mysql:mysqlchown -R mysql:mysql## 启动数据库systemctl start mysql","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Mysql-RPM-安装","slug":"mysql-rpm-安装","date":"2022-08-01T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/02/mysql-rpm-安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/02/mysql-rpm-%E5%AE%89%E8%A3%85/","excerpt":"","text":"Mysql-RPM-安装mysql5.7+centos71234567891011121314151617181920212223## 卸载mysql-libsrpm -qa |grep mysqlrpm -e mysql-libs-5.1.73-8.el6_8.x86_64 --nodeps## 安装rpm包rpm -ivh mysql-community-common-5.7.24-1.el6.x86_64.rpmrpm -ivh mysql-community-libs-5.7.24-1.el6.x86_64.rpmrpm -ivh mysql-community-libs-compat-5.7.24-1.el7.x86_64.rpmrpm -ivh mysql-community-client-5.7.24-1.el6.x86_64.rpmrpm -ivh mysql-community-server-5.7.24-1.el6.x86_64.rpm## 启动systemctl start mysqldsystemctl enable mysqld## 初始化cat /var/log/mysqld.log |grep passwordmysql_secure_installationmysql&gt;use mysqlmysql&gt;GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123abc!!!&#x27;;mysql&gt;flush privileges;mysql&gt;quit mysql8+centos7123456789101112131415161718192021222324## 卸载mariadbrpm -e $(rpm -qa |grep maria) --nodepsyum install -y net-tools.x86_64 libaio.x86_64 perl.x86_64## 安装rpm包rpm -ivh mysql-community-common-8*.rpmrpm -ivh mysql-community-client-plugins-8*.rpmrpm -ivh mysql-community-libs-8*.rpmrpm -ivh mysql-community-client-8*.rpmrpm -ivh mysql-community-server-8*.rpm## 启动systemctl start mysqldsystemctl enable mysqld## 初始化cat /var/log/mysqld.log |grep passwordmysql_secure_installationmysql&gt;use mysqlmysql&gt;create user &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123abc!!!&#x27;;mysql&gt;GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27;;mysql&gt;flush privileges;mysql&gt;quit 配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091[client]default-character-set = utf8mb4host = localhostuser = rootport = 3306password = Hxkj2022!!!socket=/data/mysql/mysql.sock[mysql]default-character-set = utf8mb4prompt = (\\\\u@\\\\h)[\\\\d]\\\\R:\\\\m:\\\\s&gt;no-auto-rehash[mysqld]user = mysqlserver-id = 1port = 3306datadir = /data/mysqltmpdir = /tmp##bind-address = 172.31.73.65skip_name_resolve = 1sql_mode = &#x27;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION &#x27;#GTID#gtid_mode=ON#enforce-gtid-consistency=ON#sync#plugin-load-add=rpl_semi_sync_master=semisync_master.so#rpl_semi_sync_master_enabled=1#rpl_semi_sync_master_timeout=10000 # 10 secondbinlog-ignore-db = mysqlbinlog-ignore-db = sysbinlog-ignore-db = information_schemabinlog-ignore-db = performance_schema#charactercharacter-set-server = utf8mb4collation-server = utf8mb4_general_ciinit_connect = &#x27;SET NAMES utf8mb4&#x27;#lower_case_table_names = 1#connectionback_log = 1024max_connections = 1500max_connect_errors = 1000000max_allowed_packet = 128Minteractive_timeout = 1800wait_timeout = 1800#caches &amp; limitsthread_cache_size = 64key_buffer_size = 64Mjoin_buffer_size = 4Msort_buffer_size = 4Mread_buffer_size = 4Mread_rnd_buffer_size = 8Mtmp_table_size = 134217728max_heap_table_size = 134217728log_queries_not_using_indexes = 1log_throttle_queries_not_using_indexes=5#innodbinnodb_file_per_table=1innodb_thread_concurrency = 8innodb_buffer_pool_size = 2Ginnodb_log_file_size = 1Ginnodb_log_buffer_size = 32Minnodb_flush_log_at_trx_commit = 0innodb_max_dirty_pages_pct = 80innodb_io_capacity_max = 2000innodb_buffer_pool_instances = 10innodb_read_ahead_threshold = 0innodb_random_read_ahead = offinnodb_flush_neighbors = 0sync_binlog = 0#loggingsocket=/data/mysql/mysql.sockslow_query_log = 1slow_query_log_file = slow.logrelay-log = mysql-relaylog_slave_updates#log_replica_updateslong_query_time = 1sync_binlog = 1#log_bin = master-binbinlog_expire_logs_seconds = 25900log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid 更改默认目录12345678910## 关闭mysqlsystemctl stop mysqld## 移动目录mv /var/lib/mysql /data/mysql ; chown -R mysql:mysql /data/mysql## 修改my.cnf## 启动systemctl restart mysqld","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Mysql-too-many-connections错误","slug":"mysql-too-many-connections错误","date":"2022-08-01T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/02/mysql-too-many-connections错误/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/02/mysql-too-many-connections%E9%94%99%E8%AF%AF/","excerpt":"","text":"Mysql-too-many-connections错误查看最大连接数123456789101112mysql&gt; show variables like &#x27;%max_connections%&#x27;;+-----------------+-------+| Variable_name | Value |+-----------------+-------+| max_connections | 151 |+-----------------+-------+1 row in set (0.00 sec)###修改连接数set global max_connections = 1000;vi /etc/my.cnfmax_connections=1000 查看实时连接数12345678910111213mysql&gt; show status like &#x27;Threads%&#x27;;+-------------------+-------+| Variable_name | Value |+-------------------+-------+| Threads_cached | 1 || Threads_connected | 2 | ###这个数值指的是打开的连接数 | Threads_created | 3 || Threads_running | 2 | ###这个数值指的是激活的连接数，这个数值一般远低于connected数值 +-------------------+-------+4 rows in set (0.03 sec)show processlist; show status like &#x27;Threads%&#x27;; 查看timeout12345show variables like &#x27;%timeout&#x27;;## 设置timeoutset global wait_timeout=300;set global interactive_timeout=500;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Shell-获取Mysql查询返回值","slug":"shell-获取mysql查询返回值","date":"2022-08-01T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/02/shell-获取mysql查询返回值/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/02/shell-%E8%8E%B7%E5%8F%96mysql%E6%9F%A5%E8%AF%A2%E8%BF%94%E5%9B%9E%E5%80%BC/","excerpt":"","text":"Shell-获取Mysql查询返回值获取单个值1234567891011export MYSQL_PWD=123abc!!!aa=$(mysql -h192.168.8.240 -uroot -Ddatacut -e &quot;select apppath from sys_d_code&quot; --skip-column-names)echo $aauser=rootpass=yfgzSap123port=9901db=datacuttable=sys_d_codeset `mysql -u$user -p$pass -D$db -P $port -e &quot;select outpath from $table&quot;`echo $2 获取多个值12345mysql -uroot -pmysqlroot -Dmmmtest -e &quot;select &#x27;aa&#x27;,count(1) from aa&quot; --skip-column-names|while read a bdoecho $aecho $bdone","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"},{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Mysql-实现dblink","slug":"mysql-实现dblink","date":"2022-07-31T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/01/mysql-实现dblink/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/01/mysql-%E5%AE%9E%E7%8E%B0dblink/","excerpt":"","text":"Mysql-实现dblink版本1Server version: 8.0.23 MySQL Community Server - GPL 查看引擎12345678910111213141516show engines;+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+| ARCHIVE | YES | Archive storage engine | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || FEDERATED | NO | Federated MySQL storage engine | NULL | NULL | NULL || MyISAM | YES | MyISAM storage engine | NO | NO | NO || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || InnoDB | DEFAULT | Supports transactions, row-level locking, and foreign keys | YES | YES | YES || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || CSV | YES | CSV storage engine | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+#federated 有安装但没有开启 设置参数并重启数据库123echo &quot;federated&quot; &gt;&gt;/etc/my.cnfsystemctl restart mysqld 例子12345CREATE TABLE `t_tasks_operate` ( `id` bigint NOT NULL COMMENT &#x27;主键ID&#x27;, `tasks_id` bigint DEFAULT NULL COMMENT &#x27;调度任务id&#x27;, KEY `tasks_id_index` (`tasks_id`) USING BTREE) ENGINE=FEDERATED DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci ROW_FORMAT=COMPACT CONNECTION=&#x27;mysql://root:123456@192.168.1.1:3306/farm_test/t_tasks_operate&#x27; ;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Mysql-数据导入导出","slug":"mysql-文本导入导出","date":"2022-07-31T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/01/mysql-文本导入导出/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/01/mysql-%E6%96%87%E6%9C%AC%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/","excerpt":"","text":"Mysql-数据导入导出导出到文本1234567891011SOURCE_USER=rootSOURCE_DB=aaOUTFILE=aa.txtLoG=aa.log#分隔符|mysql -u$SOURCE_USER -D$SOURCE_DB &lt;&lt;! 2&gt;&gt; $LOG 1&gt;&amp;2select tablename,keymap from cut_table where iskeymap=1into outfile &quot;$OUTFILE&quot;FIELDS TERMINATED BY &#x27;|&#x27; ;! 导入文本12345678910SOURCE_USER=rootSOURCE_DB=aaOUTFILE=aa.txtLoG=aa.log#分隔符|mysql -u$SOURCE_USER -D$SOURCE_DB &lt;&lt;! 2&gt;&gt; $LOG 1&gt;&amp;2load data infile &#x27;$OUTFILE&#x27; into table cut_pkey fields terminated by &#x27;|&#x27;(dbname,list_code,pkeyname,pkeyvalue,status);!","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"},{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Mysql-数据同步脚本","slug":"mysql-数据同步脚本","date":"2022-07-31T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/01/mysql-数据同步脚本/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/01/mysql-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%84%9A%E6%9C%AC/","excerpt":"","text":"Mysql-数据同步脚本用mysqldump同步两个数据库 结构12345├── db.lst ## 数据库对照表├── ignore-table.lst ## 只同步结构，不同步数据的表├── mysql_sync.sh ## 主程序├── source.lst ## 源数据库的配置信息└── target.lst ## 目标数据库的配置信息 配置文件1234567891011121314151617181920212223242526272829# cat db.lst##sourcedb|targetdbtelematics|telematicsiot_sit|iotbaseinfo_sit|base_info# cat ignore-table.lst #sourcedb.tablefarm_sit.t_task_machinery_msg_log_20220511smart_farm_test.t_ag_machinery_work_logfarm_sit.t_task_machinery_msg_logsmart_farm_test.um_user_action_logfarm_sit.t_synergy_task_realtime_infosmart_farm_test.t_drainirrigate_eq_log# cat source.lst[client]user=superpassword=123456host=172.31.40.125port=3306# cat target.lst [client]user=rootpassword=123456host=localhostport=3306 脚本123456789101112131415161718192021222324252627282930#!/bin/bashfor db in $(cat db.lst|grep -v ^#)dosdb=$(echo $db|awk -F\\| &#x27;&#123;print $1&#125;&#x27;)tdb=$(echo $db|awk -F\\| &#x27;&#123;print $2&#125;&#x27;)dateecho &quot;sync $sdb --&gt; $tdb &quot;echo &quot;drop database if exists \\`$tdb\\`;&quot;|mysql --defaults-extra-file=target.lstecho &quot;create database \\`$tdb\\`;&quot;|mysql --defaults-extra-file=target.lstif grep -q $x ^$sdb ignore-table.lstthenfor row in $(grep ^$sdb ignore-table.lst)dorow1=$(echo row |awk -F\\. &#x27;&#123;print $2&#125;&#x27;)row2=$rowstr1=$str1&quot; &quot;$row1str2=$str2&quot; --ignore-table &quot;$row2doneecho $str1 $str2mysqldump --defaults-extra-file=source.lst --opt $sdb --tables $str1 --no-data| mysql --defaults-extra-file=target.lst -C $tdbfimysqldump --defaults-extra-file=source.lst --opt $sdb $str2 | mysql --defaults-extra-file=target.lst -C $tdb## no data#mysqldump --defaults-extra-file=source.lst --opt $sdb $str2 --no-data | mysql --defaults-extra-file=target.lst -C $tdbdone","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"},{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"}]},{"title":"Oracle-用户管理","slug":"oracle-用户管理","date":"2022-07-31T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/01/oracle-用户管理/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/01/oracle-%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86/","excerpt":"","text":"Oracle-用户管理创建只读用户123456create user query identified by query default tablespace cc;grant connect to query ;grant SELECT ANY TABLE to query;--grant select on aaa to query;--数据字典权限grant select any dictionary to query; 创建sysdba权限用户123create user zdbackup identified by zdbackup ;grant sysdba to zdbackup;grant create session, connect, resource to zdbackup ; 用户解锁1alter user scott account unlock; 用户更改密码1alter user user01 identified by user10; 不知道密码的情况下，修改新密码等于旧密码123select * from dba_users;FSSC_LINK 737A7F19A6C8315Balter user FSSC_LINK identified by values &#x27;737A7F19A6C8315B&#x27;; 删除用户1drop user xxxDROP USER XXx CASCADE","categories":[{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"oracle","slug":"oracle","permalink":"https://biglovewheat.gihub.io/tags/oracle/"}]},{"title":"Shell-循环例子","slug":"shell-循环例子","date":"2022-07-31T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/08/01/shell-循环例子/","link":"","permalink":"https://biglovewheat.gihub.io/2022/08/01/shell-%E5%BE%AA%E7%8E%AF%E4%BE%8B%E5%AD%90/","excerpt":"","text":"Shell-循环例子for循环123456789# exmple 1for row in $(cat aa.txt);do echo $row ;sleep 2; done# exmple 3for ((i=1; i&lt;=100; i ++))do echo $idone while循环12345678# exmple 1while true; do date; uptime; sleep 5; done# exmple 2cat a.txt | while read rowdo echo $rowdone","categories":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"}]},{"title":"AWS-EBS-磁盘管理","slug":"aws-ebs-磁盘管理","date":"2022-07-26T16:00:00.000Z","updated":"2023-08-24T12:15:39.766Z","comments":true,"path":"2022/07/27/aws-ebs-磁盘管理/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/27/aws-ebs-%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/","excerpt":"","text":"AWS-EBS-磁盘管理扩容（分区方式）控制台–&gt;EBS–&gt;volumes–&gt;select ebs–&gt;modify volume，修改后等待卷状态变为正常 123456789101112131415## 查看块设备情况[root@ip-172-31-40-27 ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTnvme0n1 259:0 0 100G 0 disk├─nvme0n1p1 259:1 0 1M 0 part└─nvme0n1p2 259:2 0 40G 0 part /## 如果是有分区的，把空间分配到对应分区，如disk没有分区，这一步省略sudo growpart /dev/nvme0n1 2## 再增加到对应的文件系统# xfssudo xfs_growfs -d /# ext4sudo resize2fs /dev/nvme0n1p2 扩容（LVM方式）123456789101112131415## 新增分区的方式## xfsfdisk /dev/vdanpwpartprobelsblkpvcreate /dev/vda3vgdisplayvgextend centos /dev/vda3lvdisplaylvextend -l +100%free /dev/mapper/centos-rootxfs_growfs -d / 1234567891011## 扩容pv的方式## ext4lsblkgrowpart /dev/vda 3lsblkpvdisplaypvresize /dev/vda3vgdisplaylvdisplaylvextend -l +100%free /dev/ubuntu-vg/ubuntu-lvresize2fs /dev/ubuntu-vg/ubuntu-lv 新增磁盘控制台–&gt;EBS–&gt;卷–&gt;创建卷 12345678910111213141516## 查看块设备情况lsblk## 创建挂载点目录mkdir /data## 格式化（xfs）mkfs -t xfs /dev/nvme1n1## 查看uuidblkid## 启动挂载vi /etc/fstabUUID=0cbb74bd-9c5c-4789-8d59-cb6bb2d1038e /data xfs defaults 0 0mount -a 问题12345678910111213## 1xfs_growfs### 错误：unexpected output in sfdisk --version### 解决export LANG=en_US.UTF-8## 2### 相关工具包### centossudo yum install xfsprogs### ubuntusudo apt install cloud-guest-utils","categories":[{"name":"云原生","slug":"云原生","permalink":"https://biglovewheat.gihub.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"}],"tags":[{"name":"aws","slug":"aws","permalink":"https://biglovewheat.gihub.io/tags/aws/"},{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"},{"name":"fs","slug":"fs","permalink":"https://biglovewheat.gihub.io/tags/fs/"}]},{"title":"MinIO-集群安装","slug":"minio-集群安装","date":"2022-07-26T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/07/27/minio-集群安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/27/minio-%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","excerpt":"","text":"MinIO-集群安装官方文档https://docs.min.io/minio/baremetal/installation/deploy-minio-distributed.html#deploy-minio-distributed 集群信息12345## 集群至少需要4个文件系统，可用空间为4台空间之和的一半，&gt;=2台，数据可读，&gt;=3台，数据可读写http://172.31.62.161/data/minio/cluster_datahttp://172.31.56.16/data/minio/cluster_datahttp://172.31.57.206/data/minio/cluster_datahttp://172.31.36.28/data/minio/cluster_data 下载1234wget https://dl.min.io/server/minio/release/linux-amd64/miniochmod +x miniowget https://dl.min.io/client/mc/release/linux-amd64/mcchmod +x mc 启动脚本1234567891011cat &lt;&lt; EOF &gt; startup.shexport MINIO_ROOT_USER=&#x27;minioadmin&#x27;export MINIO_ROOT_PASSWORD=&#x27;minioadmin&#x27;nohup /data/minio/minio server --address &quot;:29000&quot; --console-address &quot;:29001&quot; \\http://172.31.62.161/data/minio/cluster_data http://172.31.56.16/data/minio/cluster_data \\http://172.31.57.206/data/minio/cluster_data http://172.31.36.28/data/minio/cluster_data \\&gt;&gt; /data/minio/minio.log 2&gt;&amp;1 &amp;EOFchmod u+x startup.sh 常用操作1234567891011121314### 导入信息（别名）./mc alias set minio-cluster http://172.31.62.161:29000 minioadmin minioadmin./mc alias set XXXX http://XXXX.s3.cn-northwest-1.amazonaws.com.cn/ AXXXXXXX## 列出别名./mc alias list## 查看集群信息./mc admin info hxs3./mc admin info minio-cluster## 对拷./mc mirror minio-prod minio-cluster./mc mirror minio-prod minio-cluster --overwrite","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"},{"name":"fs","slug":"fs","permalink":"https://biglovewheat.gihub.io/tags/fs/"}]},{"title":"Prometheus-mysql-监控","slug":"prometheus-mysql-监控","date":"2022-07-26T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/07/27/prometheus-mysql-监控/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/27/prometheus-mysql-%E7%9B%91%E6%8E%A7/","excerpt":"","text":"Prometheus-mysql-监控mysql创建用户并授权1234drop user &#x27;exporter&#x27;@&#x27;localhost&#x27;;create user &#x27;exporter&#x27;@&#x27;localhost&#x27; identified by &#x27;123456&#x27;; GRANT REPLICATION CLIENT,PROCESS,SELECT ON *.* TO &#x27;exporter&#x27;@&#x27;localhost&#x27; ; flush privileges; mysql-exporter配置1234567891011121314151617181920212223242526# client.cnfcat &lt;&lt; EOF &gt;/opt/mysqld_exporter/.client.cnf[client]user=exporterpassword=123456EOF# systemctl配置cat &lt;&lt; EOF &gt;/usr/lib/systemd/system/mysqld_exporter.service[Unit]Description= Prometheus MySQL ExporterWants=network-online.targetAfter=network-online.target[Service]User=rootGroup=rootType=simpleRestart=alwaysExecStart=/opt/mysqld_exporter/mysqld_exporter \\--config.my-cnf /opt/mysqld_exporter/.client.cnf \\--web.listen-address=0.0.0.0:51235[Install]WantedBy=multi-user.targetEOF prometheus配置12345# 增加配置并重启prometheusprometheus 配置 - job_name: mysql static_configs: - targets: [&#x27;172.31.40.125:51235&#x27;, &#x27;172.31.36.28:51235&#x27;] grafana配置grafana.com&#x2F;grafana&#x2F;dashboards&#x2F; alert-manager告警配置待补充","categories":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"},{"name":"prometheus","slug":"prometheus","permalink":"https://biglovewheat.gihub.io/tags/prometheus/"}]},{"title":"Python-查数据库-邮件告警","slug":"python-查数据库-邮件告警","date":"2022-07-26T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/07/27/python-查数据库-邮件告警/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/27/python-%E6%9F%A5%E6%95%B0%E6%8D%AE%E5%BA%93-%E9%82%AE%E4%BB%B6%E5%91%8A%E8%AD%A6/","excerpt":"","text":"Python-查数据库-邮件告警一个python写的简单的查数据库脚本，配合crontab和邮件实现定时监控和告警。 监控脚本12345678910111213141516171819202122232425262728293031#!/opt/python3/bin/python3import smtplibfrom email.mime.text import MIMETextimport pymysqlimport datetimedd=(datetime.datetime.now()+datetime.timedelta(days=-1)).strftime(&quot;%Y-%m-%d&quot;)print (dd)db = pymysql.Connect(host=&#x27;10.0.0.1&#x27;,port=3306,user=&#x27;root&#x27;,passwd=&#x27;123456&#x27;,db=&#x27;testdb&#x27;,charset=&#x27;utf8&#x27;)cursor = db.cursor()sql = &quot;select * from t_farm where time=&#x27;&quot;+dd+&quot;&#x27;;&quot;cursor.execute(sql)row=cursor.rowcount#print (row)if row == 0 : msg = MIMEText(dd+&#x27;的条目数是: &#x27;+str(row)+&#x27; ,请检查。&#x27;,&#x27;plain&#x27;,&#x27;utf-8&#x27;) from_addr = &#x27;biglovewheat@126.com&#x27; password = &#x27;GQYRFCDKEXEIHQGH&#x27; ## 邮箱的授权密码，非用户密码 to_addr = [&#x27;biglovewheat@126.com&#x27;,&#x27;aa@126.com&#x27;] smtp_server = &#x27;smtp.126.com&#x27; msg[&#x27;From&#x27;] = from_addr msg[&#x27;To&#x27;] = &#x27;,&#x27;.join(to_addr) msg[&#x27;Subject&#x27;] = &#x27;Python脚本告警&#x27; server = smtplib.SMTP_SSL(smtp_server,465) server.login(from_addr,password) server.sendmail(from_addr,to_addr,msg.as_string()) server.quit() crontab131 4 * * * /data/app/moni.py &gt;&gt; /data/app/moni.log 2&gt;&amp;1","categories":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"}]},{"title":"Rsync同步","slug":"rsync-同步","date":"2022-07-26T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/07/27/rsync-同步/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/27/rsync-%E5%90%8C%E6%AD%A5/","excerpt":"","text":"Rsync同步安装1yum install -y rsync 参数123456789-a 归档模式-v 详细模式-z 传输过程中压缩-u 更新模式-t 保持文件时间-P 显示进度--progress 显示过程中的状态--delete 实现无差异数据同步，删掉dst的文件--exclude 排除,目录相对于src目录 例子123rsync -avzut -P --progress /data/aaa/ root@10.9.127.33:/data/bbb/rsync -avzut -P --progress /var/lib/jenkins/ ops_root@172.31.51.65:/data/backup/jenkins/ --exclude workspace --exclude .cache --exclude .npm 排除列表脚本1234567891011121314151617181920212223242526## 排除列表cat sync_gis.exclude.lstgeoserver/8083/geoserver/8084/logs/geoserver/8084/temp/geoserver/6066/logs/geoserver/6066/temp/geoserver/data/data_8083/#geoserver/data/data_6066/data/test0903geoserver/data/data_6066/logs/geoserver/data/data_6066/gwc/geoserver/data/data_8084/logs/geoserver/data/data_8084/gwc/##!/bin/shdateCMDSTR=&#x27;cd /home/gis/server;rsync -avzut geoserver /s3mnt/gis_data/&#x27;for row in $(cat sync_gis.exclude.lst |grep -v ^# |grep -v ^$);do CMDSTR=$CMDSTR&quot; --exclude &quot;$rowdoneecho $CMDSTR |sh","categories":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"},{"name":"backup","slug":"backup","permalink":"https://biglovewheat.gihub.io/tags/backup/"}]},{"title":"Frp-内网穿透反向代理安装配置","slug":"frp-内网穿透反向代理","date":"2022-07-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/07/26/frp-内网穿透反向代理/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/26/frp-%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/","excerpt":"","text":"Frp-内网穿透反向代理安装配置frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。 测试环境12345公网服务器（server端）：IP：68.79.111.111，centos7内网服务器（client端）：IP：192.168.8.211，centos7frp v0.43.0 下载网址，按需下载对应操作系统版本https://github.com/fatedier/frp/ server配置123456789vi frps.ini[common]bind_port = 7111## 启动./frps -c frps.ini## 或后台启动：nohup /data/frp/frps -c /data/frp/frps.ini &gt;&gt;/data/frp/frps.log 2&gt;&amp;1 &amp; client配置1234567891011121314151617## 配置端口映射，这里server端7112映射到client端22端口，其他端口同理。vi frpc.ini[common]server_addr = 68.79.111.111server_port = 7111## ssh 这个标签不能重复，建议用服务+端口命名[ssh_7112]type = tcplocal_ip = 68.79.111.111local_port = 22remote_port = 7112## 启动：./frpc -c frpc.ini## 或后台启动：nohup /data/frp/frpc -c /data/frp/frpc.ini &gt;&gt;/data/frp/frpc.log 2&gt;&amp;1 &amp; client service 配置1234567891011121314151617181920cat &lt;&lt;EOF &gt; /usr/lib/systemd/system/frp.service[Unit]Description=frpAfter=network.target [Service]Type=forkingUser=rootExecStart=/data/frp/startup.shExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPID[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl enable frpsystemctl restart frp 登录测试访问server的外网IP+7112端口，等于访问client端22端口，达到内网穿透的效果。","categories":[{"name":"network","slug":"network","permalink":"https://biglovewheat.gihub.io/categories/network/"}],"tags":[{"name":"frp","slug":"frp","permalink":"https://biglovewheat.gihub.io/tags/frp/"},{"name":"network","slug":"network","permalink":"https://biglovewheat.gihub.io/tags/network/"}]},{"title":"GitLab-备份恢复","slug":"gitlab-备份恢复","date":"2022-07-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/07/26/gitlab-备份恢复/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/26/gitlab-%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/","excerpt":"","text":"GitLab-备份恢复备份脚本12345678910111213141516171819#!/bin/bashcd /gitlab_jenkins_bakcup/gitlab/DATETIME=$(date +&quot;%Y%m%d%H%M&quot;)FILE1=&quot;gitlab_data_&quot;$&#123;DATETIME&#125;.tarFILE2=&quot;gitlab_config_&quot;$&#123;DATETIME&#125;.tarrm -f /gitlab_jenkins_bakcup/gitlab/*.targitlab-backup creategitlab-ctl backup-etcmv /var/opt/gitlab/backups/*_gitlab_backup.tar $FILE1mv /etc/gitlab/config_backup/gitlab_config*.tar $FILE2/usr/local/bin/aws s3 cp $FILE1 s3://hxs3/backup//usr/local/bin/aws s3 cp $FILE2 s3://hxs3/backup/ 恢复查看版本，备份恢复gitlab版本需一致 http://192.168.8.1:8090/help 13.10.3 安装指定版本 1234567891011cat &lt;&lt; EOF &gt; /etc/yum.repos.d/gitlab-ce.repo[gitlab-ce]name=gitlab-cebaseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7repo_gpgcheck=0gpgcheck=0enabled=1EOFyum list gitlab-ce --showduplicatesyum install -y gitlab-ce-13.10.3-ce.0.el7 将配置文件拷贝到 &#x2F;etc&#x2F;gitlab&#x2F; 将备份文件拷贝到 &#x2F;var&#x2F;opt&#x2F;gitlab&#x2F;backups&#x2F; 恢复准备 12345gitlab-ctl reconfiguregitlab-ctl stop unicorngitlab-ctl stop pumagitlab-ctl stop sidekiqgitlab-ctl status 恢复，文件名不包含_gitlab_backup.tar 123mv gitlab_data_202201190445.tar 1633686919_2021_10_08_13.10.3_gitlab_backup.tarmv 1633686919_2021_10_08_13.10.3_gitlab_backup.tar /var/opt/gitlab/backups/gitlab-backup restore BACKUP=1633686919_2021_10_08_13.10.3 重新配置并启动 12gitlab-ctl reconfiguregitlab-ctl restart","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"git","slug":"git","permalink":"https://biglovewheat.gihub.io/tags/git/"}]},{"title":"Jenkins-k8s-发布脚本","slug":"jenkins-k8s-发布脚本","date":"2022-07-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/07/26/jenkins-k8s-发布脚本/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/26/jenkins-k8s-%E5%8F%91%E5%B8%83%E8%84%9A%E6%9C%AC/","excerpt":"","text":"Jenkins-k8s-发布脚本发布脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586def createVersion() &#123; return new Date().format(&#x27;yyyyMMddHHmmss&#x27;)&#125;def _version = createVersion()def service = &#x27;hx-python-tianqi&#x27;def git_url = &#x27;http://192.168.8.1/hx-python.git&#x27;def credentialsId = &#x27;0a5e96ae-0443-4e1f-ac0a-e02b3b0e4d81&#x27;def docker_repo = &#x27;10.9.127.243:30002/dev&#x27;def namespaces = &#x27;dev&#x27;pipeline &#123; agent any stages &#123; stage(&#x27;拉取代码&#x27;) &#123; when &#123; environment name: &#x27;action&#x27;, value: &#x27;update&#x27; &#125; steps &#123; checkout([$class: &#x27;GitSCM&#x27;, branches: [[name: branch]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[credentialsId: credentialsId, url: git_url]]]) &#125; &#125; stage(&#x27;构建镜像&#x27;)&#123; when &#123; environment name: &#x27;action&#x27;, value: &#x27;update&#x27; &#125; steps &#123; sh &#x27;&#x27;&#x27; cat &lt;&lt; &#x27;EOF&#x27; &gt; dockerfileFROM jfloff/alpine-pythonMAINTAINER hxkjRUN cp -a /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeCOPY tianqi.py /opt/app.pyRUN pip install requests pymysql beautifulsoup4 -i https://pypi.tuna.tsinghua.edu.cn/simpleWORKDIR /optENTRYPOINT [&quot;python&quot;,&quot;app.py&quot;]EOF&#x27;&#x27;&#x27; sh &quot;docker build -t $&#123;docker_repo&#125;/$&#123;service&#125;:$&#123;_version&#125; .&quot; &#125; &#125; stage(&#x27;推送镜像&#x27;)&#123; when &#123; environment name: &#x27;action&#x27;, value: &#x27;update&#x27; &#125; steps &#123; sh &quot;docker push $&#123;docker_repo&#125;/$&#123;service&#125;:$&#123;_version&#125; &quot; sh &quot;docker rmi $&#123;docker_repo&#125;/$&#123;service&#125;:$&#123;_version&#125; &quot; &#125; &#125; stage(&#x27;升级发布&#x27;)&#123; when &#123; environment name: &#x27;action&#x27;, value: &#x27;update&#x27; &#125; steps &#123; sh &quot;&quot;&quot; cat &lt;&lt; EOF &gt; $&#123;service&#125;.yamlapiVersion: batch/v1beta1kind: CronJobmetadata: name: $&#123;service&#125; namespace: $&#123;namespaces&#125;spec: schedule: &quot;*/15 * * * *&quot; jobTemplate: spec: template: spec: nodeSelector: containers: - name: $&#123;namespaces&#125; image: $&#123;docker_repo&#125;/$&#123;service&#125;:$&#123;_version&#125; imagePullPolicy: IfNotPresent restartPolicy: OnFailureEOF&quot;&quot;&quot; sh &quot;kubectl apply -f $&#123;service&#125;.yaml&quot; &#125; &#125; stage(&#x27;紧急回滚&#x27;)&#123; when &#123; environment name: &#x27;action&#x27;, value: &#x27;rollback&#x27; &#125; steps &#123; sh &quot;kubectl rollout undo deployment/$&#123;service&#125; -n $&#123;namespaces&#125;&quot; &#125; &#125; &#125;&#125;","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"},{"name":"jenkins","slug":"jenkins","permalink":"https://biglovewheat.gihub.io/tags/jenkins/"}]},{"title":"Jenkins-Systemd-发布脚本","slug":"jenkins-systemd-发布脚本","date":"2022-07-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.769Z","comments":true,"path":"2022/07/26/jenkins-systemd-发布脚本/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/26/jenkins-systemd-%E5%8F%91%E5%B8%83%E8%84%9A%E6%9C%AC/","excerpt":"","text":"Jenkins-Systemd-发布脚本发布脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#!/bin/bash## /data/publish.sh update js hx-basic 5 4 &quot;www-test/&quot;action=$1apptype=$2svc=$3ver=$4webpath=$6## envROOT=/data#TEMP_HOME=$ROOT/tmpcase $apptype in## java&#x27;java&#x27;) if [ ! -f /usr/lib/systemd/system/$svc.service ];then if [ ! -f $ROOT/java_demo.service ];then echo &quot;java_demo.service not found&quot;; exit ; fi sed &quot;s/__SVC__/$&#123;svc&#125;/g&quot; $ROOT/java_demo.service &gt; /usr/lib/systemd/system/$svc.service systemctl daemon-reload systemctl enable $svc.service fi case $action in &#x27;restart&#x27;) systemctl restart $svc.service ;; &#x27;update&#x27;) ln -snf $ROOT/temp/$&#123;svc&#125;-$&#123;ver&#125;.jar $ROOT/app/$&#123;svc&#125;.jar systemctl restart $svc.service ls -t $ROOT/temp/$&#123;svc&#125;-[[:digit:]]*.jar | sed -n &#x27;11,$p&#x27; | xargs rm -vf ;; &#x27;stop&#x27;) systemctl stop $svc.service ;; &#x27;restore&#x27;) ver=$5 ln -snf $ROOT/temp/$&#123;svc&#125;-$&#123;ver&#125;.jar $ROOT/app/$&#123;svc&#125;.jar systemctl restart $svc.service ;; *) ;; esac;;## js&#x27;js&#x27;) case $action in update) rm -rf $ROOT/webapp/$webpath mkdir -p $ROOT/webapp/$webpath tar -xf $ROOT/temp/$svc-$ver.tgz -C $ROOT/webapp/$webpath ls -t $ROOT/temp/$&#123;svc&#125;-[[:digit:]]*.tgz | sed -n &#x27;11,$p&#x27; | xargs rm -vf ;; restore) ver=$5 rm -rf $ROOT/webapp/$&#123;webpath&#125; mkdir -p $ROOT/webapp/$webpath tar -xf $ROOT/temp/$svc-$ver.tgz -C $ROOT/webapp/$webpath ;; *) ;; esac;;&#x27;autotest&#x27;) case $action in update) rm -rf $ROOT/autotest/web/$svc rm -rf $ROOT/autotest/web/$&#123;svc&#125;*.html rm -rf $ROOT/autotest/web/$&#123;svc&#125;*.log mkdir -p $ROOT/autotest/web/$svc/&#123;logs,screen_shot&#125; rm -rf $ROOT/autotest/$svc mkdir -p $ROOT/autotest/$svc/ChromeDriver/linux/ export PATH=/opt/python3/bin:$PATH tar -xf $ROOT/temp/$svc-$ver.tgz -C $ROOT/autotest/$svc rm -rf /data/autotest/$&#123;svc&#125;/ChromeDriver/linux/chromedriver rm -rf /data/autotest/$&#123;svc&#125;/CommonLibrary/chromedriver.exe ln -sf $ROOT/autotest/chromedriver /data/autotest/$&#123;svc&#125;/ChromeDriver/linux/chromedriver ln -sf $ROOT/autotest/chromedriver /data/autotest/$&#123;svc&#125;/CommonLibrary/chromedriver.exe cd /data/autotest/$svc &amp;&amp; python3 ./runs/run.py &gt; $ROOT/autotest/web/$&#123;svc&#125;.log 2&gt;&amp;1 \\cp -rf $ROOT/autotest/$svc/reports/TestResult.html $ROOT/autotest/web/$&#123;svc&#125;_TestResult.html \\cp -rf $ROOT/autotest/$svc/logs/*.log $ROOT/autotest/web/$&#123;svc&#125;/logs/ \\cp -rf $ROOT/autotest/$svc/screen_shot/*.png $ROOT/autotest/web/$&#123;svc&#125;/screen_shot/ sed -i &#x27;s|http://127.0.0.1/show_log/?log_path=/data/autotest/|http://autotest.farmbgy.com/|g&#x27; $ROOT/autotest/web/$&#123;svc&#125;_TestResult.html sed -i &#x27;s|http://127.0.0.1/show_photo/?pic_path=/data/autotest/|http://autotest.farmbgy.com/|g&#x27; $ROOT/autotest/web/$&#123;svc&#125;_TestResult.html sed -i &#x27;s|http://127.0.0.1:5000/show_log/?log_path=/data/autotest/|http://autotest.farmbgy.com/|g&#x27; $ROOT/autotest/web/$&#123;svc&#125;_TestResult.html sed -i &#x27;s|http://127.0.0.1:5000/show_photo/?pic_path=/data/autotest/|http://autotest.farmbgy.com/|g&#x27; $ROOT/autotest/web/$&#123;svc&#125;_TestResult.html ;; *) ;; esac;;## other*);;esac Service java_demo.service123456789101112131415161718cat &lt;&lt; EOF &gt; java_demo.service[Unit]Description=__SVC__After=network.target[Service]Type=forkingUser=rootEnvironment=&quot;SVC=__SVC__&quot;ExecStart=/data/start_jar.sh start $&#123;SVC&#125;ExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPID#Restart=always[Install]WantedBy=multi-user.targetEOF 启动脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/bin/bashsvc=$2## dirAPP_HOME=/data/appLOG_HOME=/data/logsif [ ! -d $&#123;LOG_HOME&#125;/analyzeGc ]; then mkdir -p $&#123;LOG_HOME&#125;/analyzeGc; fi## nacosexport nacos_address=&quot;172.31.71.117&quot;export nacos_port=&quot;8848&quot;export nacos_namespace=&#x27;c876967c-d8dd-4318-9bf1-e7e72eb47d13&#x27;## javaexport JAVA_HOME=/data/soft/jdk-11.0.11export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar## app envcase $svc in&#x27;hx-schedule-algorithm&#x27;)JAVA_OPS=&quot;-Xms512m -Xmx4g -Xmn1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$&#123;LOG_HOME&#125;/analyzeGc/ -XX:+PrintGCDetails -verbosegc -Xloggc:$&#123;LOG_HOME&#125;/analyzeGc/gc.$&#123;svc&#125;.log&quot;;;*)JAVA_OPS=&quot;-Xms512m -Xmx2g -Xmn1g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$&#123;LOG_HOME&#125;/analyzeGc/ -XX:+PrintGCDetails -verbosegc -Xloggc:$&#123;LOG_HOME&#125;/analyzeGc/gc.$&#123;svc&#125;.log&quot;;;esaccase $svc in#&#x27;hx-thirdparty&#x27;|&#x27;hx-sensordata&#x27;)&#x27;hx-thirdparty&#x27;)SPRING_ENV=prod ## prod,sit,local;;*)SPRING_ENV=local ## prod,sit,local;;esaccase $1 instart) nohup java $&#123;JAVA_OPS&#125; -jar $&#123;APP_HOME&#125;/$&#123;svc&#125;.jar --spring.profiles.active=$&#123;SPRING_ENV&#125; &gt;&gt; $&#123;APP_HOME&#125;/$&#123;svc&#125;.log 2&gt;&amp;1 &amp;;;restart) $0 stop $svc sleep 2 $0 start $svc;;stop) PID=`jps |grep $&#123;svc&#125;|awk &#x27;&#123;print $1&#125;&#x27;` if [ -z &quot;$PID&quot; ]; then echo &quot;no pid found. $0 no start&quot; else kill -9 $PID &amp;&amp; echo &quot;kill pid $PID success.&quot; || echo &quot;kill pid $PID failed.&quot; fi;;*) echo &quot;Usage: $0 [start|restart|update|stop|restore|log|check]&quot; exit 0esac","categories":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"}],"tags":[{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"},{"name":"jenkins","slug":"jenkins","permalink":"https://biglovewheat.gihub.io/tags/jenkins/"}]},{"title":"Nacos集群配置","slug":"nacos-集群配置","date":"2022-07-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/07/26/nacos-集群配置/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/26/nacos-%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Nacos集群配置版本v1.4.1 cluster.conf配置123192.168.8.111:8848192.168.8.112:8848192.168.8.113:8848 初始化数据库1mysql -uroot -p &lt; /data/nacos/conf/nacos-mysql.sql application.properties配置，集群必须用外部存储，这里用mysql123456## Count of DB:db.num=1## Connect URL of DB:db.url.0=jdbc:mysql://192.168.8.111:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTC&amp;allowPublicKeyRetrieval=truedb.user.0=rootdb.password.0=123456 启动脚本12345678#!/bin/shexport JAVA_HOME=/data/soft/jdk-11.0.11export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar## 单机sh /data/nacos/bin/startup.sh -m standalone## 集群sh /data/nacos/bin/startup.sh","categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/tags/middleware/"},{"name":"nacos","slug":"nacos","permalink":"https://biglovewheat.gihub.io/tags/nacos/"}]},{"title":"Python-端口监控-钉钉告警","slug":"python-端口监控-钉钉告警","date":"2022-07-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/07/26/python-端口监控-钉钉告警/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/26/python-%E7%AB%AF%E5%8F%A3%E7%9B%91%E6%8E%A7-%E9%92%89%E9%92%89%E5%91%8A%E8%AD%A6/","excerpt":"","text":"Python-端口监控-钉钉告警一个python写的简单的端口监控例子，配合crontab和钉钉实现定时监控和告警。 配置文件12345678910111213141516171819[root@aws-sit-server-dev-01 moni]# cat moni_port.lstgis|172.31.45.42|6066gis|172.31.45.42|8083gis|172.31.45.42|8084sit-mq|172.31.40.27|9876sit-gitlab|172.31.40.27|8090sit-jenkins|172.31.40.27|8089sit-nacos|172.31.40.27|8848sit-redis|172.31.40.125|6379sit-mysql|172.31.40.125|3306sit-nexus|172.31.45.187|8081show-mq|172.31.73.65|9876show-mysql|172.31.73.65|3306show-nacos|172.31.73.65|8848show-redis|172.31.73.65|6379jx-mq|172.31.71.117|9876jx-mysql|172.31.71.117|3306jx-nacos|172.31.71.117|8848jx-redis|172.31.71.117|6378 监控脚本123456789101112131415161718192021222324252627282930313233#!/opt/python3/bin/python3import datetimeimport socket,sysimport requests,jsondef send_dingding(url, msg): headers = &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125; data = &#123; &quot;msgtype&quot;: &quot;text&quot;, &quot;text&quot;: &#123; &quot;content&quot;: msg &#125; &#125; r = requests.post(url, headers=headers, data=json.dumps(data)) print(r.text)if __name__ == &quot;__main__&quot;: url_dingding = &#x27;https://oapi.dingtalk.com/robot/send?access_token=abcd&#x27; msg=&#x27;&#x27; with open(r&#x27;/data/moni/moni_port.lst&#x27;) as f: for row in f.readlines(): # print(row.strip()) r1,r2,r3=row.strip().split(&#x27;|&#x27;,2) moni_host=r1 moni_ip=r2 moni_port=r3 port_state=socket.socket(socket.AF_INET,socket.SOCK_STREAM).connect_ex((moni_ip,int(moni_port))) if port_state != 0 : msg=msg+moni_host+&quot; &quot;+moni_ip+&quot;:&quot;+moni_port+&quot; has been down. Please check.\\n&quot; if len(msg) &gt; 2: print(datetime.datetime.now()) print(msg) send_dingding(url_dingding,msg)","categories":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"}]},{"title":"Rocketmq-DLeger-集群安装","slug":"rocketmq-dleger-集群安装","date":"2022-07-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/07/26/rocketmq-dleger-集群安装/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/26/rocketmq-dleger-%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85/","excerpt":"","text":"Rocketmq-DLeger-集群安装官方文档More Info: 官方文档 More Info: rocketmq-dashbord 部署主机123172.31.34.25 aws-sit-app-01 172.31.43.98 aws-sit-app-03172.31.43.45 aws-sit-app-04 配置文件123456789101112131415161718/data/rocketmq/conf/dledger/broker-n*.confbrokerClusterName = RaftClusterbrokerName=RaftNode00listenPort=30911namesrvAddr=172.31.34.25:9876;172.31.43.98:9876;172.31.43.45:9876storePathRootDir=/tmp/rmqstore/node00storePathCommitLog=/tmp/rmqstore/node00/commitlogenableDLegerCommitLog=truedLegerGroup=RaftNode00dLegerPeers=n0-172.31.34.25:40911;n1-172.31.43.98:40911;n2-172.31.43.45:40911##每个节点更改n0、n1、n2dLegerSelfId=n0sendMessageThreadPoolNums=4##自动创建topicautoCreateTopicEnable = true## 执行broker ip（多网卡适用）#brokerIP1=10.19.73.64 启动脚本1234567891011#!/bin/shexport JAVA_HOME=/data/soft/jdk1.8.0_301export PATH=$JAVA_HOME/bin:$PATHROOT_PATH=/data/rocketmqnohup sh $ROOT_PATH/bin/mqnamesrv &gt; $ROOT_PATH/startup.log 2&gt;&amp;1 &amp;nohup sh $ROOT_PATH/bin/mqbroker -c $ROOT_PATH/conf/dledger/broker-n0.conf &gt;&gt; $ROOT_PATH/startup.log 2&gt;&amp;1 &amp;## mq consolenohup java -jar $ROOT_PATH/rocketmq-dashboard-1.0.1-SNAPSHOT.jar --server.port=9801 \\--rocketmq.config.namesrvAddr=tcp.farmbgy.net:29876 &gt; $ROOT_PATH/startDashboard.log 2&gt;&amp;1 &amp; systemd-service123456789101112131415161718192021cat &lt;&lt; EOF &gt; /usr/lib/systemd/system/rocketmq.service[Unit]Description=rocketmqAfter=network.target[Service]Type=forkingUser=rootExecStart=/data/rocketmq/startup.shExecStop=/data/rocketmq/stop.sh[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl enable rocketmqsystemctl start rocketmqsystemctl stop rocketmq","categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/tags/middleware/"},{"name":"mq","slug":"mq","permalink":"https://biglovewheat.gihub.io/tags/mq/"}]},{"title":"Shell-并发执行","slug":"shell-并发处理","date":"2022-07-25T16:00:00.000Z","updated":"2023-08-24T12:15:39.770Z","comments":true,"path":"2022/07/26/shell-并发处理/","link":"","permalink":"https://biglovewheat.gihub.io/2022/07/26/shell-%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86/","excerpt":"","text":"Shell-并发处理并发执行12345678910111213141516171819202122[root@std_centos test]# cat aa.shf1()&#123;tail -f 1.txt&#125;f2()&#123;tail -f 2.txt&#125;f3()&#123;tail -f 3.txt&#125;f4()&#123;echo &quot;finished&quot;&#125;f1 &amp; #f1-f3 并发执行f2 &amp;f3 &amp;wait #wait的作用：等待前面的函数执行完成f4 #最后执行f4 控制并发进程数12345678910111213141516171819202122[root@std_centos test]# cat cc.shtempfifo=/tmp/$$.fifo ##获取当前程序的pid，以pid作为文件名，防止重复。mkfifo $tempfifo ##创建有名管道文件exec 1000&lt;&gt;$tempfifo ##将文件描述符1000与管道文件关联rm -rf $tempfifo ##删除管道文件，只保留文件描述符for ((i=1; i&lt;=3; i++)) ##写入3行（空行）到文件描述符1000doecho &gt;&amp;1000donefor ((j=1;j&lt;=10;j++)) ##队列总共10个doread -u1000 ##读取1个空行（读取后，文件描述符减少1个空行，如没空行则hold住等待，知道有新增空行，以达到进程数控制的效果）&#123;tail -f $j.txtecho &gt;&amp;1000 ##写入1个空行（写入后，文件描述符又增加1个空行）&#125;&amp;echo &quot;running:&quot;$jdonewaitexec 1000&lt;&amp;- #关闭文件描述符的读exec 1000&gt;&amp;-echo &quot;--finished--&quot;","categories":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/categories/shell/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"}]}],"categories":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/categories/middleware/"},{"name":"云原生","slug":"云原生","permalink":"https://biglovewheat.gihub.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"},{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/categories/devops/"},{"name":"数据库","slug":"数据库","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/categories/shell/"},{"name":"日志","slug":"日志","permalink":"https://biglovewheat.gihub.io/categories/%E6%97%A5%E5%BF%97/"},{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/categories/%E7%9B%91%E6%8E%A7/"},{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/categories/linux/"},{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/categories/python/"},{"name":"备份恢复","slug":"备份恢复","permalink":"https://biglovewheat.gihub.io/categories/%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/"},{"name":"测试","slug":"测试","permalink":"https://biglovewheat.gihub.io/categories/%E6%B5%8B%E8%AF%95/"},{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/categories/bigdata/"},{"name":"故障排查","slug":"故障排查","permalink":"https://biglovewheat.gihub.io/categories/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/"},{"name":"java","slug":"java","permalink":"https://biglovewheat.gihub.io/categories/java/"},{"name":"network","slug":"network","permalink":"https://biglovewheat.gihub.io/categories/network/"},{"name":"理论知识","slug":"理论知识","permalink":"https://biglovewheat.gihub.io/categories/%E7%90%86%E8%AE%BA%E7%9F%A5%E8%AF%86/"},{"name":"all","slug":"all","permalink":"https://biglovewheat.gihub.io/categories/all/"},{"name":"安全","slug":"安全","permalink":"https://biglovewheat.gihub.io/categories/%E5%AE%89%E5%85%A8/"},{"name":"基础概念","slug":"基础概念","permalink":"https://biglovewheat.gihub.io/categories/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"name":"gis","slug":"gis","permalink":"https://biglovewheat.gihub.io/categories/gis/"}],"tags":[{"name":"middleware","slug":"middleware","permalink":"https://biglovewheat.gihub.io/tags/middleware/"},{"name":"mq","slug":"mq","permalink":"https://biglovewheat.gihub.io/tags/mq/"},{"name":"aws","slug":"aws","permalink":"https://biglovewheat.gihub.io/tags/aws/"},{"name":"gitlab","slug":"gitlab","permalink":"https://biglovewheat.gihub.io/tags/gitlab/"},{"name":"devops","slug":"devops","permalink":"https://biglovewheat.gihub.io/tags/devops/"},{"name":"git","slug":"git","permalink":"https://biglovewheat.gihub.io/tags/git/"},{"name":"oracle","slug":"oracle","permalink":"https://biglovewheat.gihub.io/tags/oracle/"},{"name":"postgresql","slug":"postgresql","permalink":"https://biglovewheat.gihub.io/tags/postgresql/"},{"name":"shell","slug":"shell","permalink":"https://biglovewheat.gihub.io/tags/shell/"},{"name":"阿里云","slug":"阿里云","permalink":"https://biglovewheat.gihub.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"日志","slug":"日志","permalink":"https://biglovewheat.gihub.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"k8s","slug":"k8s","permalink":"https://biglovewheat.gihub.io/tags/k8s/"},{"name":"prometheus","slug":"prometheus","permalink":"https://biglovewheat.gihub.io/tags/prometheus/"},{"name":"linux","slug":"linux","permalink":"https://biglovewheat.gihub.io/tags/linux/"},{"name":"python","slug":"python","permalink":"https://biglovewheat.gihub.io/tags/python/"},{"name":"备份恢复","slug":"备份恢复","permalink":"https://biglovewheat.gihub.io/tags/%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D/"},{"name":"mysql","slug":"mysql","permalink":"https://biglovewheat.gihub.io/tags/mysql/"},{"name":"测试","slug":"测试","permalink":"https://biglovewheat.gihub.io/tags/%E6%B5%8B%E8%AF%95/"},{"name":"bigdata","slug":"bigdata","permalink":"https://biglovewheat.gihub.io/tags/bigdata/"},{"name":"ansible","slug":"ansible","permalink":"https://biglovewheat.gihub.io/tags/ansible/"},{"name":"nginx","slug":"nginx","permalink":"https://biglovewheat.gihub.io/tags/nginx/"},{"name":"consul","slug":"consul","permalink":"https://biglovewheat.gihub.io/tags/consul/"},{"name":"supervisor","slug":"supervisor","permalink":"https://biglovewheat.gihub.io/tags/supervisor/"},{"name":"java","slug":"java","permalink":"https://biglovewheat.gihub.io/tags/java/"},{"name":"database","slug":"database","permalink":"https://biglovewheat.gihub.io/tags/database/"},{"name":"监控","slug":"监控","permalink":"https://biglovewheat.gihub.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"docker","slug":"docker","permalink":"https://biglovewheat.gihub.io/tags/docker/"},{"name":"skywalking","slug":"skywalking","permalink":"https://biglovewheat.gihub.io/tags/skywalking/"},{"name":"network","slug":"network","permalink":"https://biglovewheat.gihub.io/tags/network/"},{"name":"vpn","slug":"vpn","permalink":"https://biglovewheat.gihub.io/tags/vpn/"},{"name":"dns","slug":"dns","permalink":"https://biglovewheat.gihub.io/tags/dns/"},{"name":"jenkins","slug":"jenkins","permalink":"https://biglovewheat.gihub.io/tags/jenkins/"},{"name":"seata","slug":"seata","permalink":"https://biglovewheat.gihub.io/tags/seata/"},{"name":"nodejs","slug":"nodejs","permalink":"https://biglovewheat.gihub.io/tags/nodejs/"},{"name":"nacos","slug":"nacos","permalink":"https://biglovewheat.gihub.io/tags/nacos/"},{"name":"lvs","slug":"lvs","permalink":"https://biglovewheat.gihub.io/tags/lvs/"},{"name":"keepalived","slug":"keepalived","permalink":"https://biglovewheat.gihub.io/tags/keepalived/"},{"name":"ssl","slug":"ssl","permalink":"https://biglovewheat.gihub.io/tags/ssl/"},{"name":"s3","slug":"s3","permalink":"https://biglovewheat.gihub.io/tags/s3/"},{"name":"nexus","slug":"nexus","permalink":"https://biglovewheat.gihub.io/tags/nexus/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://biglovewheat.gihub.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"redis","slug":"redis","permalink":"https://biglovewheat.gihub.io/tags/redis/"},{"name":"安全","slug":"安全","permalink":"https://biglovewheat.gihub.io/tags/%E5%AE%89%E5%85%A8/"},{"name":"http","slug":"http","permalink":"https://biglovewheat.gihub.io/tags/http/"},{"name":"基础概念","slug":"基础概念","permalink":"https://biglovewheat.gihub.io/tags/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"name":"gis","slug":"gis","permalink":"https://biglovewheat.gihub.io/tags/gis/"},{"name":"fs","slug":"fs","permalink":"https://biglovewheat.gihub.io/tags/fs/"},{"name":"backup","slug":"backup","permalink":"https://biglovewheat.gihub.io/tags/backup/"},{"name":"frp","slug":"frp","permalink":"https://biglovewheat.gihub.io/tags/frp/"}]}